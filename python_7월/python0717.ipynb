{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594963159035",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\python37\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf # 1.XX version 을 사용 \n",
    "tf.disable_v2_behavior() # 2.xx version 기능을 사용하지 않겠음\n",
    "import seaborn as sns\n",
    "from tensorflow.examples.tutorials.mnist import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(60000,)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "xtrain.shape\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련샛 검증셋 분리\n",
    "xval = xtrain[50000:]\n",
    "yval = ytrain[50000:]\n",
    "xtrain = xtrain[:50000]\n",
    "ytrain = ytrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=xtrain.reshape(50000,784).astype('float32')/255.0\n",
    "xval=xval.reshape(10000,784).astype('float32')/255.0\n",
    "xtest=xtest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 7
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p5e1cc10494)\">\r\n    <image height=\"218\" id=\"image5f7a934ab5\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m4b4f176efa\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m4b4f176efa\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m4b4f176efa\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m4b4f176efa\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m4b4f176efa\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m4b4f176efa\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m4b4f176efa\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m09d594d667\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m09d594d667\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m09d594d667\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m09d594d667\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m09d594d667\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m09d594d667\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m09d594d667\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p5e1cc10494\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(xtrain[1].reshape(28, 28), plt.cm.Blues)\n",
    "ytrain[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 2, 0])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "np.random.choice(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRandIdx = np.random.choice(50000, 700)\n",
    "valRandIdx = np.random.choice(10000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain[trainRandIdx]\n",
    "ytrain = ytrain[trainRandIdx]\n",
    "xval= xval[valRandIdx]\n",
    "yval= yval[valRandIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스 코딩\n",
    "\n",
    "1)데이터 셋 생성(훈련/ 검증/ 시험 생성)   \n",
    "2) 모델구성 (Sequential(간단한 모델), 함수 API(복잡한 모델))   \n",
    "3) 모델 학습 과정 설정(cost함수, 옵티마이저 정의) - compile함    \n",
    "4) 모델 락습시키기 (train data) = fit 함수  \n",
    "5) 학습과정 확인(훈련셋/ 검증셋 cost, 정확도 측정) -> 모델  \n",
    "6) 모델 평가(test data) - evalute 함수  \n",
    "7) 모델 사용  - predict 함수  \n",
    "\n",
    "참고 콜백 함수: 어떤 상태가 되었을 때, 사전에 지정한 함수가 호출됨\n",
    "ex) 와이파이 켬 -> 이동 -> 와이파이 검색 되었을 때, 사전에 지정한 함수가 도출됨\n",
    "사전에 지정한 함수가 호출 됨 -> 화면에 와이파이가 검색되었습니다.가 나옴\n",
    "\n",
    "콜백함수 : 모델을 학습하다가 더 이상 좋아지지 않으면 (상태) 모델링 중단하도록 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(300,)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "yval = np_utils.to_categorical(yval)\n",
    "ytest = np_utils.to_categorical(ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(300, 10)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data = [2,3,9,0,1]\n",
    "np_utils.to_categorical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
    }
   ],
   "source": [
    "# 2. 모델 구성하기  입력계층, 히든 계층 출력 계층\n",
    "model = Sequential()\n",
    "model.add(Dense(units =2, input_dim = 28*28, activation= 'relu')) #래이어 설계, 입력데이터의 차원\n",
    "# 입력 =784, 출력=2인 레이어 추가 \n",
    "\n",
    "model.add(Dense(units =10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번 모델 학습과정 설정 \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics = ['accuracy']) # loss == cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 700 samples, validate on 300 samples\nEpoch 1/1000\n700/700 [==============================] - 0s 114us/sample - loss: 2.2788 - acc: 0.1314 - val_loss: 2.2667 - val_acc: 0.1333\nEpoch 2/1000\n700/700 [==============================] - 0s 84us/sample - loss: 2.2336 - acc: 0.1757 - val_loss: 2.2282 - val_acc: 0.1567\nEpoch 3/1000\n700/700 [==============================] - 0s 87us/sample - loss: 2.1948 - acc: 0.2114 - val_loss: 2.1926 - val_acc: 0.1967\nEpoch 4/1000\n700/700 [==============================] - 0s 84us/sample - loss: 2.1396 - acc: 0.2286 - val_loss: 2.1217 - val_acc: 0.2133\nEpoch 5/1000\n700/700 [==============================] - 0s 88us/sample - loss: 2.0777 - acc: 0.2729 - val_loss: 2.0619 - val_acc: 0.3133\nEpoch 6/1000\n700/700 [==============================] - 0s 87us/sample - loss: 2.0271 - acc: 0.3257 - val_loss: 2.0143 - val_acc: 0.3367\nEpoch 7/1000\n700/700 [==============================] - 0s 88us/sample - loss: 1.9834 - acc: 0.3386 - val_loss: 1.9765 - val_acc: 0.3500\nEpoch 8/1000\n700/700 [==============================] - 0s 90us/sample - loss: 1.9445 - acc: 0.3314 - val_loss: 1.9516 - val_acc: 0.3233\nEpoch 9/1000\n700/700 [==============================] - 0s 81us/sample - loss: 1.9069 - acc: 0.3357 - val_loss: 1.9352 - val_acc: 0.3367\nEpoch 10/1000\n700/700 [==============================] - 0s 81us/sample - loss: 1.8778 - acc: 0.3571 - val_loss: 1.8829 - val_acc: 0.3500\nEpoch 11/1000\n700/700 [==============================] - 0s 113us/sample - loss: 1.8464 - acc: 0.3686 - val_loss: 1.8524 - val_acc: 0.3667\nEpoch 12/1000\n700/700 [==============================] - 0s 78us/sample - loss: 1.8170 - acc: 0.4014 - val_loss: 1.8286 - val_acc: 0.3667\nEpoch 13/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.7907 - acc: 0.4143 - val_loss: 1.8165 - val_acc: 0.3800\nEpoch 14/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.7644 - acc: 0.4314 - val_loss: 1.7791 - val_acc: 0.3933\nEpoch 15/1000\n700/700 [==============================] - 0s 78us/sample - loss: 1.7422 - acc: 0.4400 - val_loss: 1.7645 - val_acc: 0.3967\nEpoch 16/1000\n700/700 [==============================] - 0s 81us/sample - loss: 1.7203 - acc: 0.4443 - val_loss: 1.7512 - val_acc: 0.4000\nEpoch 17/1000\n700/700 [==============================] - 0s 114us/sample - loss: 1.6995 - acc: 0.4600 - val_loss: 1.7296 - val_acc: 0.4100\nEpoch 18/1000\n700/700 [==============================] - 0s 101us/sample - loss: 1.6778 - acc: 0.4586 - val_loss: 1.7313 - val_acc: 0.4067\nEpoch 19/1000\n700/700 [==============================] - 0s 81us/sample - loss: 1.6606 - acc: 0.4629 - val_loss: 1.7005 - val_acc: 0.4300\nEpoch 20/1000\n700/700 [==============================] - 0s 84us/sample - loss: 1.6415 - acc: 0.4700 - val_loss: 1.6819 - val_acc: 0.4333\nEpoch 21/1000\n700/700 [==============================] - 0s 83us/sample - loss: 1.6256 - acc: 0.4600 - val_loss: 1.6718 - val_acc: 0.4333\nEpoch 22/1000\n700/700 [==============================] - 0s 80us/sample - loss: 1.6084 - acc: 0.4714 - val_loss: 1.6728 - val_acc: 0.4433\nEpoch 23/1000\n700/700 [==============================] - 0s 80us/sample - loss: 1.5925 - acc: 0.4714 - val_loss: 1.6493 - val_acc: 0.4500\nEpoch 24/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.5765 - acc: 0.4729 - val_loss: 1.6318 - val_acc: 0.4567\nEpoch 25/1000\n700/700 [==============================] - 0s 84us/sample - loss: 1.5635 - acc: 0.4886 - val_loss: 1.6229 - val_acc: 0.4633\nEpoch 26/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.5477 - acc: 0.4714 - val_loss: 1.6242 - val_acc: 0.4500\nEpoch 27/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.5342 - acc: 0.4786 - val_loss: 1.5971 - val_acc: 0.4533\nEpoch 28/1000\n700/700 [==============================] - 0s 88us/sample - loss: 1.5215 - acc: 0.4786 - val_loss: 1.5988 - val_acc: 0.4633\nEpoch 29/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.5078 - acc: 0.4800 - val_loss: 1.5813 - val_acc: 0.4533\nEpoch 30/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.4948 - acc: 0.4771 - val_loss: 1.5810 - val_acc: 0.4767\nEpoch 31/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.4815 - acc: 0.4757 - val_loss: 1.5586 - val_acc: 0.4433\nEpoch 32/1000\n700/700 [==============================] - 0s 84us/sample - loss: 1.4686 - acc: 0.4971 - val_loss: 1.5590 - val_acc: 0.4533\nEpoch 33/1000\n700/700 [==============================] - 0s 85us/sample - loss: 1.4565 - acc: 0.4814 - val_loss: 1.5479 - val_acc: 0.4767\nEpoch 34/1000\n700/700 [==============================] - 0s 78us/sample - loss: 1.4455 - acc: 0.5014 - val_loss: 1.5338 - val_acc: 0.4400\nEpoch 35/1000\n700/700 [==============================] - 0s 80us/sample - loss: 1.4357 - acc: 0.4786 - val_loss: 1.5312 - val_acc: 0.4833\nEpoch 36/1000\n700/700 [==============================] - 0s 87us/sample - loss: 1.4251 - acc: 0.4843 - val_loss: 1.5237 - val_acc: 0.4800\nEpoch 37/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.4111 - acc: 0.5129 - val_loss: 1.5160 - val_acc: 0.4800\nEpoch 38/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.4036 - acc: 0.4943 - val_loss: 1.5148 - val_acc: 0.5000\nEpoch 39/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.3925 - acc: 0.5186 - val_loss: 1.5077 - val_acc: 0.4800\nEpoch 40/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.3805 - acc: 0.4886 - val_loss: 1.5046 - val_acc: 0.5000\nEpoch 41/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.3759 - acc: 0.4986 - val_loss: 1.4858 - val_acc: 0.4733\nEpoch 42/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.3629 - acc: 0.5071 - val_loss: 1.4925 - val_acc: 0.4733\nEpoch 43/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.3571 - acc: 0.5029 - val_loss: 1.4797 - val_acc: 0.4833\nEpoch 44/1000\n700/700 [==============================] - 0s 135us/sample - loss: 1.3462 - acc: 0.5014 - val_loss: 1.4763 - val_acc: 0.4800\nEpoch 45/1000\n700/700 [==============================] - 0s 80us/sample - loss: 1.3381 - acc: 0.5157 - val_loss: 1.4799 - val_acc: 0.5000\nEpoch 46/1000\n700/700 [==============================] - 0s 70us/sample - loss: 1.3304 - acc: 0.5186 - val_loss: 1.4611 - val_acc: 0.4833\nEpoch 47/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.3232 - acc: 0.5029 - val_loss: 1.4528 - val_acc: 0.4767\nEpoch 48/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.3173 - acc: 0.5286 - val_loss: 1.4609 - val_acc: 0.4967\nEpoch 49/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.3073 - acc: 0.5143 - val_loss: 1.4758 - val_acc: 0.5000\nEpoch 50/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.3039 - acc: 0.5143 - val_loss: 1.4476 - val_acc: 0.4967\nEpoch 51/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.2963 - acc: 0.5314 - val_loss: 1.4470 - val_acc: 0.5167\nEpoch 52/1000\n700/700 [==============================] - 0s 70us/sample - loss: 1.2887 - acc: 0.5257 - val_loss: 1.4466 - val_acc: 0.5033\nEpoch 53/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.2820 - acc: 0.5257 - val_loss: 1.4404 - val_acc: 0.5100\nEpoch 54/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.2751 - acc: 0.5329 - val_loss: 1.4314 - val_acc: 0.4733\nEpoch 55/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.2686 - acc: 0.5243 - val_loss: 1.4338 - val_acc: 0.5033\nEpoch 56/1000\n700/700 [==============================] - 0s 70us/sample - loss: 1.2652 - acc: 0.5257 - val_loss: 1.4306 - val_acc: 0.5167\nEpoch 57/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.2576 - acc: 0.5486 - val_loss: 1.4413 - val_acc: 0.5100\nEpoch 58/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.2544 - acc: 0.5343 - val_loss: 1.4268 - val_acc: 0.5100\nEpoch 59/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.2475 - acc: 0.5357 - val_loss: 1.4354 - val_acc: 0.5067\nEpoch 60/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.2412 - acc: 0.5414 - val_loss: 1.4234 - val_acc: 0.5033\nEpoch 61/1000\n700/700 [==============================] - 0s 70us/sample - loss: 1.2359 - acc: 0.5514 - val_loss: 1.4233 - val_acc: 0.5067\nEpoch 62/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.2299 - acc: 0.5386 - val_loss: 1.4164 - val_acc: 0.5067\nEpoch 63/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.2223 - acc: 0.5514 - val_loss: 1.4159 - val_acc: 0.5000\nEpoch 64/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.2199 - acc: 0.5314 - val_loss: 1.4173 - val_acc: 0.5033\nEpoch 65/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.2158 - acc: 0.5600 - val_loss: 1.4289 - val_acc: 0.5033\nEpoch 66/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.2120 - acc: 0.5500 - val_loss: 1.4117 - val_acc: 0.5133\nEpoch 67/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.2048 - acc: 0.5514 - val_loss: 1.4110 - val_acc: 0.5100\nEpoch 68/1000\n700/700 [==============================] - 0s 78us/sample - loss: 1.2021 - acc: 0.5443 - val_loss: 1.4233 - val_acc: 0.5033\nEpoch 69/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1964 - acc: 0.5557 - val_loss: 1.4071 - val_acc: 0.5067\nEpoch 70/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1936 - acc: 0.5443 - val_loss: 1.4097 - val_acc: 0.5267\nEpoch 71/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1899 - acc: 0.5557 - val_loss: 1.4139 - val_acc: 0.5167\nEpoch 72/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1844 - acc: 0.5600 - val_loss: 1.4160 - val_acc: 0.5033\nEpoch 73/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.1820 - acc: 0.5686 - val_loss: 1.4059 - val_acc: 0.5267\nEpoch 74/1000\n700/700 [==============================] - 0s 87us/sample - loss: 1.1761 - acc: 0.5557 - val_loss: 1.4084 - val_acc: 0.5067\nEpoch 75/1000\n700/700 [==============================] - 0s 104us/sample - loss: 1.1730 - acc: 0.5671 - val_loss: 1.4068 - val_acc: 0.5167\nEpoch 76/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.1680 - acc: 0.5471 - val_loss: 1.4165 - val_acc: 0.5167\nEpoch 77/1000\n700/700 [==============================] - 0s 70us/sample - loss: 1.1620 - acc: 0.5629 - val_loss: 1.4179 - val_acc: 0.5067\nEpoch 78/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1588 - acc: 0.5743 - val_loss: 1.3943 - val_acc: 0.5400\nEpoch 79/1000\n700/700 [==============================] - 0s 81us/sample - loss: 1.1568 - acc: 0.5743 - val_loss: 1.3945 - val_acc: 0.5167\nEpoch 80/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1515 - acc: 0.5757 - val_loss: 1.4081 - val_acc: 0.5167\nEpoch 81/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.1484 - acc: 0.5671 - val_loss: 1.4086 - val_acc: 0.5100\nEpoch 82/1000\n700/700 [==============================] - 0s 128us/sample - loss: 1.1435 - acc: 0.5843 - val_loss: 1.4345 - val_acc: 0.5000\nEpoch 83/1000\n700/700 [==============================] - 0s 104us/sample - loss: 1.1411 - acc: 0.5786 - val_loss: 1.4067 - val_acc: 0.5200\nEpoch 84/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1385 - acc: 0.5700 - val_loss: 1.4195 - val_acc: 0.5167\nEpoch 85/1000\n700/700 [==============================] - 0s 83us/sample - loss: 1.1331 - acc: 0.5814 - val_loss: 1.4014 - val_acc: 0.5133\nEpoch 86/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.1271 - acc: 0.5757 - val_loss: 1.4081 - val_acc: 0.5067\nEpoch 87/1000\n700/700 [==============================] - 0s 81us/sample - loss: 1.1284 - acc: 0.5800 - val_loss: 1.4040 - val_acc: 0.5267\nEpoch 88/1000\n700/700 [==============================] - 0s 78us/sample - loss: 1.1242 - acc: 0.5729 - val_loss: 1.3962 - val_acc: 0.5267\nEpoch 89/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.1214 - acc: 0.5671 - val_loss: 1.3986 - val_acc: 0.5167\nEpoch 90/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.1163 - acc: 0.5929 - val_loss: 1.4059 - val_acc: 0.5267\nEpoch 91/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.1145 - acc: 0.5786 - val_loss: 1.4272 - val_acc: 0.5133\nEpoch 92/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.1105 - acc: 0.5843 - val_loss: 1.4027 - val_acc: 0.5267\nEpoch 93/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.1080 - acc: 0.5829 - val_loss: 1.4066 - val_acc: 0.5267\nEpoch 94/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.1037 - acc: 0.5771 - val_loss: 1.4122 - val_acc: 0.5167\nEpoch 95/1000\n700/700 [==============================] - 0s 84us/sample - loss: 1.1001 - acc: 0.5786 - val_loss: 1.4094 - val_acc: 0.5333\nEpoch 96/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.0987 - acc: 0.5786 - val_loss: 1.4137 - val_acc: 0.5267\nEpoch 97/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.0938 - acc: 0.5871 - val_loss: 1.4194 - val_acc: 0.5167\nEpoch 98/1000\n700/700 [==============================] - 0s 80us/sample - loss: 1.0926 - acc: 0.5871 - val_loss: 1.4078 - val_acc: 0.5367\nEpoch 99/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0931 - acc: 0.5914 - val_loss: 1.4088 - val_acc: 0.5200\nEpoch 100/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0861 - acc: 0.6057 - val_loss: 1.4017 - val_acc: 0.5233\nEpoch 101/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0829 - acc: 0.5914 - val_loss: 1.4127 - val_acc: 0.5300\nEpoch 102/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0794 - acc: 0.5986 - val_loss: 1.4056 - val_acc: 0.5267\nEpoch 103/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.0763 - acc: 0.5914 - val_loss: 1.4212 - val_acc: 0.5267\nEpoch 104/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0746 - acc: 0.5814 - val_loss: 1.4158 - val_acc: 0.5133\nEpoch 105/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.0687 - acc: 0.5929 - val_loss: 1.4089 - val_acc: 0.5367\nEpoch 106/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.0716 - acc: 0.5971 - val_loss: 1.4254 - val_acc: 0.5167\nEpoch 107/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0703 - acc: 0.5843 - val_loss: 1.4129 - val_acc: 0.5267\nEpoch 108/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.0602 - acc: 0.6071 - val_loss: 1.4189 - val_acc: 0.5167\nEpoch 109/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0599 - acc: 0.5943 - val_loss: 1.4273 - val_acc: 0.5267\nEpoch 110/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0563 - acc: 0.6043 - val_loss: 1.4271 - val_acc: 0.5233\nEpoch 111/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0571 - acc: 0.6100 - val_loss: 1.4170 - val_acc: 0.5333\nEpoch 112/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.0549 - acc: 0.6000 - val_loss: 1.4306 - val_acc: 0.5133\nEpoch 113/1000\n700/700 [==============================] - 0s 93us/sample - loss: 1.0507 - acc: 0.5886 - val_loss: 1.4247 - val_acc: 0.5333\nEpoch 114/1000\n700/700 [==============================] - 0s 78us/sample - loss: 1.0476 - acc: 0.6057 - val_loss: 1.4325 - val_acc: 0.5233\nEpoch 115/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.0430 - acc: 0.6114 - val_loss: 1.4444 - val_acc: 0.5133\nEpoch 116/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0445 - acc: 0.6029 - val_loss: 1.4250 - val_acc: 0.5200\nEpoch 117/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0410 - acc: 0.6143 - val_loss: 1.4188 - val_acc: 0.5267\nEpoch 118/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.0367 - acc: 0.6171 - val_loss: 1.4276 - val_acc: 0.5100\nEpoch 119/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.0360 - acc: 0.6143 - val_loss: 1.4267 - val_acc: 0.5267\nEpoch 120/1000\n700/700 [==============================] - 0s 125us/sample - loss: 1.0324 - acc: 0.6186 - val_loss: 1.4249 - val_acc: 0.5267\nEpoch 121/1000\n700/700 [==============================] - 0s 76us/sample - loss: 1.0308 - acc: 0.6114 - val_loss: 1.4549 - val_acc: 0.5067\nEpoch 122/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.0276 - acc: 0.6157 - val_loss: 1.4354 - val_acc: 0.5267\nEpoch 123/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0263 - acc: 0.6171 - val_loss: 1.4439 - val_acc: 0.5100\nEpoch 124/1000\n700/700 [==============================] - 0s 73us/sample - loss: 1.0223 - acc: 0.6071 - val_loss: 1.4438 - val_acc: 0.5233\nEpoch 125/1000\n700/700 [==============================] - 0s 131us/sample - loss: 1.0183 - acc: 0.6129 - val_loss: 1.4289 - val_acc: 0.5333\nEpoch 126/1000\n700/700 [==============================] - 0s 77us/sample - loss: 1.0172 - acc: 0.6114 - val_loss: 1.4378 - val_acc: 0.5167\nEpoch 127/1000\n700/700 [==============================] - 0s 85us/sample - loss: 1.0148 - acc: 0.6271 - val_loss: 1.4519 - val_acc: 0.4900\nEpoch 128/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.0135 - acc: 0.6186 - val_loss: 1.4372 - val_acc: 0.5267\nEpoch 129/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0105 - acc: 0.6200 - val_loss: 1.4380 - val_acc: 0.5167\nEpoch 130/1000\n700/700 [==============================] - 0s 74us/sample - loss: 1.0064 - acc: 0.6229 - val_loss: 1.4420 - val_acc: 0.5200\nEpoch 131/1000\n700/700 [==============================] - 0s 94us/sample - loss: 1.0062 - acc: 0.6229 - val_loss: 1.4532 - val_acc: 0.5100\nEpoch 132/1000\n700/700 [==============================] - 0s 71us/sample - loss: 1.0043 - acc: 0.6300 - val_loss: 1.4421 - val_acc: 0.5333\nEpoch 133/1000\n 10/700 [..............................] - ETA: 0s - loss: 0.7519 - acc: 0.800700/700 [==============================] - 0s 73us/sample - loss: 1.0020 - acc: 0.6086 - val_loss: 1.4322 - val_acc: 0.5300\nEpoch 134/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.9985 - acc: 0.6357 - val_loss: 1.4475 - val_acc: 0.5100\nEpoch 135/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9971 - acc: 0.6343 - val_loss: 1.4416 - val_acc: 0.5267\nEpoch 136/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9965 - acc: 0.6214 - val_loss: 1.4527 - val_acc: 0.5067\nEpoch 137/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9914 - acc: 0.6229 - val_loss: 1.4612 - val_acc: 0.4967\nEpoch 138/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.9901 - acc: 0.6157 - val_loss: 1.4607 - val_acc: 0.4967\nEpoch 139/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9882 - acc: 0.6329 - val_loss: 1.4405 - val_acc: 0.5200\nEpoch 140/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.9858 - acc: 0.6386 - val_loss: 1.4473 - val_acc: 0.5267\nEpoch 141/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9837 - acc: 0.6300 - val_loss: 1.4631 - val_acc: 0.5033\nEpoch 142/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9802 - acc: 0.6186 - val_loss: 1.4512 - val_acc: 0.5233\nEpoch 143/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9815 - acc: 0.6329 - val_loss: 1.4511 - val_acc: 0.5233\nEpoch 144/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9800 - acc: 0.6429 - val_loss: 1.4596 - val_acc: 0.5133\nEpoch 145/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9771 - acc: 0.6343 - val_loss: 1.4575 - val_acc: 0.5133\nEpoch 146/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9727 - acc: 0.6386 - val_loss: 1.4687 - val_acc: 0.5133\nEpoch 147/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9735 - acc: 0.6443 - val_loss: 1.4501 - val_acc: 0.5300\nEpoch 148/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9675 - acc: 0.6429 - val_loss: 1.4456 - val_acc: 0.5300\nEpoch 149/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9668 - acc: 0.6486 - val_loss: 1.4561 - val_acc: 0.5100\nEpoch 150/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9630 - acc: 0.6300 - val_loss: 1.4619 - val_acc: 0.5100\nEpoch 151/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9591 - acc: 0.6443 - val_loss: 1.4532 - val_acc: 0.5300\nEpoch 152/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9620 - acc: 0.6429 - val_loss: 1.4704 - val_acc: 0.5167\nEpoch 153/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9561 - acc: 0.6343 - val_loss: 1.4656 - val_acc: 0.5233\nEpoch 154/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9565 - acc: 0.6857 - val_loss: 1.4629 - val_acc: 0.5467\nEpoch 155/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9580 - acc: 0.6857 - val_loss: 1.4697 - val_acc: 0.5300\nEpoch 156/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9531 - acc: 0.6700 - val_loss: 1.4585 - val_acc: 0.5333\nEpoch 157/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.9522 - acc: 0.6771 - val_loss: 1.4691 - val_acc: 0.5267\nEpoch 158/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.9481 - acc: 0.6814 - val_loss: 1.4700 - val_acc: 0.5333\nEpoch 159/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9425 - acc: 0.6843 - val_loss: 1.5040 - val_acc: 0.5200\nEpoch 160/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.9454 - acc: 0.6743 - val_loss: 1.4864 - val_acc: 0.5267\nEpoch 161/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9435 - acc: 0.6800 - val_loss: 1.4739 - val_acc: 0.5267\nEpoch 162/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9433 - acc: 0.6843 - val_loss: 1.4747 - val_acc: 0.5267\nEpoch 163/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9417 - acc: 0.6686 - val_loss: 1.4813 - val_acc: 0.5333\nEpoch 164/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9401 - acc: 0.6814 - val_loss: 1.4728 - val_acc: 0.5467\nEpoch 165/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9384 - acc: 0.6886 - val_loss: 1.4831 - val_acc: 0.5367\nEpoch 166/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9358 - acc: 0.6886 - val_loss: 1.4943 - val_acc: 0.5167\nEpoch 167/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.9318 - acc: 0.6914 - val_loss: 1.4785 - val_acc: 0.5333\nEpoch 168/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9282 - acc: 0.6914 - val_loss: 1.5146 - val_acc: 0.5333\nEpoch 169/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9265 - acc: 0.6971 - val_loss: 1.4990 - val_acc: 0.5233\nEpoch 170/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9268 - acc: 0.6857 - val_loss: 1.4923 - val_acc: 0.5400\nEpoch 171/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9239 - acc: 0.6843 - val_loss: 1.4907 - val_acc: 0.5433\nEpoch 172/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9220 - acc: 0.6943 - val_loss: 1.4851 - val_acc: 0.5467\nEpoch 173/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9184 - acc: 0.6886 - val_loss: 1.4770 - val_acc: 0.5433\nEpoch 174/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9222 - acc: 0.6943 - val_loss: 1.4934 - val_acc: 0.5600\nEpoch 175/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9174 - acc: 0.6971 - val_loss: 1.4901 - val_acc: 0.5367\nEpoch 176/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.9171 - acc: 0.6914 - val_loss: 1.4971 - val_acc: 0.5400\nEpoch 177/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.9145 - acc: 0.6857 - val_loss: 1.4935 - val_acc: 0.5333\nEpoch 178/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9130 - acc: 0.7000 - val_loss: 1.4849 - val_acc: 0.5600\nEpoch 179/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.9106 - acc: 0.6986 - val_loss: 1.4928 - val_acc: 0.5333\nEpoch 180/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9086 - acc: 0.6900 - val_loss: 1.5205 - val_acc: 0.5333\nEpoch 181/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.9067 - acc: 0.6957 - val_loss: 1.4898 - val_acc: 0.5467\nEpoch 182/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9075 - acc: 0.6943 - val_loss: 1.4886 - val_acc: 0.5433\nEpoch 183/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.9063 - acc: 0.6957 - val_loss: 1.4932 - val_acc: 0.5500\nEpoch 184/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9026 - acc: 0.7057 - val_loss: 1.5089 - val_acc: 0.5367\nEpoch 185/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8989 - acc: 0.6929 - val_loss: 1.5114 - val_acc: 0.5333\nEpoch 186/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.9005 - acc: 0.7029 - val_loss: 1.5203 - val_acc: 0.5467\nEpoch 187/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8968 - acc: 0.6929 - val_loss: 1.5093 - val_acc: 0.5367\nEpoch 188/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.8943 - acc: 0.6986 - val_loss: 1.5195 - val_acc: 0.5233\nEpoch 189/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8957 - acc: 0.7029 - val_loss: 1.5263 - val_acc: 0.5433\nEpoch 190/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8921 - acc: 0.6986 - val_loss: 1.5043 - val_acc: 0.5533\nEpoch 191/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8917 - acc: 0.7143 - val_loss: 1.5265 - val_acc: 0.5167\nEpoch 192/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8864 - acc: 0.7000 - val_loss: 1.5227 - val_acc: 0.5333\nEpoch 193/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.8845 - acc: 0.7086 - val_loss: 1.5435 - val_acc: 0.5233\nEpoch 194/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.8894 - acc: 0.7000 - val_loss: 1.5171 - val_acc: 0.5467\nEpoch 195/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8818 - acc: 0.7114 - val_loss: 1.5278 - val_acc: 0.5400\nEpoch 196/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8856 - acc: 0.7057 - val_loss: 1.5295 - val_acc: 0.5433\nEpoch 197/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8805 - acc: 0.7000 - val_loss: 1.5420 - val_acc: 0.5400\nEpoch 198/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8782 - acc: 0.7171 - val_loss: 1.5130 - val_acc: 0.5467\nEpoch 199/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8765 - acc: 0.7014 - val_loss: 1.5578 - val_acc: 0.5367\nEpoch 200/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8774 - acc: 0.7043 - val_loss: 1.5165 - val_acc: 0.5267\nEpoch 201/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8742 - acc: 0.7143 - val_loss: 1.5162 - val_acc: 0.5300\nEpoch 202/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8732 - acc: 0.7100 - val_loss: 1.5306 - val_acc: 0.5267\nEpoch 203/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8711 - acc: 0.7057 - val_loss: 1.5491 - val_acc: 0.5333\nEpoch 204/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.8677 - acc: 0.7114 - val_loss: 1.5257 - val_acc: 0.5233\nEpoch 205/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8687 - acc: 0.7086 - val_loss: 1.5324 - val_acc: 0.5533\nEpoch 206/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8652 - acc: 0.7114 - val_loss: 1.5308 - val_acc: 0.5433\nEpoch 207/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8665 - acc: 0.7000 - val_loss: 1.5354 - val_acc: 0.5367\nEpoch 208/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8601 - acc: 0.7114 - val_loss: 1.5522 - val_acc: 0.5233\nEpoch 209/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8610 - acc: 0.7186 - val_loss: 1.5548 - val_acc: 0.5333\nEpoch 210/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8620 - acc: 0.7171 - val_loss: 1.5347 - val_acc: 0.5300\nEpoch 211/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8603 - acc: 0.7229 - val_loss: 1.5706 - val_acc: 0.5333\nEpoch 212/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8580 - acc: 0.7129 - val_loss: 1.5311 - val_acc: 0.5500\nEpoch 213/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8566 - acc: 0.7143 - val_loss: 1.5442 - val_acc: 0.5267\nEpoch 214/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8548 - acc: 0.7186 - val_loss: 1.5369 - val_acc: 0.5333\nEpoch 215/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8558 - acc: 0.7214 - val_loss: 1.5537 - val_acc: 0.5400\nEpoch 216/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8531 - acc: 0.7229 - val_loss: 1.5474 - val_acc: 0.5533\nEpoch 217/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8476 - acc: 0.7229 - val_loss: 1.5425 - val_acc: 0.5367\nEpoch 218/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8489 - acc: 0.7200 - val_loss: 1.5647 - val_acc: 0.5467\nEpoch 219/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8474 - acc: 0.7157 - val_loss: 1.5596 - val_acc: 0.5367\nEpoch 220/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.8482 - acc: 0.7357 - val_loss: 1.5471 - val_acc: 0.5467\nEpoch 221/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.8447 - acc: 0.7243 - val_loss: 1.5774 - val_acc: 0.5500\nEpoch 222/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.8412 - acc: 0.7243 - val_loss: 1.5487 - val_acc: 0.5433\nEpoch 223/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.8402 - acc: 0.7186 - val_loss: 1.5396 - val_acc: 0.5433\nEpoch 224/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.8404 - acc: 0.7257 - val_loss: 1.5619 - val_acc: 0.5467\nEpoch 225/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.8380 - acc: 0.7143 - val_loss: 1.5515 - val_acc: 0.5500\nEpoch 226/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8391 - acc: 0.7371 - val_loss: 1.5611 - val_acc: 0.5567\nEpoch 227/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8335 - acc: 0.7400 - val_loss: 1.5594 - val_acc: 0.5367\nEpoch 228/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.8316 - acc: 0.7357 - val_loss: 1.5948 - val_acc: 0.5300\nEpoch 229/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8308 - acc: 0.7386 - val_loss: 1.5649 - val_acc: 0.5433\nEpoch 230/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8342 - acc: 0.7386 - val_loss: 1.5715 - val_acc: 0.5567\nEpoch 231/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8272 - acc: 0.7414 - val_loss: 1.5675 - val_acc: 0.5333\nEpoch 232/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8313 - acc: 0.7257 - val_loss: 1.5464 - val_acc: 0.5500\nEpoch 233/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8297 - acc: 0.7429 - val_loss: 1.5806 - val_acc: 0.5300\nEpoch 234/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8279 - acc: 0.7343 - val_loss: 1.5657 - val_acc: 0.5500\nEpoch 235/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8239 - acc: 0.7471 - val_loss: 1.5639 - val_acc: 0.5333\nEpoch 236/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8241 - acc: 0.7243 - val_loss: 1.5688 - val_acc: 0.5400\nEpoch 237/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8214 - acc: 0.7500 - val_loss: 1.5894 - val_acc: 0.5400\nEpoch 238/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8230 - acc: 0.7271 - val_loss: 1.5608 - val_acc: 0.5567\nEpoch 239/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8217 - acc: 0.7286 - val_loss: 1.5762 - val_acc: 0.5433\nEpoch 240/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8192 - acc: 0.7257 - val_loss: 1.5938 - val_acc: 0.5600\nEpoch 241/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8196 - acc: 0.7443 - val_loss: 1.5877 - val_acc: 0.5600\nEpoch 242/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.8169 - acc: 0.7343 - val_loss: 1.5646 - val_acc: 0.5600\nEpoch 243/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8147 - acc: 0.7400 - val_loss: 1.5846 - val_acc: 0.5367\nEpoch 244/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8164 - acc: 0.7486 - val_loss: 1.5732 - val_acc: 0.5567\nEpoch 245/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.8144 - acc: 0.7386 - val_loss: 1.5775 - val_acc: 0.5600\nEpoch 246/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8134 - acc: 0.7471 - val_loss: 1.5752 - val_acc: 0.5500\nEpoch 247/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8072 - acc: 0.7414 - val_loss: 1.5690 - val_acc: 0.5367\nEpoch 248/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8133 - acc: 0.7357 - val_loss: 1.5787 - val_acc: 0.5367\nEpoch 249/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.8091 - acc: 0.7514 - val_loss: 1.5756 - val_acc: 0.5500\nEpoch 250/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8056 - acc: 0.7514 - val_loss: 1.5857 - val_acc: 0.5433\nEpoch 251/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8086 - acc: 0.7357 - val_loss: 1.5754 - val_acc: 0.5500\nEpoch 252/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8060 - acc: 0.7529 - val_loss: 1.5685 - val_acc: 0.5433\nEpoch 253/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.8047 - acc: 0.7514 - val_loss: 1.5836 - val_acc: 0.5400\nEpoch 254/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8040 - acc: 0.7414 - val_loss: 1.5898 - val_acc: 0.5533\nEpoch 255/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.8032 - acc: 0.7429 - val_loss: 1.5864 - val_acc: 0.5433\nEpoch 256/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.8010 - acc: 0.7500 - val_loss: 1.6012 - val_acc: 0.5533\nEpoch 257/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7992 - acc: 0.7414 - val_loss: 1.5963 - val_acc: 0.5500\nEpoch 258/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7989 - acc: 0.7457 - val_loss: 1.5882 - val_acc: 0.5467\nEpoch 259/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7954 - acc: 0.7614 - val_loss: 1.6359 - val_acc: 0.5433\nEpoch 260/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7926 - acc: 0.7500 - val_loss: 1.6037 - val_acc: 0.5267\nEpoch 261/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.7958 - acc: 0.7471 - val_loss: 1.6123 - val_acc: 0.5367\nEpoch 262/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.7902 - acc: 0.7700 - val_loss: 1.6206 - val_acc: 0.5533\nEpoch 263/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7900 - acc: 0.7414 - val_loss: 1.6169 - val_acc: 0.5467\nEpoch 264/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7929 - acc: 0.7486 - val_loss: 1.5983 - val_acc: 0.5433\nEpoch 265/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7879 - acc: 0.7643 - val_loss: 1.6048 - val_acc: 0.5367\nEpoch 266/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7845 - acc: 0.7671 - val_loss: 1.5950 - val_acc: 0.5500\nEpoch 267/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.7887 - acc: 0.7514 - val_loss: 1.6001 - val_acc: 0.5500\nEpoch 268/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7873 - acc: 0.7586 - val_loss: 1.6047 - val_acc: 0.5333\nEpoch 269/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7873 - acc: 0.7443 - val_loss: 1.6212 - val_acc: 0.5500\nEpoch 270/1000\n700/700 [==============================] - 0s 127us/sample - loss: 0.7841 - acc: 0.7543 - val_loss: 1.6015 - val_acc: 0.5433\nEpoch 271/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.7833 - acc: 0.7443 - val_loss: 1.6188 - val_acc: 0.5467\nEpoch 272/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.7810 - acc: 0.7643 - val_loss: 1.6131 - val_acc: 0.5433\nEpoch 273/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7818 - acc: 0.7557 - val_loss: 1.6300 - val_acc: 0.5300\nEpoch 274/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.7791 - acc: 0.7629 - val_loss: 1.6189 - val_acc: 0.5500\nEpoch 275/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.7802 - acc: 0.7514 - val_loss: 1.6200 - val_acc: 0.5433\nEpoch 276/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.7775 - acc: 0.7514 - val_loss: 1.6227 - val_acc: 0.5433\nEpoch 277/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7731 - acc: 0.7586 - val_loss: 1.6182 - val_acc: 0.5433\nEpoch 278/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7730 - acc: 0.7529 - val_loss: 1.6353 - val_acc: 0.5400\nEpoch 279/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7795 - acc: 0.7571 - val_loss: 1.6385 - val_acc: 0.5433\nEpoch 280/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7746 - acc: 0.7629 - val_loss: 1.6509 - val_acc: 0.5400\nEpoch 281/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7708 - acc: 0.7543 - val_loss: 1.6398 - val_acc: 0.5467\nEpoch 282/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7732 - acc: 0.7543 - val_loss: 1.6531 - val_acc: 0.5500\nEpoch 283/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.7738 - acc: 0.7686 - val_loss: 1.6393 - val_acc: 0.5433\nEpoch 284/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7703 - acc: 0.7586 - val_loss: 1.6295 - val_acc: 0.5433\nEpoch 285/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7694 - acc: 0.7586 - val_loss: 1.6258 - val_acc: 0.5467\nEpoch 286/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7679 - acc: 0.7643 - val_loss: 1.6297 - val_acc: 0.5300\nEpoch 287/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7686 - acc: 0.7600 - val_loss: 1.6257 - val_acc: 0.5433\nEpoch 288/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7656 - acc: 0.7529 - val_loss: 1.6377 - val_acc: 0.5367\nEpoch 289/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7671 - acc: 0.7471 - val_loss: 1.6314 - val_acc: 0.5467\nEpoch 290/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7661 - acc: 0.7643 - val_loss: 1.6242 - val_acc: 0.5333\nEpoch 291/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7626 - acc: 0.7529 - val_loss: 1.6253 - val_acc: 0.5367\nEpoch 292/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7610 - acc: 0.7657 - val_loss: 1.6576 - val_acc: 0.5500\nEpoch 293/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7638 - acc: 0.7643 - val_loss: 1.6483 - val_acc: 0.5367\nEpoch 294/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7616 - acc: 0.7600 - val_loss: 1.6590 - val_acc: 0.5400\nEpoch 295/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7578 - acc: 0.7600 - val_loss: 1.6639 - val_acc: 0.5500\nEpoch 296/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7559 - acc: 0.7743 - val_loss: 1.6490 - val_acc: 0.5467\nEpoch 297/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7561 - acc: 0.7614 - val_loss: 1.6688 - val_acc: 0.5467\nEpoch 298/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7551 - acc: 0.7686 - val_loss: 1.6503 - val_acc: 0.5267\nEpoch 299/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7570 - acc: 0.7629 - val_loss: 1.6522 - val_acc: 0.5367\nEpoch 300/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7546 - acc: 0.7729 - val_loss: 1.6499 - val_acc: 0.5300\nEpoch 301/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.7516 - acc: 0.7757 - val_loss: 1.6574 - val_acc: 0.5433\nEpoch 302/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7504 - acc: 0.7771 - val_loss: 1.6565 - val_acc: 0.5333\nEpoch 303/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7491 - acc: 0.7643 - val_loss: 1.6649 - val_acc: 0.5467\nEpoch 304/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7517 - acc: 0.7600 - val_loss: 1.6546 - val_acc: 0.5500\nEpoch 305/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7472 - acc: 0.7629 - val_loss: 1.6647 - val_acc: 0.5367\nEpoch 306/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7490 - acc: 0.7600 - val_loss: 1.6790 - val_acc: 0.5433\nEpoch 307/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7463 - acc: 0.7600 - val_loss: 1.6740 - val_acc: 0.5400\nEpoch 308/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7471 - acc: 0.7600 - val_loss: 1.6599 - val_acc: 0.5433\nEpoch 309/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7467 - acc: 0.7671 - val_loss: 1.6720 - val_acc: 0.5567\nEpoch 310/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7476 - acc: 0.7486 - val_loss: 1.6804 - val_acc: 0.5500\nEpoch 311/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7436 - acc: 0.7629 - val_loss: 1.6641 - val_acc: 0.5367\nEpoch 312/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7441 - acc: 0.7614 - val_loss: 1.6506 - val_acc: 0.5467\nEpoch 313/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7395 - acc: 0.7686 - val_loss: 1.6443 - val_acc: 0.5400\nEpoch 314/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7427 - acc: 0.7700 - val_loss: 1.6666 - val_acc: 0.5533\nEpoch 315/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7418 - acc: 0.7671 - val_loss: 1.6752 - val_acc: 0.5500\nEpoch 316/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7391 - acc: 0.7743 - val_loss: 1.6646 - val_acc: 0.5233\nEpoch 317/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.7394 - acc: 0.7657 - val_loss: 1.6945 - val_acc: 0.5400\nEpoch 318/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7407 - acc: 0.7614 - val_loss: 1.6680 - val_acc: 0.5400\nEpoch 319/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7393 - acc: 0.7643 - val_loss: 1.6649 - val_acc: 0.5300\nEpoch 320/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7361 - acc: 0.7686 - val_loss: 1.6759 - val_acc: 0.5467\nEpoch 321/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.7386 - acc: 0.7700 - val_loss: 1.6752 - val_acc: 0.5533\nEpoch 322/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7359 - acc: 0.7800 - val_loss: 1.6801 - val_acc: 0.5400\nEpoch 323/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7319 - acc: 0.7757 - val_loss: 1.6882 - val_acc: 0.5433\nEpoch 324/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.7347 - acc: 0.7743 - val_loss: 1.7055 - val_acc: 0.5433\nEpoch 325/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.7289 - acc: 0.7757 - val_loss: 1.6872 - val_acc: 0.5300\nEpoch 326/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7300 - acc: 0.7771 - val_loss: 1.6755 - val_acc: 0.5467\nEpoch 327/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.7304 - acc: 0.7671 - val_loss: 1.6956 - val_acc: 0.5433\nEpoch 328/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.7305 - acc: 0.7743 - val_loss: 1.6757 - val_acc: 0.5300\nEpoch 329/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.7271 - acc: 0.7686 - val_loss: 1.6809 - val_acc: 0.5267\nEpoch 330/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.7309 - acc: 0.7686 - val_loss: 1.6715 - val_acc: 0.5467\nEpoch 331/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.7229 - acc: 0.7786 - val_loss: 1.7013 - val_acc: 0.5367\nEpoch 332/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.7255 - acc: 0.7729 - val_loss: 1.6900 - val_acc: 0.5133\nEpoch 333/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.7249 - acc: 0.7671 - val_loss: 1.6834 - val_acc: 0.5200\nEpoch 334/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7200 - acc: 0.7700 - val_loss: 1.7230 - val_acc: 0.5400\nEpoch 335/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7248 - acc: 0.7786 - val_loss: 1.7124 - val_acc: 0.5433\nEpoch 336/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7234 - acc: 0.7743 - val_loss: 1.7049 - val_acc: 0.5433\nEpoch 337/1000\n700/700 [==============================] - 0s 118us/sample - loss: 0.7188 - acc: 0.7714 - val_loss: 1.7408 - val_acc: 0.5300\nEpoch 338/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7199 - acc: 0.7686 - val_loss: 1.7086 - val_acc: 0.5367\nEpoch 339/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.7183 - acc: 0.7843 - val_loss: 1.7096 - val_acc: 0.5267\nEpoch 340/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.7189 - acc: 0.7729 - val_loss: 1.7111 - val_acc: 0.5400\nEpoch 341/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.7185 - acc: 0.7671 - val_loss: 1.7461 - val_acc: 0.5333\nEpoch 342/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7165 - acc: 0.7786 - val_loss: 1.7264 - val_acc: 0.5433\nEpoch 343/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.7196 - acc: 0.7700 - val_loss: 1.7222 - val_acc: 0.5400\nEpoch 344/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.7156 - acc: 0.7786 - val_loss: 1.7209 - val_acc: 0.5367\nEpoch 345/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.7117 - acc: 0.7743 - val_loss: 1.7147 - val_acc: 0.5433\nEpoch 346/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.7126 - acc: 0.7729 - val_loss: 1.7102 - val_acc: 0.5367\nEpoch 347/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.7079 - acc: 0.7729 - val_loss: 1.7321 - val_acc: 0.5267\nEpoch 348/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.7118 - acc: 0.7771 - val_loss: 1.7168 - val_acc: 0.5267\nEpoch 349/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.7072 - acc: 0.7814 - val_loss: 1.7323 - val_acc: 0.5267\nEpoch 350/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7072 - acc: 0.7929 - val_loss: 1.7222 - val_acc: 0.5433\nEpoch 351/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7082 - acc: 0.7714 - val_loss: 1.7396 - val_acc: 0.5367\nEpoch 352/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7070 - acc: 0.7757 - val_loss: 1.7481 - val_acc: 0.5333\nEpoch 353/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.7061 - acc: 0.7800 - val_loss: 1.7318 - val_acc: 0.5333\nEpoch 354/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.7078 - acc: 0.7857 - val_loss: 1.7357 - val_acc: 0.5333\nEpoch 355/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7049 - acc: 0.7829 - val_loss: 1.7192 - val_acc: 0.5433\nEpoch 356/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.7046 - acc: 0.7800 - val_loss: 1.7118 - val_acc: 0.5300\nEpoch 357/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.7044 - acc: 0.7700 - val_loss: 1.7233 - val_acc: 0.5400\nEpoch 358/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.7005 - acc: 0.7857 - val_loss: 1.7203 - val_acc: 0.5367\nEpoch 359/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.7002 - acc: 0.7800 - val_loss: 1.7503 - val_acc: 0.5367\nEpoch 360/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6999 - acc: 0.7814 - val_loss: 1.7411 - val_acc: 0.5433\nEpoch 361/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.6997 - acc: 0.7786 - val_loss: 1.7367 - val_acc: 0.5367\nEpoch 362/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.6985 - acc: 0.7786 - val_loss: 1.7560 - val_acc: 0.5367\nEpoch 363/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.6941 - acc: 0.7914 - val_loss: 1.7321 - val_acc: 0.5467\nEpoch 364/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6947 - acc: 0.7857 - val_loss: 1.7450 - val_acc: 0.5267\nEpoch 365/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6956 - acc: 0.7900 - val_loss: 1.7374 - val_acc: 0.5367\nEpoch 366/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6944 - acc: 0.7786 - val_loss: 1.7796 - val_acc: 0.5400\nEpoch 367/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6944 - acc: 0.7743 - val_loss: 1.7487 - val_acc: 0.5433\nEpoch 368/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.6919 - acc: 0.7829 - val_loss: 1.7398 - val_acc: 0.5300\nEpoch 369/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.6924 - acc: 0.7771 - val_loss: 1.7639 - val_acc: 0.5400\nEpoch 370/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.6928 - acc: 0.7900 - val_loss: 1.7533 - val_acc: 0.5433\nEpoch 371/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.6884 - acc: 0.7886 - val_loss: 1.7565 - val_acc: 0.5433\nEpoch 372/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.6904 - acc: 0.7800 - val_loss: 1.7640 - val_acc: 0.5400\nEpoch 373/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.6902 - acc: 0.7814 - val_loss: 1.7582 - val_acc: 0.5333\nEpoch 374/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.6883 - acc: 0.7800 - val_loss: 1.7595 - val_acc: 0.5233\nEpoch 375/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6852 - acc: 0.7914 - val_loss: 1.7975 - val_acc: 0.5267\nEpoch 376/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6876 - acc: 0.7800 - val_loss: 1.7930 - val_acc: 0.5433\nEpoch 377/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.6875 - acc: 0.7786 - val_loss: 1.7996 - val_acc: 0.5367\nEpoch 378/1000\n700/700 [==============================] - 0s 121us/sample - loss: 0.6834 - acc: 0.7757 - val_loss: 1.7471 - val_acc: 0.5200\nEpoch 379/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.6828 - acc: 0.7914 - val_loss: 1.7825 - val_acc: 0.5300\nEpoch 380/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6817 - acc: 0.7814 - val_loss: 1.7906 - val_acc: 0.5267\nEpoch 381/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6823 - acc: 0.7800 - val_loss: 1.7776 - val_acc: 0.5400\nEpoch 382/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6797 - acc: 0.7786 - val_loss: 1.7888 - val_acc: 0.5300\nEpoch 383/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6792 - acc: 0.7886 - val_loss: 1.7920 - val_acc: 0.5133\nEpoch 384/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6810 - acc: 0.7829 - val_loss: 1.7819 - val_acc: 0.5300\nEpoch 385/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6781 - acc: 0.7814 - val_loss: 1.7797 - val_acc: 0.5300\nEpoch 386/1000\n700/700 [==============================] - 0s 130us/sample - loss: 0.6767 - acc: 0.7929 - val_loss: 1.7944 - val_acc: 0.5367\nEpoch 387/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.6784 - acc: 0.7900 - val_loss: 1.7908 - val_acc: 0.5300\nEpoch 388/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.6762 - acc: 0.7900 - val_loss: 1.7641 - val_acc: 0.5267\nEpoch 389/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6761 - acc: 0.7829 - val_loss: 1.7983 - val_acc: 0.5333\nEpoch 390/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.6740 - acc: 0.7757 - val_loss: 1.7860 - val_acc: 0.5500\nEpoch 391/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.6725 - acc: 0.7800 - val_loss: 1.7816 - val_acc: 0.5200\nEpoch 392/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.6725 - acc: 0.7843 - val_loss: 1.7669 - val_acc: 0.5167\nEpoch 393/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6720 - acc: 0.7886 - val_loss: 1.7763 - val_acc: 0.5167\nEpoch 394/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6722 - acc: 0.7957 - val_loss: 1.7815 - val_acc: 0.5200\nEpoch 395/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.6712 - acc: 0.7871 - val_loss: 1.7861 - val_acc: 0.5300\nEpoch 396/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.6698 - acc: 0.7886 - val_loss: 1.8042 - val_acc: 0.5267\nEpoch 397/1000\n700/700 [==============================] - 0s 147us/sample - loss: 0.6683 - acc: 0.7929 - val_loss: 1.7825 - val_acc: 0.5267\nEpoch 398/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.6650 - acc: 0.7929 - val_loss: 1.8259 - val_acc: 0.5267\nEpoch 399/1000\n700/700 [==============================] - 0s 168us/sample - loss: 0.6664 - acc: 0.7914 - val_loss: 1.7830 - val_acc: 0.5267\nEpoch 400/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6651 - acc: 0.7943 - val_loss: 1.8090 - val_acc: 0.5167\nEpoch 401/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6644 - acc: 0.7971 - val_loss: 1.8253 - val_acc: 0.5200\nEpoch 402/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6654 - acc: 0.7857 - val_loss: 1.8129 - val_acc: 0.5300\nEpoch 403/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6645 - acc: 0.7957 - val_loss: 1.8136 - val_acc: 0.5333\nEpoch 404/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.6623 - acc: 0.8000 - val_loss: 1.8106 - val_acc: 0.5133\nEpoch 405/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.6645 - acc: 0.7929 - val_loss: 1.8025 - val_acc: 0.5267\nEpoch 406/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6600 - acc: 0.7971 - val_loss: 1.8035 - val_acc: 0.5367\nEpoch 407/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6624 - acc: 0.7871 - val_loss: 1.8161 - val_acc: 0.5200\nEpoch 408/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6604 - acc: 0.7814 - val_loss: 1.8103 - val_acc: 0.5267\nEpoch 409/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.6583 - acc: 0.7943 - val_loss: 1.8162 - val_acc: 0.5333\nEpoch 410/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.6589 - acc: 0.7943 - val_loss: 1.8081 - val_acc: 0.5133\nEpoch 411/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.6586 - acc: 0.7943 - val_loss: 1.8026 - val_acc: 0.5167\nEpoch 412/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.6596 - acc: 0.7929 - val_loss: 1.8402 - val_acc: 0.5233\nEpoch 413/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.6610 - acc: 0.7914 - val_loss: 1.8284 - val_acc: 0.5267\nEpoch 414/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6570 - acc: 0.7914 - val_loss: 1.8522 - val_acc: 0.5233\nEpoch 415/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6529 - acc: 0.7971 - val_loss: 1.8210 - val_acc: 0.5167\nEpoch 416/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6560 - acc: 0.7943 - val_loss: 1.8169 - val_acc: 0.5067\nEpoch 417/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6550 - acc: 0.7943 - val_loss: 1.8252 - val_acc: 0.5267\nEpoch 418/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6516 - acc: 0.7914 - val_loss: 1.8223 - val_acc: 0.4933\nEpoch 419/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.6550 - acc: 0.7943 - val_loss: 1.8479 - val_acc: 0.5200\nEpoch 420/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6486 - acc: 0.8014 - val_loss: 1.8257 - val_acc: 0.5167\nEpoch 421/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6520 - acc: 0.7957 - val_loss: 1.8258 - val_acc: 0.5233\nEpoch 422/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6523 - acc: 0.7943 - val_loss: 1.8377 - val_acc: 0.5233\nEpoch 423/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6495 - acc: 0.7900 - val_loss: 1.8267 - val_acc: 0.5300\nEpoch 424/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6483 - acc: 0.7971 - val_loss: 1.8353 - val_acc: 0.5333\nEpoch 425/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.6480 - acc: 0.7986 - val_loss: 1.8454 - val_acc: 0.5200\nEpoch 426/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.6479 - acc: 0.7957 - val_loss: 1.8401 - val_acc: 0.5233\nEpoch 427/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6464 - acc: 0.7986 - val_loss: 1.8637 - val_acc: 0.5367\nEpoch 428/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.6459 - acc: 0.8014 - val_loss: 1.8449 - val_acc: 0.5133\nEpoch 429/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6459 - acc: 0.7986 - val_loss: 1.8617 - val_acc: 0.5233\nEpoch 430/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.6449 - acc: 0.8057 - val_loss: 1.8552 - val_acc: 0.5267\nEpoch 431/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6429 - acc: 0.8100 - val_loss: 1.8431 - val_acc: 0.5233\nEpoch 432/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6479 - acc: 0.7943 - val_loss: 1.8501 - val_acc: 0.5133\nEpoch 433/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6423 - acc: 0.7971 - val_loss: 1.8312 - val_acc: 0.5167\nEpoch 434/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.6433 - acc: 0.7900 - val_loss: 1.8639 - val_acc: 0.5233\nEpoch 435/1000\n700/700 [==============================] - 0s 130us/sample - loss: 0.6385 - acc: 0.8086 - val_loss: 1.8470 - val_acc: 0.5267\nEpoch 436/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6405 - acc: 0.7871 - val_loss: 1.8486 - val_acc: 0.5167\nEpoch 437/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.6413 - acc: 0.7929 - val_loss: 1.8719 - val_acc: 0.5200\nEpoch 438/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.6390 - acc: 0.8057 - val_loss: 1.8721 - val_acc: 0.5167\nEpoch 439/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6364 - acc: 0.8100 - val_loss: 1.8584 - val_acc: 0.5267\nEpoch 440/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.6380 - acc: 0.8043 - val_loss: 1.9255 - val_acc: 0.5167\nEpoch 441/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6397 - acc: 0.8043 - val_loss: 1.8970 - val_acc: 0.5300\nEpoch 442/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6364 - acc: 0.8043 - val_loss: 1.9083 - val_acc: 0.5233\nEpoch 443/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6361 - acc: 0.8143 - val_loss: 1.8632 - val_acc: 0.5200\nEpoch 444/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.6368 - acc: 0.8029 - val_loss: 1.9114 - val_acc: 0.5300\nEpoch 445/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.6350 - acc: 0.8086 - val_loss: 1.8575 - val_acc: 0.5200\nEpoch 446/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.6362 - acc: 0.8129 - val_loss: 1.8778 - val_acc: 0.5167\nEpoch 447/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6336 - acc: 0.8129 - val_loss: 1.8901 - val_acc: 0.5033\nEpoch 448/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6307 - acc: 0.7986 - val_loss: 1.9009 - val_acc: 0.5267\nEpoch 449/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.6318 - acc: 0.8029 - val_loss: 1.8683 - val_acc: 0.5067\nEpoch 450/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6325 - acc: 0.7971 - val_loss: 1.8857 - val_acc: 0.5133\nEpoch 451/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6289 - acc: 0.8057 - val_loss: 1.9193 - val_acc: 0.5167\nEpoch 452/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6325 - acc: 0.8129 - val_loss: 1.8867 - val_acc: 0.5100\nEpoch 453/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.6291 - acc: 0.8071 - val_loss: 1.8879 - val_acc: 0.5167\nEpoch 454/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6296 - acc: 0.8043 - val_loss: 1.9147 - val_acc: 0.5167\nEpoch 455/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6291 - acc: 0.8057 - val_loss: 1.9163 - val_acc: 0.5100\nEpoch 456/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6244 - acc: 0.8114 - val_loss: 1.8935 - val_acc: 0.5100\nEpoch 457/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6258 - acc: 0.8157 - val_loss: 1.8975 - val_acc: 0.5067\nEpoch 458/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6297 - acc: 0.8043 - val_loss: 1.8920 - val_acc: 0.5000\nEpoch 459/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6244 - acc: 0.8100 - val_loss: 1.8911 - val_acc: 0.5100\nEpoch 460/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6273 - acc: 0.8014 - val_loss: 1.8837 - val_acc: 0.5167\nEpoch 461/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6262 - acc: 0.8086 - val_loss: 1.8891 - val_acc: 0.5067\nEpoch 462/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.6227 - acc: 0.8157 - val_loss: 1.8834 - val_acc: 0.5167\nEpoch 463/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.6235 - acc: 0.8114 - val_loss: 1.9019 - val_acc: 0.5233\nEpoch 464/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.6220 - acc: 0.8171 - val_loss: 1.9218 - val_acc: 0.5200\nEpoch 465/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.6215 - acc: 0.8143 - val_loss: 1.8868 - val_acc: 0.5167\nEpoch 466/1000\n700/700 [==============================] - 0s 144us/sample - loss: 0.6219 - acc: 0.8186 - val_loss: 1.9157 - val_acc: 0.5133\nEpoch 467/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.6197 - acc: 0.8100 - val_loss: 1.9157 - val_acc: 0.4967\nEpoch 468/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6194 - acc: 0.8157 - val_loss: 1.9119 - val_acc: 0.5033\nEpoch 469/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6178 - acc: 0.8129 - val_loss: 1.9109 - val_acc: 0.5133\nEpoch 470/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.6170 - acc: 0.8214 - val_loss: 1.9392 - val_acc: 0.5233\nEpoch 471/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.6175 - acc: 0.8100 - val_loss: 1.9157 - val_acc: 0.5133\nEpoch 472/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.6187 - acc: 0.8157 - val_loss: 1.9133 - val_acc: 0.5000\nEpoch 473/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.6174 - acc: 0.8157 - val_loss: 1.9155 - val_acc: 0.5133\nEpoch 474/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.6189 - acc: 0.8029 - val_loss: 1.9149 - val_acc: 0.5000\nEpoch 475/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.6149 - acc: 0.8214 - val_loss: 1.9254 - val_acc: 0.5167\nEpoch 476/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.6125 - acc: 0.8100 - val_loss: 1.9288 - val_acc: 0.5167\nEpoch 477/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6169 - acc: 0.8129 - val_loss: 1.9234 - val_acc: 0.4967\nEpoch 478/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6113 - acc: 0.8214 - val_loss: 1.9166 - val_acc: 0.5067\nEpoch 479/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6146 - acc: 0.8100 - val_loss: 1.9434 - val_acc: 0.5100\nEpoch 480/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.6128 - acc: 0.8157 - val_loss: 1.9332 - val_acc: 0.5100\nEpoch 481/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.6147 - acc: 0.8186 - val_loss: 1.9293 - val_acc: 0.5100\nEpoch 482/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.6117 - acc: 0.8200 - val_loss: 1.9447 - val_acc: 0.5133\nEpoch 483/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.6100 - acc: 0.8086 - val_loss: 1.9545 - val_acc: 0.5000\nEpoch 484/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.6101 - acc: 0.8200 - val_loss: 1.9694 - val_acc: 0.4967\nEpoch 485/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6078 - acc: 0.8186 - val_loss: 1.9408 - val_acc: 0.4933\nEpoch 486/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6078 - acc: 0.8257 - val_loss: 1.9549 - val_acc: 0.5067\nEpoch 487/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6049 - acc: 0.8286 - val_loss: 1.9348 - val_acc: 0.5033\nEpoch 488/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.6064 - acc: 0.8186 - val_loss: 1.9450 - val_acc: 0.5067\nEpoch 489/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.6046 - acc: 0.8229 - val_loss: 1.9432 - val_acc: 0.5067\nEpoch 490/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6058 - acc: 0.8186 - val_loss: 1.9452 - val_acc: 0.5100\nEpoch 491/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.6042 - acc: 0.8129 - val_loss: 1.9365 - val_acc: 0.4900\nEpoch 492/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6056 - acc: 0.8043 - val_loss: 1.9504 - val_acc: 0.5000\nEpoch 493/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.6033 - acc: 0.8186 - val_loss: 1.9796 - val_acc: 0.5100\nEpoch 494/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6026 - acc: 0.8157 - val_loss: 1.9658 - val_acc: 0.4933\nEpoch 495/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.6031 - acc: 0.8243 - val_loss: 1.9543 - val_acc: 0.5100\nEpoch 496/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5998 - acc: 0.8243 - val_loss: 1.9625 - val_acc: 0.5100\nEpoch 497/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5988 - acc: 0.8229 - val_loss: 1.9764 - val_acc: 0.4967\nEpoch 498/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.6047 - acc: 0.8286 - val_loss: 1.9621 - val_acc: 0.4900\nEpoch 499/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5979 - acc: 0.8229 - val_loss: 1.9474 - val_acc: 0.5133\nEpoch 500/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.5980 - acc: 0.8157 - val_loss: 1.9661 - val_acc: 0.5067\nEpoch 501/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.5987 - acc: 0.8171 - val_loss: 1.9755 - val_acc: 0.4900\nEpoch 502/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5961 - acc: 0.8300 - val_loss: 1.9751 - val_acc: 0.5000\nEpoch 503/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5984 - acc: 0.8257 - val_loss: 1.9616 - val_acc: 0.5067\nEpoch 504/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5985 - acc: 0.8186 - val_loss: 1.9796 - val_acc: 0.4967\nEpoch 505/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5988 - acc: 0.8200 - val_loss: 1.9762 - val_acc: 0.5033\nEpoch 506/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5939 - acc: 0.8271 - val_loss: 1.9794 - val_acc: 0.5067\nEpoch 507/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.5969 - acc: 0.8157 - val_loss: 1.9758 - val_acc: 0.4933\nEpoch 508/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5946 - acc: 0.8229 - val_loss: 1.9708 - val_acc: 0.5033\nEpoch 509/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5947 - acc: 0.8257 - val_loss: 1.9754 - val_acc: 0.5033\nEpoch 510/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5930 - acc: 0.8200 - val_loss: 1.9988 - val_acc: 0.5000\nEpoch 511/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5930 - acc: 0.8243 - val_loss: 1.9925 - val_acc: 0.4900\nEpoch 512/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5936 - acc: 0.8243 - val_loss: 1.9823 - val_acc: 0.5033\nEpoch 513/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5882 - acc: 0.8257 - val_loss: 1.9932 - val_acc: 0.5100\nEpoch 514/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5936 - acc: 0.8171 - val_loss: 1.9948 - val_acc: 0.4967\nEpoch 515/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5895 - acc: 0.8271 - val_loss: 1.9886 - val_acc: 0.5067\nEpoch 516/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5899 - acc: 0.8257 - val_loss: 1.9899 - val_acc: 0.4867\nEpoch 517/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5890 - acc: 0.8271 - val_loss: 1.9963 - val_acc: 0.4900\nEpoch 518/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.5881 - acc: 0.8271 - val_loss: 2.0114 - val_acc: 0.4967\nEpoch 519/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5892 - acc: 0.8343 - val_loss: 2.0009 - val_acc: 0.4867\nEpoch 520/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5882 - acc: 0.8286 - val_loss: 1.9907 - val_acc: 0.4900\nEpoch 521/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5892 - acc: 0.8214 - val_loss: 2.0030 - val_acc: 0.4867\nEpoch 522/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.5857 - acc: 0.8257 - val_loss: 2.0270 - val_acc: 0.5000\nEpoch 523/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5883 - acc: 0.8257 - val_loss: 2.0115 - val_acc: 0.4900\nEpoch 524/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5854 - acc: 0.8314 - val_loss: 2.0246 - val_acc: 0.4967\nEpoch 525/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5836 - acc: 0.8329 - val_loss: 2.0249 - val_acc: 0.5033\nEpoch 526/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5840 - acc: 0.8271 - val_loss: 2.0109 - val_acc: 0.5000\nEpoch 527/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.5826 - acc: 0.8243 - val_loss: 2.0136 - val_acc: 0.4933\nEpoch 528/1000\n700/700 [==============================] - 0s 113us/sample - loss: 0.5837 - acc: 0.8257 - val_loss: 2.0165 - val_acc: 0.4900\nEpoch 529/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5803 - acc: 0.8257 - val_loss: 2.0091 - val_acc: 0.4967\nEpoch 530/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5802 - acc: 0.8329 - val_loss: 1.9905 - val_acc: 0.4900\nEpoch 531/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5823 - acc: 0.8271 - val_loss: 2.0151 - val_acc: 0.5000\nEpoch 532/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5784 - acc: 0.8271 - val_loss: 2.0218 - val_acc: 0.4867\nEpoch 533/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5798 - acc: 0.8271 - val_loss: 2.0000 - val_acc: 0.4900\nEpoch 534/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5770 - acc: 0.8257 - val_loss: 2.0446 - val_acc: 0.5000\nEpoch 535/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5772 - acc: 0.8314 - val_loss: 2.0172 - val_acc: 0.4867\nEpoch 536/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5798 - acc: 0.8257 - val_loss: 2.0199 - val_acc: 0.4933\nEpoch 537/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5756 - acc: 0.8329 - val_loss: 2.0187 - val_acc: 0.5033\nEpoch 538/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5779 - acc: 0.8214 - val_loss: 2.0357 - val_acc: 0.4833\nEpoch 539/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5767 - acc: 0.8329 - val_loss: 2.0192 - val_acc: 0.4900\nEpoch 540/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5766 - acc: 0.8314 - val_loss: 2.0152 - val_acc: 0.4967\nEpoch 541/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.5760 - acc: 0.8314 - val_loss: 2.0290 - val_acc: 0.4967\nEpoch 542/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.5753 - acc: 0.8400 - val_loss: 2.0491 - val_acc: 0.4900\nEpoch 543/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.5740 - acc: 0.8329 - val_loss: 2.0476 - val_acc: 0.4900\nEpoch 544/1000\n700/700 [==============================] - 0s 137us/sample - loss: 0.5732 - acc: 0.8343 - val_loss: 2.0258 - val_acc: 0.4867\nEpoch 545/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5730 - acc: 0.8271 - val_loss: 2.0335 - val_acc: 0.4867\nEpoch 546/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.5718 - acc: 0.8314 - val_loss: 2.0285 - val_acc: 0.4933\nEpoch 547/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.5715 - acc: 0.8357 - val_loss: 2.0385 - val_acc: 0.4967\nEpoch 548/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5724 - acc: 0.8271 - val_loss: 2.0366 - val_acc: 0.4967\nEpoch 549/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.5724 - acc: 0.8257 - val_loss: 2.0394 - val_acc: 0.5067\nEpoch 550/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5716 - acc: 0.8343 - val_loss: 2.0434 - val_acc: 0.5033\nEpoch 551/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5684 - acc: 0.8371 - val_loss: 2.0566 - val_acc: 0.4867\nEpoch 552/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5689 - acc: 0.8414 - val_loss: 2.0423 - val_acc: 0.5000\nEpoch 553/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5668 - acc: 0.8371 - val_loss: 2.0575 - val_acc: 0.4900\nEpoch 554/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5671 - acc: 0.8329 - val_loss: 2.0581 - val_acc: 0.4867\nEpoch 555/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.5692 - acc: 0.8257 - val_loss: 2.0526 - val_acc: 0.5067\nEpoch 556/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5691 - acc: 0.8343 - val_loss: 2.0547 - val_acc: 0.5000\nEpoch 557/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5680 - acc: 0.8357 - val_loss: 2.0682 - val_acc: 0.4867\nEpoch 558/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5670 - acc: 0.8329 - val_loss: 2.0604 - val_acc: 0.4867\nEpoch 559/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.5672 - acc: 0.8329 - val_loss: 2.0518 - val_acc: 0.4767\nEpoch 560/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.5655 - acc: 0.8357 - val_loss: 2.0514 - val_acc: 0.4933\nEpoch 561/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.5640 - acc: 0.8343 - val_loss: 2.0573 - val_acc: 0.4800\nEpoch 562/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.5666 - acc: 0.8371 - val_loss: 2.0612 - val_acc: 0.4933\nEpoch 563/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.5641 - acc: 0.8386 - val_loss: 2.0852 - val_acc: 0.4867\nEpoch 564/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5646 - acc: 0.8357 - val_loss: 2.0640 - val_acc: 0.4900\nEpoch 565/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5605 - acc: 0.8400 - val_loss: 2.0806 - val_acc: 0.5100\nEpoch 566/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5614 - acc: 0.8343 - val_loss: 2.0728 - val_acc: 0.5000\nEpoch 567/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.5618 - acc: 0.8414 - val_loss: 2.0799 - val_acc: 0.5067\nEpoch 568/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5632 - acc: 0.8414 - val_loss: 2.0821 - val_acc: 0.4933\nEpoch 569/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.5624 - acc: 0.8386 - val_loss: 2.0799 - val_acc: 0.4833\nEpoch 570/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5612 - acc: 0.8357 - val_loss: 2.0918 - val_acc: 0.4833\nEpoch 571/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5622 - acc: 0.8371 - val_loss: 2.0765 - val_acc: 0.4900\nEpoch 572/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5598 - acc: 0.8300 - val_loss: 2.1015 - val_acc: 0.4900\nEpoch 573/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5586 - acc: 0.8457 - val_loss: 2.0818 - val_acc: 0.4767\nEpoch 574/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5597 - acc: 0.8343 - val_loss: 2.0796 - val_acc: 0.4867\nEpoch 575/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5568 - acc: 0.8329 - val_loss: 2.1122 - val_acc: 0.4833\nEpoch 576/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5562 - acc: 0.8429 - val_loss: 2.0889 - val_acc: 0.5033\nEpoch 577/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5555 - acc: 0.8429 - val_loss: 2.0819 - val_acc: 0.4933\nEpoch 578/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5559 - acc: 0.8343 - val_loss: 2.0890 - val_acc: 0.4967\nEpoch 579/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.5555 - acc: 0.8357 - val_loss: 2.1013 - val_acc: 0.4833\nEpoch 580/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5539 - acc: 0.8386 - val_loss: 2.0972 - val_acc: 0.5133\nEpoch 581/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5557 - acc: 0.8343 - val_loss: 2.1051 - val_acc: 0.4800\nEpoch 582/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5519 - acc: 0.8343 - val_loss: 2.0989 - val_acc: 0.4933\nEpoch 583/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5565 - acc: 0.8500 - val_loss: 2.1189 - val_acc: 0.4867\nEpoch 584/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5520 - acc: 0.8471 - val_loss: 2.1030 - val_acc: 0.4900\nEpoch 585/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5535 - acc: 0.8314 - val_loss: 2.1163 - val_acc: 0.4800\nEpoch 586/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5511 - acc: 0.8471 - val_loss: 2.1178 - val_acc: 0.4833\nEpoch 587/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5504 - acc: 0.8429 - val_loss: 2.1210 - val_acc: 0.4900\nEpoch 588/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5527 - acc: 0.8429 - val_loss: 2.1147 - val_acc: 0.4900\nEpoch 589/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5522 - acc: 0.8429 - val_loss: 2.1189 - val_acc: 0.4800\nEpoch 590/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5485 - acc: 0.8414 - val_loss: 2.1043 - val_acc: 0.5000\nEpoch 591/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.5492 - acc: 0.8429 - val_loss: 2.1190 - val_acc: 0.4867\nEpoch 592/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5497 - acc: 0.8457 - val_loss: 2.1199 - val_acc: 0.5000\nEpoch 593/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.5472 - acc: 0.8443 - val_loss: 2.1166 - val_acc: 0.4867\nEpoch 594/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5488 - acc: 0.8414 - val_loss: 2.1434 - val_acc: 0.4800\nEpoch 595/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5491 - acc: 0.8414 - val_loss: 2.1163 - val_acc: 0.4833\nEpoch 596/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5478 - acc: 0.8457 - val_loss: 2.1620 - val_acc: 0.4967\nEpoch 597/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.5464 - acc: 0.8471 - val_loss: 2.1440 - val_acc: 0.4933\nEpoch 598/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5475 - acc: 0.8443 - val_loss: 2.1229 - val_acc: 0.4800\nEpoch 599/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5445 - acc: 0.8414 - val_loss: 2.1357 - val_acc: 0.4833\nEpoch 600/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5445 - acc: 0.8443 - val_loss: 2.1428 - val_acc: 0.5000\nEpoch 601/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5456 - acc: 0.8429 - val_loss: 2.1466 - val_acc: 0.4867\nEpoch 602/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5424 - acc: 0.8429 - val_loss: 2.1426 - val_acc: 0.4767\nEpoch 603/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.5461 - acc: 0.8471 - val_loss: 2.1436 - val_acc: 0.4867\nEpoch 604/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.5439 - acc: 0.8486 - val_loss: 2.1482 - val_acc: 0.4833\nEpoch 605/1000\n700/700 [==============================] - 0s 121us/sample - loss: 0.5400 - acc: 0.8471 - val_loss: 2.1365 - val_acc: 0.4833\nEpoch 606/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5384 - acc: 0.8500 - val_loss: 2.1476 - val_acc: 0.5067\nEpoch 607/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5406 - acc: 0.8514 - val_loss: 2.1387 - val_acc: 0.4833\nEpoch 608/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5412 - acc: 0.8429 - val_loss: 2.1799 - val_acc: 0.5000\nEpoch 609/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.5415 - acc: 0.8457 - val_loss: 2.1549 - val_acc: 0.4867\nEpoch 610/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5405 - acc: 0.8400 - val_loss: 2.1735 - val_acc: 0.4933\nEpoch 611/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5357 - acc: 0.8586 - val_loss: 2.1555 - val_acc: 0.4900\nEpoch 612/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5399 - acc: 0.8486 - val_loss: 2.1445 - val_acc: 0.4933\nEpoch 613/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5384 - acc: 0.8514 - val_loss: 2.1470 - val_acc: 0.4900\nEpoch 614/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5375 - acc: 0.8586 - val_loss: 2.1577 - val_acc: 0.4733\nEpoch 615/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5340 - acc: 0.8500 - val_loss: 2.1566 - val_acc: 0.4800\nEpoch 616/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5395 - acc: 0.8443 - val_loss: 2.1570 - val_acc: 0.4800\nEpoch 617/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.5364 - acc: 0.8471 - val_loss: 2.1723 - val_acc: 0.4933\nEpoch 618/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5358 - acc: 0.8514 - val_loss: 2.1683 - val_acc: 0.4933\nEpoch 619/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5356 - acc: 0.8443 - val_loss: 2.1657 - val_acc: 0.4833\nEpoch 620/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5340 - acc: 0.8500 - val_loss: 2.1845 - val_acc: 0.5033\nEpoch 621/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5355 - acc: 0.8457 - val_loss: 2.1595 - val_acc: 0.4867\nEpoch 622/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5332 - acc: 0.8414 - val_loss: 2.1656 - val_acc: 0.4900\nEpoch 623/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5332 - acc: 0.8529 - val_loss: 2.1839 - val_acc: 0.4900\nEpoch 624/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5336 - acc: 0.8529 - val_loss: 2.1677 - val_acc: 0.4933\nEpoch 625/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5341 - acc: 0.8457 - val_loss: 2.1681 - val_acc: 0.4867\nEpoch 626/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5323 - acc: 0.8586 - val_loss: 2.1925 - val_acc: 0.4833\nEpoch 627/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5333 - acc: 0.8514 - val_loss: 2.1778 - val_acc: 0.4867\nEpoch 628/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5320 - acc: 0.8529 - val_loss: 2.1815 - val_acc: 0.4800\nEpoch 629/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5287 - acc: 0.8571 - val_loss: 2.1714 - val_acc: 0.4833\nEpoch 630/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5287 - acc: 0.8429 - val_loss: 2.1992 - val_acc: 0.4900\nEpoch 631/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.5306 - acc: 0.8500 - val_loss: 2.1872 - val_acc: 0.4867\nEpoch 632/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5258 - acc: 0.8486 - val_loss: 2.1857 - val_acc: 0.5033\nEpoch 633/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5277 - acc: 0.8557 - val_loss: 2.2096 - val_acc: 0.4933\nEpoch 634/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.5281 - acc: 0.8514 - val_loss: 2.1925 - val_acc: 0.4967\nEpoch 635/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5262 - acc: 0.8486 - val_loss: 2.2060 - val_acc: 0.4933\nEpoch 636/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5281 - acc: 0.8543 - val_loss: 2.2033 - val_acc: 0.4967\nEpoch 637/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5267 - acc: 0.8529 - val_loss: 2.1946 - val_acc: 0.4867\nEpoch 638/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.5214 - acc: 0.8629 - val_loss: 2.1839 - val_acc: 0.4900\nEpoch 639/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.5269 - acc: 0.8486 - val_loss: 2.1926 - val_acc: 0.4900\nEpoch 640/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5259 - acc: 0.8557 - val_loss: 2.2049 - val_acc: 0.4933\nEpoch 641/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.5268 - acc: 0.8514 - val_loss: 2.2095 - val_acc: 0.4867\nEpoch 642/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5241 - acc: 0.8486 - val_loss: 2.2181 - val_acc: 0.4900\nEpoch 643/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5257 - acc: 0.8543 - val_loss: 2.2052 - val_acc: 0.4967\nEpoch 644/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5262 - acc: 0.8514 - val_loss: 2.2159 - val_acc: 0.4833\nEpoch 645/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.5230 - acc: 0.8543 - val_loss: 2.1987 - val_acc: 0.4900\nEpoch 646/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.5250 - acc: 0.8586 - val_loss: 2.2159 - val_acc: 0.5000\nEpoch 647/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5216 - acc: 0.8586 - val_loss: 2.2202 - val_acc: 0.4933\nEpoch 648/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5216 - acc: 0.8529 - val_loss: 2.2097 - val_acc: 0.4900\nEpoch 649/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5231 - acc: 0.8629 - val_loss: 2.2272 - val_acc: 0.4800\nEpoch 650/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5229 - acc: 0.8529 - val_loss: 2.2107 - val_acc: 0.4833\nEpoch 651/1000\n700/700 [==============================] - 0s 113us/sample - loss: 0.5192 - acc: 0.8600 - val_loss: 2.1928 - val_acc: 0.4900\nEpoch 652/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5196 - acc: 0.8543 - val_loss: 2.2173 - val_acc: 0.4933\nEpoch 653/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.5166 - acc: 0.8571 - val_loss: 2.2039 - val_acc: 0.4900\nEpoch 654/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5188 - acc: 0.8571 - val_loss: 2.2129 - val_acc: 0.4867\nEpoch 655/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5191 - acc: 0.8600 - val_loss: 2.2455 - val_acc: 0.4967\nEpoch 656/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5193 - acc: 0.8471 - val_loss: 2.2254 - val_acc: 0.4867\nEpoch 657/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5187 - acc: 0.8486 - val_loss: 2.2290 - val_acc: 0.4833\nEpoch 658/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5171 - acc: 0.8600 - val_loss: 2.2484 - val_acc: 0.4767\nEpoch 659/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5174 - acc: 0.8529 - val_loss: 2.2347 - val_acc: 0.4900\nEpoch 660/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.5155 - acc: 0.8557 - val_loss: 2.2290 - val_acc: 0.4900\nEpoch 661/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5156 - acc: 0.8629 - val_loss: 2.2442 - val_acc: 0.4900\nEpoch 662/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5143 - acc: 0.8543 - val_loss: 2.2368 - val_acc: 0.4967\nEpoch 663/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5154 - acc: 0.8557 - val_loss: 2.2395 - val_acc: 0.4867\nEpoch 664/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5145 - acc: 0.8529 - val_loss: 2.2307 - val_acc: 0.4933\nEpoch 665/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5144 - acc: 0.8600 - val_loss: 2.2368 - val_acc: 0.4867\nEpoch 666/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5142 - acc: 0.8557 - val_loss: 2.2346 - val_acc: 0.4933\nEpoch 667/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5142 - acc: 0.8600 - val_loss: 2.2234 - val_acc: 0.4967\nEpoch 668/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5124 - acc: 0.8571 - val_loss: 2.2725 - val_acc: 0.4967\nEpoch 669/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5115 - acc: 0.8586 - val_loss: 2.2359 - val_acc: 0.4833\nEpoch 670/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.5103 - acc: 0.8629 - val_loss: 2.2402 - val_acc: 0.4867\nEpoch 671/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.5110 - acc: 0.8500 - val_loss: 2.2394 - val_acc: 0.4867\nEpoch 672/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5092 - acc: 0.8543 - val_loss: 2.2306 - val_acc: 0.4800\nEpoch 673/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5153 - acc: 0.8529 - val_loss: 2.2448 - val_acc: 0.4967\nEpoch 674/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5104 - acc: 0.8643 - val_loss: 2.2359 - val_acc: 0.4800\nEpoch 675/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5091 - acc: 0.8629 - val_loss: 2.2682 - val_acc: 0.4933\nEpoch 676/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5068 - acc: 0.8643 - val_loss: 2.2358 - val_acc: 0.4933\nEpoch 677/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.5066 - acc: 0.8643 - val_loss: 2.2699 - val_acc: 0.4967\nEpoch 678/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.5085 - acc: 0.8643 - val_loss: 2.2522 - val_acc: 0.4800\nEpoch 679/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.5069 - acc: 0.8614 - val_loss: 2.2649 - val_acc: 0.4933\nEpoch 680/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5052 - acc: 0.8614 - val_loss: 2.2800 - val_acc: 0.4867\nEpoch 681/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.5081 - acc: 0.8600 - val_loss: 2.2607 - val_acc: 0.4800\nEpoch 682/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5077 - acc: 0.8600 - val_loss: 2.2692 - val_acc: 0.4800\nEpoch 683/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.5054 - acc: 0.8657 - val_loss: 2.2722 - val_acc: 0.4967\nEpoch 684/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.5047 - acc: 0.8600 - val_loss: 2.2637 - val_acc: 0.4933\nEpoch 685/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5046 - acc: 0.8614 - val_loss: 2.2642 - val_acc: 0.4867\nEpoch 686/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5028 - acc: 0.8714 - val_loss: 2.2759 - val_acc: 0.4833\nEpoch 687/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5017 - acc: 0.8700 - val_loss: 2.2747 - val_acc: 0.4933\nEpoch 688/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5064 - acc: 0.8643 - val_loss: 2.2815 - val_acc: 0.4867\nEpoch 689/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5041 - acc: 0.8571 - val_loss: 2.2812 - val_acc: 0.4767\nEpoch 690/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5027 - acc: 0.8643 - val_loss: 2.3017 - val_acc: 0.4867\nEpoch 691/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.5010 - acc: 0.8686 - val_loss: 2.2814 - val_acc: 0.4900\nEpoch 692/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5015 - acc: 0.8571 - val_loss: 2.2980 - val_acc: 0.4967\nEpoch 693/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5002 - acc: 0.8729 - val_loss: 2.2908 - val_acc: 0.4800\nEpoch 694/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.5016 - acc: 0.8714 - val_loss: 2.3039 - val_acc: 0.4867\nEpoch 695/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5024 - acc: 0.8700 - val_loss: 2.2993 - val_acc: 0.4900\nEpoch 696/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4995 - acc: 0.8629 - val_loss: 2.3103 - val_acc: 0.4867\nEpoch 697/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4990 - acc: 0.8686 - val_loss: 2.2988 - val_acc: 0.4900\nEpoch 698/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4960 - acc: 0.8743 - val_loss: 2.2999 - val_acc: 0.4867\nEpoch 699/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.5001 - acc: 0.8629 - val_loss: 2.3008 - val_acc: 0.4900\nEpoch 700/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4975 - acc: 0.8614 - val_loss: 2.2895 - val_acc: 0.4967\nEpoch 701/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4974 - acc: 0.8657 - val_loss: 2.2894 - val_acc: 0.4933\nEpoch 702/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4967 - acc: 0.8657 - val_loss: 2.3093 - val_acc: 0.4967\nEpoch 703/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4948 - acc: 0.8771 - val_loss: 2.2828 - val_acc: 0.4733\nEpoch 704/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4970 - acc: 0.8686 - val_loss: 2.3008 - val_acc: 0.4933\nEpoch 705/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4978 - acc: 0.8700 - val_loss: 2.2995 - val_acc: 0.4933\nEpoch 706/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4947 - acc: 0.8686 - val_loss: 2.2980 - val_acc: 0.4900\nEpoch 707/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4958 - acc: 0.8686 - val_loss: 2.3025 - val_acc: 0.4833\nEpoch 708/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4969 - acc: 0.8600 - val_loss: 2.3019 - val_acc: 0.4900\nEpoch 709/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4963 - acc: 0.8743 - val_loss: 2.3044 - val_acc: 0.4933\nEpoch 710/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4941 - acc: 0.8671 - val_loss: 2.3224 - val_acc: 0.4900\nEpoch 711/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4941 - acc: 0.8757 - val_loss: 2.3166 - val_acc: 0.4933\nEpoch 712/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.4952 - acc: 0.8729 - val_loss: 2.3195 - val_acc: 0.4867\nEpoch 713/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4927 - acc: 0.8714 - val_loss: 2.3240 - val_acc: 0.4800\nEpoch 714/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4969 - acc: 0.8671 - val_loss: 2.3098 - val_acc: 0.4867\nEpoch 715/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4940 - acc: 0.8686 - val_loss: 2.3228 - val_acc: 0.4833\nEpoch 716/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4925 - acc: 0.8700 - val_loss: 2.3296 - val_acc: 0.4933\nEpoch 717/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4914 - acc: 0.8771 - val_loss: 2.3339 - val_acc: 0.4967\nEpoch 718/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4905 - acc: 0.8686 - val_loss: 2.3271 - val_acc: 0.4933\nEpoch 719/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4896 - acc: 0.8729 - val_loss: 2.3387 - val_acc: 0.4733\nEpoch 720/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4911 - acc: 0.8600 - val_loss: 2.3272 - val_acc: 0.4933\nEpoch 721/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.4899 - acc: 0.8700 - val_loss: 2.3460 - val_acc: 0.4900\nEpoch 722/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4885 - acc: 0.8657 - val_loss: 2.3107 - val_acc: 0.4800\nEpoch 723/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4893 - acc: 0.8743 - val_loss: 2.3200 - val_acc: 0.4933\nEpoch 724/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4876 - acc: 0.8786 - val_loss: 2.3243 - val_acc: 0.4933\nEpoch 725/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4888 - acc: 0.8743 - val_loss: 2.3345 - val_acc: 0.4900\nEpoch 726/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4895 - acc: 0.8629 - val_loss: 2.3452 - val_acc: 0.4933\nEpoch 727/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4867 - acc: 0.8657 - val_loss: 2.3457 - val_acc: 0.4967\nEpoch 728/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4911 - acc: 0.8671 - val_loss: 2.3278 - val_acc: 0.4933\nEpoch 729/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4869 - acc: 0.8686 - val_loss: 2.3515 - val_acc: 0.4933\nEpoch 730/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4864 - acc: 0.8771 - val_loss: 2.3510 - val_acc: 0.4800\nEpoch 731/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4872 - acc: 0.8657 - val_loss: 2.3377 - val_acc: 0.4900\nEpoch 732/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4813 - acc: 0.8786 - val_loss: 2.3536 - val_acc: 0.4967\nEpoch 733/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4834 - acc: 0.8671 - val_loss: 2.3636 - val_acc: 0.4833\nEpoch 734/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4874 - acc: 0.8700 - val_loss: 2.3488 - val_acc: 0.4833\nEpoch 735/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4837 - acc: 0.8714 - val_loss: 2.3581 - val_acc: 0.4767\nEpoch 736/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4841 - acc: 0.8771 - val_loss: 2.3669 - val_acc: 0.4933\nEpoch 737/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4815 - acc: 0.8829 - val_loss: 2.3503 - val_acc: 0.4867\nEpoch 738/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4842 - acc: 0.8714 - val_loss: 2.3618 - val_acc: 0.4800\nEpoch 739/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4833 - acc: 0.8643 - val_loss: 2.3595 - val_acc: 0.4800\nEpoch 740/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4825 - acc: 0.8700 - val_loss: 2.3580 - val_acc: 0.4767\nEpoch 741/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4844 - acc: 0.8814 - val_loss: 2.3764 - val_acc: 0.4933\nEpoch 742/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4843 - acc: 0.8700 - val_loss: 2.3727 - val_acc: 0.4900\nEpoch 743/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4801 - acc: 0.8743 - val_loss: 2.3768 - val_acc: 0.4833\nEpoch 744/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4816 - acc: 0.8757 - val_loss: 2.3744 - val_acc: 0.4900\nEpoch 745/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4790 - acc: 0.8771 - val_loss: 2.3762 - val_acc: 0.4800\nEpoch 746/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4808 - acc: 0.8743 - val_loss: 2.3686 - val_acc: 0.4867\nEpoch 747/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4790 - acc: 0.8800 - val_loss: 2.3705 - val_acc: 0.4833\nEpoch 748/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4801 - acc: 0.8700 - val_loss: 2.3838 - val_acc: 0.4867\nEpoch 749/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4800 - acc: 0.8757 - val_loss: 2.3818 - val_acc: 0.4867\nEpoch 750/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4784 - acc: 0.8671 - val_loss: 2.3722 - val_acc: 0.4833\nEpoch 751/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4783 - acc: 0.8771 - val_loss: 2.4070 - val_acc: 0.4833\nEpoch 752/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.4771 - acc: 0.8814 - val_loss: 2.3718 - val_acc: 0.4933\nEpoch 753/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.4777 - acc: 0.8743 - val_loss: 2.3951 - val_acc: 0.4867\nEpoch 754/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4716 - acc: 0.8743 - val_loss: 2.3950 - val_acc: 0.4800\nEpoch 755/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4738 - acc: 0.8814 - val_loss: 2.3928 - val_acc: 0.4867\nEpoch 756/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4777 - acc: 0.8800 - val_loss: 2.4000 - val_acc: 0.4767\nEpoch 757/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4754 - acc: 0.8814 - val_loss: 2.3970 - val_acc: 0.4800\nEpoch 758/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4747 - acc: 0.8743 - val_loss: 2.4067 - val_acc: 0.4833\nEpoch 759/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4776 - acc: 0.8757 - val_loss: 2.4036 - val_acc: 0.4933\nEpoch 760/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4729 - acc: 0.8800 - val_loss: 2.3963 - val_acc: 0.4900\nEpoch 761/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4727 - acc: 0.8829 - val_loss: 2.4022 - val_acc: 0.4833\nEpoch 762/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4742 - acc: 0.8714 - val_loss: 2.3945 - val_acc: 0.4867\nEpoch 763/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4744 - acc: 0.8829 - val_loss: 2.4021 - val_acc: 0.4733\nEpoch 764/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4722 - acc: 0.8857 - val_loss: 2.3976 - val_acc: 0.4867\nEpoch 765/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4723 - acc: 0.8757 - val_loss: 2.4034 - val_acc: 0.4800\nEpoch 766/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.4722 - acc: 0.8843 - val_loss: 2.4275 - val_acc: 0.4767\nEpoch 767/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4744 - acc: 0.8786 - val_loss: 2.4154 - val_acc: 0.4933\nEpoch 768/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.4684 - acc: 0.8814 - val_loss: 2.4170 - val_acc: 0.4867\nEpoch 769/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.4717 - acc: 0.8800 - val_loss: 2.4182 - val_acc: 0.4933\nEpoch 770/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4692 - acc: 0.8829 - val_loss: 2.4199 - val_acc: 0.4867\nEpoch 771/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4696 - acc: 0.8814 - val_loss: 2.4258 - val_acc: 0.4800\nEpoch 772/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4696 - acc: 0.8757 - val_loss: 2.4284 - val_acc: 0.4967\nEpoch 773/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4691 - acc: 0.8786 - val_loss: 2.4235 - val_acc: 0.4867\nEpoch 774/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.4704 - acc: 0.8800 - val_loss: 2.4298 - val_acc: 0.4767\nEpoch 775/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4687 - acc: 0.8843 - val_loss: 2.4328 - val_acc: 0.4933\nEpoch 776/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4679 - acc: 0.8814 - val_loss: 2.4262 - val_acc: 0.4867\nEpoch 777/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4676 - acc: 0.8800 - val_loss: 2.4453 - val_acc: 0.4900\nEpoch 778/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4685 - acc: 0.8771 - val_loss: 2.4099 - val_acc: 0.4767\nEpoch 779/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4644 - acc: 0.8786 - val_loss: 2.4458 - val_acc: 0.4700\nEpoch 780/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4669 - acc: 0.8857 - val_loss: 2.4488 - val_acc: 0.4833\nEpoch 781/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4669 - acc: 0.8814 - val_loss: 2.4272 - val_acc: 0.4867\nEpoch 782/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.4666 - acc: 0.8771 - val_loss: 2.4177 - val_acc: 0.4833\nEpoch 783/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4681 - acc: 0.8814 - val_loss: 2.4302 - val_acc: 0.4800\nEpoch 784/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4677 - acc: 0.8900 - val_loss: 2.4426 - val_acc: 0.4800\nEpoch 785/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4655 - acc: 0.8857 - val_loss: 2.4679 - val_acc: 0.4867\nEpoch 786/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4657 - acc: 0.8857 - val_loss: 2.4411 - val_acc: 0.4767\nEpoch 787/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4626 - acc: 0.8886 - val_loss: 2.4411 - val_acc: 0.4800\nEpoch 788/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4639 - acc: 0.8771 - val_loss: 2.4681 - val_acc: 0.4833\nEpoch 789/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4637 - acc: 0.8843 - val_loss: 2.4325 - val_acc: 0.4767\nEpoch 790/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4640 - acc: 0.8857 - val_loss: 2.4507 - val_acc: 0.4800\nEpoch 791/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4623 - acc: 0.8871 - val_loss: 2.4478 - val_acc: 0.4900\nEpoch 792/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4617 - acc: 0.8900 - val_loss: 2.4486 - val_acc: 0.4933\nEpoch 793/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4634 - acc: 0.8814 - val_loss: 2.4754 - val_acc: 0.4767\nEpoch 794/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4621 - acc: 0.8829 - val_loss: 2.4885 - val_acc: 0.4867\nEpoch 795/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4604 - acc: 0.8900 - val_loss: 2.4532 - val_acc: 0.4800\nEpoch 796/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4592 - acc: 0.8857 - val_loss: 2.4601 - val_acc: 0.4767\nEpoch 797/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4607 - acc: 0.8843 - val_loss: 2.4593 - val_acc: 0.4800\nEpoch 798/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4605 - acc: 0.8900 - val_loss: 2.4674 - val_acc: 0.4800\nEpoch 799/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4613 - acc: 0.8771 - val_loss: 2.4919 - val_acc: 0.4733\nEpoch 800/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4636 - acc: 0.8814 - val_loss: 2.4760 - val_acc: 0.4833\nEpoch 801/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4590 - acc: 0.8829 - val_loss: 2.4628 - val_acc: 0.4867\nEpoch 802/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.4596 - acc: 0.8829 - val_loss: 2.4799 - val_acc: 0.4800\nEpoch 803/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4590 - acc: 0.8814 - val_loss: 2.4679 - val_acc: 0.4833\nEpoch 804/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4580 - acc: 0.8886 - val_loss: 2.4619 - val_acc: 0.4800\nEpoch 805/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4571 - acc: 0.8886 - val_loss: 2.4809 - val_acc: 0.4800\nEpoch 806/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4563 - acc: 0.8929 - val_loss: 2.4804 - val_acc: 0.4867\nEpoch 807/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.4581 - acc: 0.8857 - val_loss: 2.4840 - val_acc: 0.4867\nEpoch 808/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4579 - acc: 0.8857 - val_loss: 2.4814 - val_acc: 0.4767\nEpoch 809/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4556 - acc: 0.8857 - val_loss: 2.4887 - val_acc: 0.4800\nEpoch 810/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4592 - acc: 0.8771 - val_loss: 2.4853 - val_acc: 0.4800\nEpoch 811/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4592 - acc: 0.8843 - val_loss: 2.4883 - val_acc: 0.4833\nEpoch 812/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4511 - acc: 0.8986 - val_loss: 2.4801 - val_acc: 0.4800\nEpoch 813/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4555 - acc: 0.8843 - val_loss: 2.4836 - val_acc: 0.4767\nEpoch 814/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4532 - acc: 0.8886 - val_loss: 2.5079 - val_acc: 0.4900\nEpoch 815/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4544 - acc: 0.8814 - val_loss: 2.4989 - val_acc: 0.4767\nEpoch 816/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4537 - acc: 0.8900 - val_loss: 2.4903 - val_acc: 0.4867\nEpoch 817/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4552 - acc: 0.8857 - val_loss: 2.5170 - val_acc: 0.4800\nEpoch 818/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4551 - acc: 0.8829 - val_loss: 2.5102 - val_acc: 0.4733\nEpoch 819/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4540 - acc: 0.8900 - val_loss: 2.5089 - val_acc: 0.4900\nEpoch 820/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4538 - acc: 0.8800 - val_loss: 2.5317 - val_acc: 0.4900\nEpoch 821/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4528 - acc: 0.8900 - val_loss: 2.5169 - val_acc: 0.4800\nEpoch 822/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4520 - acc: 0.8986 - val_loss: 2.5123 - val_acc: 0.4867\nEpoch 823/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4507 - acc: 0.8886 - val_loss: 2.4909 - val_acc: 0.4800\nEpoch 824/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4535 - acc: 0.8871 - val_loss: 2.5339 - val_acc: 0.4833\nEpoch 825/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4542 - acc: 0.8886 - val_loss: 2.5059 - val_acc: 0.4800\nEpoch 826/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4509 - acc: 0.8929 - val_loss: 2.5011 - val_acc: 0.4867\nEpoch 827/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.4510 - acc: 0.8900 - val_loss: 2.5257 - val_acc: 0.4867\nEpoch 828/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4485 - acc: 0.8857 - val_loss: 2.4909 - val_acc: 0.4933\nEpoch 829/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4506 - acc: 0.8857 - val_loss: 2.5290 - val_acc: 0.4900\nEpoch 830/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4487 - acc: 0.8886 - val_loss: 2.5144 - val_acc: 0.4733\nEpoch 831/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4497 - acc: 0.8914 - val_loss: 2.5266 - val_acc: 0.4833\nEpoch 832/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4503 - acc: 0.8871 - val_loss: 2.5127 - val_acc: 0.4800\nEpoch 833/1000\n700/700 [==============================] - 0s 135us/sample - loss: 0.4488 - acc: 0.8929 - val_loss: 2.5410 - val_acc: 0.4833\nEpoch 834/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4496 - acc: 0.8914 - val_loss: 2.5446 - val_acc: 0.4933\nEpoch 835/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4486 - acc: 0.8857 - val_loss: 2.5383 - val_acc: 0.4833\nEpoch 836/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.4494 - acc: 0.8900 - val_loss: 2.5337 - val_acc: 0.4900\nEpoch 837/1000\n700/700 [==============================] - 0s 121us/sample - loss: 0.4465 - acc: 0.8943 - val_loss: 2.5272 - val_acc: 0.4833\nEpoch 838/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4477 - acc: 0.8857 - val_loss: 2.5414 - val_acc: 0.4800\nEpoch 839/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4455 - acc: 0.8971 - val_loss: 2.5342 - val_acc: 0.4867\nEpoch 840/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4468 - acc: 0.8914 - val_loss: 2.5543 - val_acc: 0.4900\nEpoch 841/1000\n700/700 [==============================] - 0s 127us/sample - loss: 0.4450 - acc: 0.8900 - val_loss: 2.5338 - val_acc: 0.4767\nEpoch 842/1000\n700/700 [==============================] - 0s 162us/sample - loss: 0.4463 - acc: 0.8871 - val_loss: 2.5236 - val_acc: 0.4800\nEpoch 843/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.4447 - acc: 0.8971 - val_loss: 2.5309 - val_acc: 0.4967\nEpoch 844/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.4466 - acc: 0.8943 - val_loss: 2.5418 - val_acc: 0.4800\nEpoch 845/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4465 - acc: 0.8943 - val_loss: 2.5596 - val_acc: 0.4867\nEpoch 846/1000\n700/700 [==============================] - 0s 130us/sample - loss: 0.4442 - acc: 0.8957 - val_loss: 2.5283 - val_acc: 0.4967\nEpoch 847/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.4434 - acc: 0.8900 - val_loss: 2.5672 - val_acc: 0.4867\nEpoch 848/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4426 - acc: 0.8943 - val_loss: 2.5545 - val_acc: 0.4767\nEpoch 849/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4436 - acc: 0.9000 - val_loss: 2.5664 - val_acc: 0.4767\nEpoch 850/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.4430 - acc: 0.8957 - val_loss: 2.5457 - val_acc: 0.4900\nEpoch 851/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4409 - acc: 0.8929 - val_loss: 2.5464 - val_acc: 0.4800\nEpoch 852/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4438 - acc: 0.8914 - val_loss: 2.5527 - val_acc: 0.4800\nEpoch 853/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.4425 - acc: 0.8957 - val_loss: 2.5768 - val_acc: 0.4800\nEpoch 854/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.4393 - acc: 0.8929 - val_loss: 2.5989 - val_acc: 0.4933\nEpoch 855/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.4426 - acc: 0.8943 - val_loss: 2.5688 - val_acc: 0.4833\nEpoch 856/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.4419 - acc: 0.8943 - val_loss: 2.5623 - val_acc: 0.4867\nEpoch 857/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.4427 - acc: 0.8929 - val_loss: 2.5804 - val_acc: 0.4800\nEpoch 858/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4415 - acc: 0.8943 - val_loss: 2.5796 - val_acc: 0.4933\nEpoch 859/1000\n700/700 [==============================] - 0s 175us/sample - loss: 0.4385 - acc: 0.8943 - val_loss: 2.5771 - val_acc: 0.4800\nEpoch 860/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4400 - acc: 0.8943 - val_loss: 2.5566 - val_acc: 0.4733\nEpoch 861/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.4378 - acc: 0.8886 - val_loss: 2.5959 - val_acc: 0.4867\nEpoch 862/1000\n700/700 [==============================] - 0s 121us/sample - loss: 0.4377 - acc: 0.8929 - val_loss: 2.5682 - val_acc: 0.4800\nEpoch 863/1000\n700/700 [==============================] - 0s 131us/sample - loss: 0.4378 - acc: 0.8886 - val_loss: 2.5737 - val_acc: 0.4833\nEpoch 864/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4398 - acc: 0.8957 - val_loss: 2.5797 - val_acc: 0.4800\nEpoch 865/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4359 - acc: 0.9000 - val_loss: 2.5748 - val_acc: 0.4833\nEpoch 866/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.4371 - acc: 0.8986 - val_loss: 2.6024 - val_acc: 0.4933\nEpoch 867/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4374 - acc: 0.9000 - val_loss: 2.5702 - val_acc: 0.4933\nEpoch 868/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4373 - acc: 0.8986 - val_loss: 2.5863 - val_acc: 0.4833\nEpoch 869/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4353 - acc: 0.8929 - val_loss: 2.5796 - val_acc: 0.4767\nEpoch 870/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.4392 - acc: 0.8943 - val_loss: 2.5844 - val_acc: 0.4733\nEpoch 871/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4379 - acc: 0.8986 - val_loss: 2.6128 - val_acc: 0.4833\nEpoch 872/1000\n700/700 [==============================] - 0s 113us/sample - loss: 0.4358 - acc: 0.8957 - val_loss: 2.5859 - val_acc: 0.4733\nEpoch 873/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4336 - acc: 0.8900 - val_loss: 2.5870 - val_acc: 0.4733\nEpoch 874/1000\n700/700 [==============================] - 0s 124us/sample - loss: 0.4357 - acc: 0.8957 - val_loss: 2.6028 - val_acc: 0.4767\nEpoch 875/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4331 - acc: 0.8943 - val_loss: 2.5956 - val_acc: 0.4933\nEpoch 876/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4340 - acc: 0.8957 - val_loss: 2.6043 - val_acc: 0.4833\nEpoch 877/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.4347 - acc: 0.8929 - val_loss: 2.5969 - val_acc: 0.4800\nEpoch 878/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.4326 - acc: 0.8971 - val_loss: 2.6037 - val_acc: 0.4767\nEpoch 879/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4337 - acc: 0.9014 - val_loss: 2.5974 - val_acc: 0.4933\nEpoch 880/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.4330 - acc: 0.9029 - val_loss: 2.6017 - val_acc: 0.4800\nEpoch 881/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.4305 - acc: 0.8943 - val_loss: 2.6147 - val_acc: 0.4733\nEpoch 882/1000\n700/700 [==============================] - 0s 128us/sample - loss: 0.4316 - acc: 0.9029 - val_loss: 2.6317 - val_acc: 0.4767\nEpoch 883/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.4309 - acc: 0.8971 - val_loss: 2.6071 - val_acc: 0.4833\nEpoch 884/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.4285 - acc: 0.9014 - val_loss: 2.6209 - val_acc: 0.4800\nEpoch 885/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4324 - acc: 0.8957 - val_loss: 2.6248 - val_acc: 0.4833\nEpoch 886/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4325 - acc: 0.8929 - val_loss: 2.6272 - val_acc: 0.4800\nEpoch 887/1000\n700/700 [==============================] - 0s 124us/sample - loss: 0.4332 - acc: 0.8957 - val_loss: 2.6122 - val_acc: 0.4867\nEpoch 888/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4309 - acc: 0.9000 - val_loss: 2.6266 - val_acc: 0.4933\nEpoch 889/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4299 - acc: 0.9014 - val_loss: 2.6074 - val_acc: 0.4800\nEpoch 890/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4314 - acc: 0.8943 - val_loss: 2.6227 - val_acc: 0.4767\nEpoch 891/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4301 - acc: 0.9043 - val_loss: 2.6222 - val_acc: 0.4667\nEpoch 892/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4275 - acc: 0.9043 - val_loss: 2.6376 - val_acc: 0.4733\nEpoch 893/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4307 - acc: 0.9014 - val_loss: 2.6256 - val_acc: 0.4800\nEpoch 894/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4314 - acc: 0.9000 - val_loss: 2.6241 - val_acc: 0.4733\nEpoch 895/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.4283 - acc: 0.8986 - val_loss: 2.6325 - val_acc: 0.4767\nEpoch 896/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4284 - acc: 0.9000 - val_loss: 2.6238 - val_acc: 0.4767\nEpoch 897/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.4289 - acc: 0.8957 - val_loss: 2.6309 - val_acc: 0.4767\nEpoch 898/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.4272 - acc: 0.8929 - val_loss: 2.6532 - val_acc: 0.4833\nEpoch 899/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4281 - acc: 0.9029 - val_loss: 2.6419 - val_acc: 0.4800\nEpoch 900/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4247 - acc: 0.9029 - val_loss: 2.6631 - val_acc: 0.4667\nEpoch 901/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4296 - acc: 0.8986 - val_loss: 2.6980 - val_acc: 0.4700\nEpoch 902/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4266 - acc: 0.8971 - val_loss: 2.6279 - val_acc: 0.4767\nEpoch 903/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4283 - acc: 0.8971 - val_loss: 2.6521 - val_acc: 0.4833\nEpoch 904/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4261 - acc: 0.9029 - val_loss: 2.6479 - val_acc: 0.4733\nEpoch 905/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4272 - acc: 0.8986 - val_loss: 2.6861 - val_acc: 0.4767\nEpoch 906/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4258 - acc: 0.9043 - val_loss: 2.6678 - val_acc: 0.4833\nEpoch 907/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4259 - acc: 0.9000 - val_loss: 2.6467 - val_acc: 0.4900\nEpoch 908/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.4258 - acc: 0.9043 - val_loss: 2.6345 - val_acc: 0.4800\nEpoch 909/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.4250 - acc: 0.8971 - val_loss: 2.6569 - val_acc: 0.4867\nEpoch 910/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.4272 - acc: 0.9000 - val_loss: 2.6372 - val_acc: 0.4733\nEpoch 911/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4259 - acc: 0.8986 - val_loss: 2.6525 - val_acc: 0.4800\nEpoch 912/1000\n700/700 [==============================] - 0s 113us/sample - loss: 0.4232 - acc: 0.9029 - val_loss: 2.6594 - val_acc: 0.4867\nEpoch 913/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.4238 - acc: 0.8986 - val_loss: 2.6780 - val_acc: 0.4700\nEpoch 914/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.4223 - acc: 0.9100 - val_loss: 2.6649 - val_acc: 0.4700\nEpoch 915/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.4238 - acc: 0.9043 - val_loss: 2.6732 - val_acc: 0.4833\nEpoch 916/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4217 - acc: 0.9014 - val_loss: 2.6804 - val_acc: 0.4867\nEpoch 917/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4227 - acc: 0.9057 - val_loss: 2.6812 - val_acc: 0.4767\nEpoch 918/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4211 - acc: 0.9043 - val_loss: 2.6693 - val_acc: 0.4867\nEpoch 919/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4204 - acc: 0.9071 - val_loss: 2.6663 - val_acc: 0.4700\nEpoch 920/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4242 - acc: 0.9000 - val_loss: 2.6750 - val_acc: 0.4767\nEpoch 921/1000\n700/700 [==============================] - 0s 127us/sample - loss: 0.4169 - acc: 0.9100 - val_loss: 2.7131 - val_acc: 0.4867\nEpoch 922/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.4251 - acc: 0.9014 - val_loss: 2.6788 - val_acc: 0.4800\nEpoch 923/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4231 - acc: 0.9014 - val_loss: 2.6799 - val_acc: 0.4833\nEpoch 924/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4193 - acc: 0.9057 - val_loss: 2.6862 - val_acc: 0.4767\nEpoch 925/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4196 - acc: 0.9043 - val_loss: 2.6762 - val_acc: 0.4900\nEpoch 926/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4204 - acc: 0.9029 - val_loss: 2.6719 - val_acc: 0.4733\nEpoch 927/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.4196 - acc: 0.9000 - val_loss: 2.6927 - val_acc: 0.4833\nEpoch 928/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4195 - acc: 0.8943 - val_loss: 2.6905 - val_acc: 0.4867\nEpoch 929/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4204 - acc: 0.9029 - val_loss: 2.6714 - val_acc: 0.4900\nEpoch 930/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4194 - acc: 0.9071 - val_loss: 2.6874 - val_acc: 0.4633\nEpoch 931/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.4190 - acc: 0.9014 - val_loss: 2.6950 - val_acc: 0.4700\nEpoch 932/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4181 - acc: 0.9071 - val_loss: 2.6968 - val_acc: 0.4800\nEpoch 933/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4150 - acc: 0.9043 - val_loss: 2.7086 - val_acc: 0.4633\nEpoch 934/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4217 - acc: 0.9000 - val_loss: 2.7072 - val_acc: 0.4700\nEpoch 935/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4158 - acc: 0.9014 - val_loss: 2.6914 - val_acc: 0.4800\nEpoch 936/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4166 - acc: 0.9043 - val_loss: 2.7049 - val_acc: 0.4700\nEpoch 937/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4137 - acc: 0.9086 - val_loss: 2.6766 - val_acc: 0.4933\nEpoch 938/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4163 - acc: 0.9029 - val_loss: 2.7018 - val_acc: 0.4700\nEpoch 939/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4194 - acc: 0.8971 - val_loss: 2.7035 - val_acc: 0.4767\nEpoch 940/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4157 - acc: 0.9071 - val_loss: 2.7233 - val_acc: 0.4800\nEpoch 941/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4162 - acc: 0.8986 - val_loss: 2.6828 - val_acc: 0.4833\nEpoch 942/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4156 - acc: 0.9043 - val_loss: 2.7210 - val_acc: 0.4767\nEpoch 943/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4135 - acc: 0.9086 - val_loss: 2.7100 - val_acc: 0.4733\nEpoch 944/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4105 - acc: 0.9043 - val_loss: 2.6986 - val_acc: 0.4900\nEpoch 945/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4161 - acc: 0.9071 - val_loss: 2.7202 - val_acc: 0.4733\nEpoch 946/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4146 - acc: 0.9086 - val_loss: 2.7127 - val_acc: 0.4667\nEpoch 947/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4147 - acc: 0.9086 - val_loss: 2.7207 - val_acc: 0.4833\nEpoch 948/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4138 - acc: 0.9057 - val_loss: 2.7162 - val_acc: 0.4733\nEpoch 949/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4133 - acc: 0.8986 - val_loss: 2.7097 - val_acc: 0.4800\nEpoch 950/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.4139 - acc: 0.9029 - val_loss: 2.7306 - val_acc: 0.4767\nEpoch 951/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4135 - acc: 0.9100 - val_loss: 2.7341 - val_acc: 0.4800\nEpoch 952/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4112 - acc: 0.9071 - val_loss: 2.7294 - val_acc: 0.4767\nEpoch 953/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4122 - acc: 0.9057 - val_loss: 2.7276 - val_acc: 0.4700\nEpoch 954/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4116 - acc: 0.9086 - val_loss: 2.7443 - val_acc: 0.4800\nEpoch 955/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4123 - acc: 0.9000 - val_loss: 2.7446 - val_acc: 0.4767\nEpoch 956/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4137 - acc: 0.9086 - val_loss: 2.7193 - val_acc: 0.4900\nEpoch 957/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4104 - acc: 0.9043 - val_loss: 2.7349 - val_acc: 0.4767\nEpoch 958/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4113 - acc: 0.8986 - val_loss: 2.7351 - val_acc: 0.4767\nEpoch 959/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4116 - acc: 0.9057 - val_loss: 2.7389 - val_acc: 0.4733\nEpoch 960/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4119 - acc: 0.8986 - val_loss: 2.7395 - val_acc: 0.4767\nEpoch 961/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4101 - acc: 0.9057 - val_loss: 2.7380 - val_acc: 0.4800\nEpoch 962/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4110 - acc: 0.9029 - val_loss: 2.7322 - val_acc: 0.4833\nEpoch 963/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4088 - acc: 0.9086 - val_loss: 2.7169 - val_acc: 0.4700\nEpoch 964/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.4088 - acc: 0.9029 - val_loss: 2.7371 - val_acc: 0.4800\nEpoch 965/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.4075 - acc: 0.9043 - val_loss: 2.7292 - val_acc: 0.4767\nEpoch 966/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.4076 - acc: 0.9071 - val_loss: 2.7605 - val_acc: 0.4733\nEpoch 967/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.4072 - acc: 0.9086 - val_loss: 2.7387 - val_acc: 0.4767\nEpoch 968/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4092 - acc: 0.9100 - val_loss: 2.7650 - val_acc: 0.4733\nEpoch 969/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4084 - acc: 0.9057 - val_loss: 2.7562 - val_acc: 0.4800\nEpoch 970/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4090 - acc: 0.9029 - val_loss: 2.7401 - val_acc: 0.4867\nEpoch 971/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4090 - acc: 0.9043 - val_loss: 2.7427 - val_acc: 0.4767\nEpoch 972/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.4079 - acc: 0.9057 - val_loss: 2.7486 - val_acc: 0.4733\nEpoch 973/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4075 - acc: 0.9014 - val_loss: 2.7587 - val_acc: 0.4767\nEpoch 974/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4067 - acc: 0.9057 - val_loss: 2.7532 - val_acc: 0.4800\nEpoch 975/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.4060 - acc: 0.9086 - val_loss: 2.7620 - val_acc: 0.4733\nEpoch 976/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4063 - acc: 0.9043 - val_loss: 2.7555 - val_acc: 0.4800\nEpoch 977/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.4028 - acc: 0.9129 - val_loss: 2.7772 - val_acc: 0.4700\nEpoch 978/1000\n700/700 [==============================] - 0s 123us/sample - loss: 0.4068 - acc: 0.9086 - val_loss: 2.7788 - val_acc: 0.4733\nEpoch 979/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.4047 - acc: 0.9100 - val_loss: 2.7787 - val_acc: 0.4667\nEpoch 980/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4034 - acc: 0.9114 - val_loss: 2.7760 - val_acc: 0.4667\nEpoch 981/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.4031 - acc: 0.9071 - val_loss: 2.7753 - val_acc: 0.4800\nEpoch 982/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4069 - acc: 0.9100 - val_loss: 2.7959 - val_acc: 0.4667\nEpoch 983/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4047 - acc: 0.9071 - val_loss: 2.7695 - val_acc: 0.4767\nEpoch 984/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4048 - acc: 0.9114 - val_loss: 2.7605 - val_acc: 0.4700\nEpoch 985/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4058 - acc: 0.9086 - val_loss: 2.7676 - val_acc: 0.4767\nEpoch 986/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.4032 - acc: 0.9114 - val_loss: 2.7964 - val_acc: 0.4767\nEpoch 987/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.4014 - acc: 0.9100 - val_loss: 2.7846 - val_acc: 0.4800\nEpoch 988/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.4020 - acc: 0.9100 - val_loss: 2.7681 - val_acc: 0.4733\nEpoch 989/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4041 - acc: 0.9114 - val_loss: 2.7899 - val_acc: 0.4700\nEpoch 990/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.4032 - acc: 0.9086 - val_loss: 2.7777 - val_acc: 0.4733\nEpoch 991/1000\n700/700 [==============================] - 0s 138us/sample - loss: 0.4039 - acc: 0.9086 - val_loss: 2.7781 - val_acc: 0.4800\nEpoch 992/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.3999 - acc: 0.9129 - val_loss: 2.7722 - val_acc: 0.4733\nEpoch 993/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.4013 - acc: 0.9100 - val_loss: 2.7894 - val_acc: 0.4700\nEpoch 994/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.4027 - acc: 0.9057 - val_loss: 2.8181 - val_acc: 0.4667\nEpoch 995/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.3996 - acc: 0.9071 - val_loss: 2.7956 - val_acc: 0.4767\nEpoch 996/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.4006 - acc: 0.9114 - val_loss: 2.7855 - val_acc: 0.4733\nEpoch 997/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.3975 - acc: 0.9100 - val_loss: 2.7955 - val_acc: 0.4700\nEpoch 998/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.4004 - acc: 0.9129 - val_loss: 2.7886 - val_acc: 0.4767\nEpoch 999/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.3994 - acc: 0.9114 - val_loss: 2.8276 - val_acc: 0.4733\nEpoch 1000/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.4010 - acc: 0.9086 - val_loss: 2.8226 - val_acc: 0.4700\n"
    }
   ],
   "source": [
    "# 모델 학습시키기\n",
    "\n",
    "hist = model.fit(xtrain, ytrain, batch_size=10,  epochs=1000, validation_data=(xval, yval))\n",
    "# hist.history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 700 samples, validate on 300 samples\nEpoch 1/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.2095 - acc: 0.9543 - val_loss: 5.5982 - val_acc: 0.4133\nEpoch 2/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.2097 - acc: 0.9543 - val_loss: 5.5692 - val_acc: 0.4133\nEpoch 3/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2099 - acc: 0.9586 - val_loss: 5.5768 - val_acc: 0.4133\nEpoch 4/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2099 - acc: 0.9571 - val_loss: 5.5863 - val_acc: 0.4133\nEpoch 5/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2097 - acc: 0.9557 - val_loss: 5.5798 - val_acc: 0.4100\nEpoch 6/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2095 - acc: 0.9557 - val_loss: 5.5738 - val_acc: 0.4067\nEpoch 7/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.2093 - acc: 0.9529 - val_loss: 5.6075 - val_acc: 0.4167\nEpoch 8/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.2096 - acc: 0.9557 - val_loss: 5.6008 - val_acc: 0.4167\nEpoch 9/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2097 - acc: 0.9586 - val_loss: 5.5796 - val_acc: 0.4133\nEpoch 10/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2096 - acc: 0.9571 - val_loss: 5.6051 - val_acc: 0.4100\nEpoch 11/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2097 - acc: 0.9557 - val_loss: 5.5842 - val_acc: 0.4100\nEpoch 12/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2092 - acc: 0.9557 - val_loss: 5.6170 - val_acc: 0.4167\nEpoch 13/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2096 - acc: 0.9557 - val_loss: 5.5775 - val_acc: 0.4100\nEpoch 14/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2094 - acc: 0.9586 - val_loss: 5.5843 - val_acc: 0.4133\nEpoch 15/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2093 - acc: 0.9586 - val_loss: 5.6000 - val_acc: 0.4133\nEpoch 16/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.2091 - acc: 0.9557 - val_loss: 5.5958 - val_acc: 0.4133\nEpoch 17/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2094 - acc: 0.9543 - val_loss: 5.6022 - val_acc: 0.4067\nEpoch 18/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2091 - acc: 0.9557 - val_loss: 5.6016 - val_acc: 0.4100\nEpoch 19/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2090 - acc: 0.9557 - val_loss: 5.5974 - val_acc: 0.4100\nEpoch 20/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.2091 - acc: 0.9586 - val_loss: 5.5943 - val_acc: 0.4133\nEpoch 21/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2090 - acc: 0.9586 - val_loss: 5.5742 - val_acc: 0.4100\nEpoch 22/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2092 - acc: 0.9557 - val_loss: 5.5942 - val_acc: 0.4100\nEpoch 23/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2091 - acc: 0.9614 - val_loss: 5.5840 - val_acc: 0.4100\nEpoch 24/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2088 - acc: 0.9557 - val_loss: 5.6175 - val_acc: 0.4167\nEpoch 25/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2090 - acc: 0.9571 - val_loss: 5.6106 - val_acc: 0.4100\nEpoch 26/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2091 - acc: 0.9571 - val_loss: 5.6069 - val_acc: 0.4167\nEpoch 27/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2090 - acc: 0.9571 - val_loss: 5.6133 - val_acc: 0.4167\nEpoch 28/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2087 - acc: 0.9571 - val_loss: 5.5996 - val_acc: 0.4067\nEpoch 29/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2088 - acc: 0.9586 - val_loss: 5.6051 - val_acc: 0.4133\nEpoch 30/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2087 - acc: 0.9571 - val_loss: 5.6511 - val_acc: 0.4200\nEpoch 31/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2090 - acc: 0.9543 - val_loss: 5.6181 - val_acc: 0.4167\nEpoch 32/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2086 - acc: 0.9586 - val_loss: 5.6221 - val_acc: 0.4200\nEpoch 33/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2089 - acc: 0.9571 - val_loss: 5.6188 - val_acc: 0.4200\nEpoch 34/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2090 - acc: 0.9557 - val_loss: 5.6207 - val_acc: 0.4167\nEpoch 35/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2085 - acc: 0.9586 - val_loss: 5.6379 - val_acc: 0.4167\nEpoch 36/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2089 - acc: 0.9586 - val_loss: 5.6132 - val_acc: 0.4100\nEpoch 37/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2085 - acc: 0.9586 - val_loss: 5.6163 - val_acc: 0.4100\nEpoch 38/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2090 - acc: 0.9557 - val_loss: 5.6126 - val_acc: 0.4067\nEpoch 39/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2089 - acc: 0.9571 - val_loss: 5.6240 - val_acc: 0.4133\nEpoch 40/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2088 - acc: 0.9600 - val_loss: 5.6184 - val_acc: 0.4133\nEpoch 41/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2081 - acc: 0.9543 - val_loss: 5.6176 - val_acc: 0.4100\nEpoch 42/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2087 - acc: 0.9586 - val_loss: 5.6229 - val_acc: 0.4133\nEpoch 43/1000\n700/700 [==============================] - 0s 118us/sample - loss: 0.2084 - acc: 0.9586 - val_loss: 5.6029 - val_acc: 0.4100\nEpoch 44/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2088 - acc: 0.9571 - val_loss: 5.6161 - val_acc: 0.4167\nEpoch 45/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2084 - acc: 0.9600 - val_loss: 5.6242 - val_acc: 0.4133\nEpoch 46/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.2083 - acc: 0.9571 - val_loss: 5.6164 - val_acc: 0.4100\nEpoch 47/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.2081 - acc: 0.9571 - val_loss: 5.6419 - val_acc: 0.4133\nEpoch 48/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2083 - acc: 0.9614 - val_loss: 5.6157 - val_acc: 0.4133\nEpoch 49/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2087 - acc: 0.9586 - val_loss: 5.5955 - val_acc: 0.4067\nEpoch 50/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2083 - acc: 0.9571 - val_loss: 5.6424 - val_acc: 0.4167\nEpoch 51/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2081 - acc: 0.9600 - val_loss: 5.6243 - val_acc: 0.4133\nEpoch 52/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2081 - acc: 0.9600 - val_loss: 5.6289 - val_acc: 0.4133\nEpoch 53/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2081 - acc: 0.9600 - val_loss: 5.6491 - val_acc: 0.4133\nEpoch 54/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2082 - acc: 0.9571 - val_loss: 5.6346 - val_acc: 0.4100\nEpoch 55/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.2083 - acc: 0.9571 - val_loss: 5.6515 - val_acc: 0.4167\nEpoch 56/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2081 - acc: 0.9571 - val_loss: 5.6340 - val_acc: 0.4100\nEpoch 57/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.2081 - acc: 0.9600 - val_loss: 5.6182 - val_acc: 0.4133\nEpoch 58/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2082 - acc: 0.9543 - val_loss: 5.6430 - val_acc: 0.4167\nEpoch 59/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2076 - acc: 0.9586 - val_loss: 5.6332 - val_acc: 0.4100\nEpoch 60/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2079 - acc: 0.9571 - val_loss: 5.6678 - val_acc: 0.4200\nEpoch 61/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2080 - acc: 0.9600 - val_loss: 5.6296 - val_acc: 0.4067\nEpoch 62/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2080 - acc: 0.9571 - val_loss: 5.6345 - val_acc: 0.4067\nEpoch 63/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2081 - acc: 0.9586 - val_loss: 5.6475 - val_acc: 0.4133\nEpoch 64/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2076 - acc: 0.9571 - val_loss: 5.6471 - val_acc: 0.4100\nEpoch 65/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2079 - acc: 0.9614 - val_loss: 5.6432 - val_acc: 0.4133\nEpoch 66/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2077 - acc: 0.9586 - val_loss: 5.6593 - val_acc: 0.4167\nEpoch 67/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.2077 - acc: 0.9571 - val_loss: 5.6848 - val_acc: 0.4167\nEpoch 68/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2080 - acc: 0.9571 - val_loss: 5.6406 - val_acc: 0.4067\nEpoch 69/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2079 - acc: 0.9586 - val_loss: 5.6517 - val_acc: 0.4100\nEpoch 70/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2074 - acc: 0.9586 - val_loss: 5.6260 - val_acc: 0.4133\nEpoch 71/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2075 - acc: 0.9571 - val_loss: 5.6560 - val_acc: 0.4133\nEpoch 72/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2076 - acc: 0.9586 - val_loss: 5.6702 - val_acc: 0.4200\nEpoch 73/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2075 - acc: 0.9600 - val_loss: 5.6821 - val_acc: 0.4133\nEpoch 74/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2073 - acc: 0.9600 - val_loss: 5.6736 - val_acc: 0.4133\nEpoch 75/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2074 - acc: 0.9586 - val_loss: 5.6703 - val_acc: 0.4167\nEpoch 76/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2072 - acc: 0.9600 - val_loss: 5.6326 - val_acc: 0.4100\nEpoch 77/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2075 - acc: 0.9600 - val_loss: 5.6495 - val_acc: 0.4133\nEpoch 78/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2070 - acc: 0.9600 - val_loss: 5.6754 - val_acc: 0.4133\nEpoch 79/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2075 - acc: 0.9600 - val_loss: 5.6638 - val_acc: 0.4133\nEpoch 80/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2074 - acc: 0.9586 - val_loss: 5.6516 - val_acc: 0.4100\nEpoch 81/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.2075 - acc: 0.9600 - val_loss: 5.6795 - val_acc: 0.4167\nEpoch 82/1000\n700/700 [==============================] - 0s 148us/sample - loss: 0.2072 - acc: 0.9586 - val_loss: 5.6632 - val_acc: 0.4133\nEpoch 83/1000\n700/700 [==============================] - 0s 133us/sample - loss: 0.2072 - acc: 0.9600 - val_loss: 5.6760 - val_acc: 0.4100\nEpoch 84/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2071 - acc: 0.9600 - val_loss: 5.6744 - val_acc: 0.4100\nEpoch 85/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2072 - acc: 0.9571 - val_loss: 5.6592 - val_acc: 0.4100\nEpoch 86/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2071 - acc: 0.9614 - val_loss: 5.6710 - val_acc: 0.4100\nEpoch 87/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2067 - acc: 0.9586 - val_loss: 5.6711 - val_acc: 0.4067\nEpoch 88/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2072 - acc: 0.9600 - val_loss: 5.6632 - val_acc: 0.4100\nEpoch 89/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.2071 - acc: 0.9600 - val_loss: 5.6672 - val_acc: 0.4067\nEpoch 90/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2072 - acc: 0.9571 - val_loss: 5.6756 - val_acc: 0.4067\nEpoch 91/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2068 - acc: 0.9614 - val_loss: 5.6796 - val_acc: 0.4100\nEpoch 92/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2069 - acc: 0.9586 - val_loss: 5.6626 - val_acc: 0.4067\nEpoch 93/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2071 - acc: 0.9600 - val_loss: 5.6839 - val_acc: 0.4100\nEpoch 94/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2069 - acc: 0.9600 - val_loss: 5.6620 - val_acc: 0.4100\nEpoch 95/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2069 - acc: 0.9600 - val_loss: 5.6619 - val_acc: 0.4100\nEpoch 96/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2070 - acc: 0.9614 - val_loss: 5.7017 - val_acc: 0.4133\nEpoch 97/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2065 - acc: 0.9586 - val_loss: 5.6882 - val_acc: 0.4133\nEpoch 98/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2070 - acc: 0.9586 - val_loss: 5.6800 - val_acc: 0.4100\nEpoch 99/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2068 - acc: 0.9600 - val_loss: 5.6803 - val_acc: 0.4100\nEpoch 100/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2067 - acc: 0.9586 - val_loss: 5.6792 - val_acc: 0.4133\nEpoch 101/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2064 - acc: 0.9600 - val_loss: 5.7063 - val_acc: 0.4167\nEpoch 102/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2067 - acc: 0.9614 - val_loss: 5.6892 - val_acc: 0.4100\nEpoch 103/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2067 - acc: 0.9571 - val_loss: 5.7054 - val_acc: 0.4133\nEpoch 104/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2065 - acc: 0.9614 - val_loss: 5.6974 - val_acc: 0.4133\nEpoch 105/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2068 - acc: 0.9600 - val_loss: 5.6861 - val_acc: 0.4067\nEpoch 106/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2070 - acc: 0.9614 - val_loss: 5.6994 - val_acc: 0.4067\nEpoch 107/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2062 - acc: 0.9614 - val_loss: 5.7259 - val_acc: 0.4200\nEpoch 108/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2066 - acc: 0.9557 - val_loss: 5.6701 - val_acc: 0.4100\nEpoch 109/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2063 - acc: 0.9614 - val_loss: 5.6961 - val_acc: 0.4133\nEpoch 110/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2065 - acc: 0.9600 - val_loss: 5.6979 - val_acc: 0.4067\nEpoch 111/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2060 - acc: 0.9586 - val_loss: 5.6800 - val_acc: 0.4100\nEpoch 112/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2064 - acc: 0.9586 - val_loss: 5.7235 - val_acc: 0.4133\nEpoch 113/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2064 - acc: 0.9586 - val_loss: 5.6992 - val_acc: 0.4100\nEpoch 114/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.2061 - acc: 0.9600 - val_loss: 5.7068 - val_acc: 0.4133\nEpoch 115/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.2065 - acc: 0.9600 - val_loss: 5.7274 - val_acc: 0.4200\nEpoch 116/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2064 - acc: 0.9600 - val_loss: 5.7244 - val_acc: 0.4067\nEpoch 117/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.2061 - acc: 0.9614 - val_loss: 5.7108 - val_acc: 0.4133\nEpoch 118/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2064 - acc: 0.9600 - val_loss: 5.7015 - val_acc: 0.4067\nEpoch 119/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2063 - acc: 0.9614 - val_loss: 5.7016 - val_acc: 0.4133\nEpoch 120/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2060 - acc: 0.9600 - val_loss: 5.7157 - val_acc: 0.4133\nEpoch 121/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2062 - acc: 0.9614 - val_loss: 5.7099 - val_acc: 0.4067\nEpoch 122/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2062 - acc: 0.9571 - val_loss: 5.7174 - val_acc: 0.4100\nEpoch 123/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2059 - acc: 0.9600 - val_loss: 5.6784 - val_acc: 0.4100\nEpoch 124/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2063 - acc: 0.9614 - val_loss: 5.7205 - val_acc: 0.4167\nEpoch 125/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2061 - acc: 0.9600 - val_loss: 5.7239 - val_acc: 0.4167\nEpoch 126/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2059 - acc: 0.9600 - val_loss: 5.7187 - val_acc: 0.4067\nEpoch 127/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2059 - acc: 0.9614 - val_loss: 5.7247 - val_acc: 0.4067\nEpoch 128/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2059 - acc: 0.9571 - val_loss: 5.7344 - val_acc: 0.4133\nEpoch 129/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2060 - acc: 0.9586 - val_loss: 5.7098 - val_acc: 0.4067\nEpoch 130/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2059 - acc: 0.9614 - val_loss: 5.7327 - val_acc: 0.4067\nEpoch 131/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2059 - acc: 0.9614 - val_loss: 5.7560 - val_acc: 0.4167\nEpoch 132/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2060 - acc: 0.9614 - val_loss: 5.7272 - val_acc: 0.4100\nEpoch 133/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2056 - acc: 0.9586 - val_loss: 5.7041 - val_acc: 0.4100\nEpoch 134/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2060 - acc: 0.9614 - val_loss: 5.7056 - val_acc: 0.4100\nEpoch 135/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2057 - acc: 0.9600 - val_loss: 5.6991 - val_acc: 0.4133\nEpoch 136/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2057 - acc: 0.9614 - val_loss: 5.7080 - val_acc: 0.4100\nEpoch 137/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2060 - acc: 0.9614 - val_loss: 5.7358 - val_acc: 0.4133\nEpoch 138/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2055 - acc: 0.9600 - val_loss: 5.7245 - val_acc: 0.4167\nEpoch 139/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2055 - acc: 0.9614 - val_loss: 5.7303 - val_acc: 0.4100\nEpoch 140/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2056 - acc: 0.9614 - val_loss: 5.7458 - val_acc: 0.4167\nEpoch 141/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2057 - acc: 0.9614 - val_loss: 5.7316 - val_acc: 0.4033\nEpoch 142/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2057 - acc: 0.9614 - val_loss: 5.7299 - val_acc: 0.4067\nEpoch 143/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2056 - acc: 0.9614 - val_loss: 5.7490 - val_acc: 0.4167\nEpoch 144/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2056 - acc: 0.9600 - val_loss: 5.7478 - val_acc: 0.4100\nEpoch 145/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2054 - acc: 0.9614 - val_loss: 5.7210 - val_acc: 0.4067\nEpoch 146/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2053 - acc: 0.9614 - val_loss: 5.7306 - val_acc: 0.4067\nEpoch 147/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2051 - acc: 0.9614 - val_loss: 5.7346 - val_acc: 0.4100\nEpoch 148/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2055 - acc: 0.9614 - val_loss: 5.7336 - val_acc: 0.4100\nEpoch 149/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.2050 - acc: 0.9614 - val_loss: 5.7165 - val_acc: 0.4067\nEpoch 150/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2055 - acc: 0.9614 - val_loss: 5.7538 - val_acc: 0.4067\nEpoch 151/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2054 - acc: 0.9586 - val_loss: 5.7366 - val_acc: 0.4100\nEpoch 152/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2051 - acc: 0.9614 - val_loss: 5.7520 - val_acc: 0.4100\nEpoch 153/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2053 - acc: 0.9614 - val_loss: 5.7266 - val_acc: 0.4100\nEpoch 154/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2054 - acc: 0.9614 - val_loss: 5.7538 - val_acc: 0.4067\nEpoch 155/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.2050 - acc: 0.9600 - val_loss: 5.7492 - val_acc: 0.4100\nEpoch 156/1000\n700/700 [==============================] - 0s 128us/sample - loss: 0.2052 - acc: 0.9614 - val_loss: 5.7623 - val_acc: 0.4167\nEpoch 157/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2054 - acc: 0.9600 - val_loss: 5.7645 - val_acc: 0.4100\nEpoch 158/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2050 - acc: 0.9614 - val_loss: 5.7806 - val_acc: 0.4167\nEpoch 159/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.2052 - acc: 0.9614 - val_loss: 5.7455 - val_acc: 0.4133\nEpoch 160/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2049 - acc: 0.9614 - val_loss: 5.7448 - val_acc: 0.4133\nEpoch 161/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2052 - acc: 0.9586 - val_loss: 5.7569 - val_acc: 0.4067\nEpoch 162/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2050 - acc: 0.9614 - val_loss: 5.7528 - val_acc: 0.4133\nEpoch 163/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2051 - acc: 0.9614 - val_loss: 5.7448 - val_acc: 0.4067\nEpoch 164/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2049 - acc: 0.9600 - val_loss: 5.7495 - val_acc: 0.4067\nEpoch 165/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2049 - acc: 0.9614 - val_loss: 5.7647 - val_acc: 0.4133\nEpoch 166/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2049 - acc: 0.9629 - val_loss: 5.7510 - val_acc: 0.4067\nEpoch 167/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.2050 - acc: 0.9614 - val_loss: 5.7492 - val_acc: 0.4067\nEpoch 168/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2052 - acc: 0.9614 - val_loss: 5.7347 - val_acc: 0.4067\nEpoch 169/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2049 - acc: 0.9614 - val_loss: 5.7817 - val_acc: 0.4167\nEpoch 170/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2047 - acc: 0.9614 - val_loss: 5.7788 - val_acc: 0.4067\nEpoch 171/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.2049 - acc: 0.9614 - val_loss: 5.7699 - val_acc: 0.4100\nEpoch 172/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.2045 - acc: 0.9629 - val_loss: 5.7711 - val_acc: 0.4067\nEpoch 173/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2050 - acc: 0.9629 - val_loss: 5.7597 - val_acc: 0.4167\nEpoch 174/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2045 - acc: 0.9614 - val_loss: 5.7670 - val_acc: 0.4100\nEpoch 175/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2046 - acc: 0.9614 - val_loss: 5.7752 - val_acc: 0.4100\nEpoch 176/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2049 - acc: 0.9614 - val_loss: 5.7661 - val_acc: 0.4067\nEpoch 177/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2045 - acc: 0.9600 - val_loss: 5.7521 - val_acc: 0.4100\nEpoch 178/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2045 - acc: 0.9614 - val_loss: 5.7659 - val_acc: 0.4100\nEpoch 179/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2045 - acc: 0.9614 - val_loss: 5.7801 - val_acc: 0.4067\nEpoch 180/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2045 - acc: 0.9614 - val_loss: 5.7666 - val_acc: 0.4067\nEpoch 181/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2046 - acc: 0.9600 - val_loss: 5.7829 - val_acc: 0.4133\nEpoch 182/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.2043 - acc: 0.9614 - val_loss: 5.7697 - val_acc: 0.4100\nEpoch 183/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2043 - acc: 0.9614 - val_loss: 5.8006 - val_acc: 0.4167\nEpoch 184/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2044 - acc: 0.9614 - val_loss: 5.7938 - val_acc: 0.4067\nEpoch 185/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.2043 - acc: 0.9614 - val_loss: 5.7717 - val_acc: 0.4100\nEpoch 186/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2046 - acc: 0.9614 - val_loss: 5.7934 - val_acc: 0.4200\nEpoch 187/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2042 - acc: 0.9629 - val_loss: 5.7840 - val_acc: 0.4067\nEpoch 188/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2045 - acc: 0.9614 - val_loss: 5.8014 - val_acc: 0.4100\nEpoch 189/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2043 - acc: 0.9614 - val_loss: 5.7994 - val_acc: 0.4133\nEpoch 190/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2041 - acc: 0.9629 - val_loss: 5.7895 - val_acc: 0.4167\nEpoch 191/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2041 - acc: 0.9600 - val_loss: 5.7852 - val_acc: 0.4067\nEpoch 192/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2041 - acc: 0.9614 - val_loss: 5.7742 - val_acc: 0.4067\nEpoch 193/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2040 - acc: 0.9629 - val_loss: 5.7877 - val_acc: 0.4033\nEpoch 194/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2039 - acc: 0.9600 - val_loss: 5.7848 - val_acc: 0.4067\nEpoch 195/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2043 - acc: 0.9600 - val_loss: 5.7742 - val_acc: 0.4067\nEpoch 196/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2041 - acc: 0.9614 - val_loss: 5.8041 - val_acc: 0.4200\nEpoch 197/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2041 - acc: 0.9614 - val_loss: 5.7753 - val_acc: 0.4100\nEpoch 198/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2041 - acc: 0.9614 - val_loss: 5.8047 - val_acc: 0.4100\nEpoch 199/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2037 - acc: 0.9629 - val_loss: 5.8433 - val_acc: 0.4133\nEpoch 200/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2043 - acc: 0.9629 - val_loss: 5.7803 - val_acc: 0.4033\nEpoch 201/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2038 - acc: 0.9614 - val_loss: 5.8185 - val_acc: 0.4167\nEpoch 202/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2040 - acc: 0.9629 - val_loss: 5.7996 - val_acc: 0.4100\nEpoch 203/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2037 - acc: 0.9614 - val_loss: 5.7878 - val_acc: 0.4100\nEpoch 204/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2040 - acc: 0.9614 - val_loss: 5.8035 - val_acc: 0.4100\nEpoch 205/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2038 - acc: 0.9614 - val_loss: 5.7813 - val_acc: 0.4100\nEpoch 206/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2037 - acc: 0.9600 - val_loss: 5.8276 - val_acc: 0.4133\nEpoch 207/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2038 - acc: 0.9614 - val_loss: 5.8221 - val_acc: 0.4133\nEpoch 208/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.2037 - acc: 0.9614 - val_loss: 5.8048 - val_acc: 0.4100\nEpoch 209/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2037 - acc: 0.9614 - val_loss: 5.7889 - val_acc: 0.4100\nEpoch 210/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2035 - acc: 0.9614 - val_loss: 5.8127 - val_acc: 0.4100\nEpoch 211/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2042 - acc: 0.9614 - val_loss: 5.8169 - val_acc: 0.4100\nEpoch 212/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.2036 - acc: 0.9614 - val_loss: 5.7962 - val_acc: 0.4067\nEpoch 213/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2036 - acc: 0.9600 - val_loss: 5.8255 - val_acc: 0.4133\nEpoch 214/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2036 - acc: 0.9614 - val_loss: 5.8205 - val_acc: 0.4100\nEpoch 215/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2037 - acc: 0.9629 - val_loss: 5.7954 - val_acc: 0.4067\nEpoch 216/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2033 - acc: 0.9629 - val_loss: 5.8186 - val_acc: 0.4067\nEpoch 217/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2037 - acc: 0.9614 - val_loss: 5.8121 - val_acc: 0.4067\nEpoch 218/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2034 - acc: 0.9600 - val_loss: 5.8129 - val_acc: 0.4100\nEpoch 219/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2033 - acc: 0.9614 - val_loss: 5.8236 - val_acc: 0.4033\nEpoch 220/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2033 - acc: 0.9600 - val_loss: 5.8404 - val_acc: 0.4133\nEpoch 221/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2034 - acc: 0.9614 - val_loss: 5.8269 - val_acc: 0.4067\nEpoch 222/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2032 - acc: 0.9629 - val_loss: 5.8285 - val_acc: 0.4067\nEpoch 223/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2031 - acc: 0.9614 - val_loss: 5.8290 - val_acc: 0.4167\nEpoch 224/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2032 - acc: 0.9629 - val_loss: 5.8358 - val_acc: 0.4100\nEpoch 225/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2034 - acc: 0.9614 - val_loss: 5.8036 - val_acc: 0.4033\nEpoch 226/1000\n700/700 [==============================] - 0s 68us/sample - loss: 0.2033 - acc: 0.9629 - val_loss: 5.8251 - val_acc: 0.4067\nEpoch 227/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2031 - acc: 0.9614 - val_loss: 5.8261 - val_acc: 0.4033\nEpoch 228/1000\n700/700 [==============================] - 0s 154us/sample - loss: 0.2031 - acc: 0.9629 - val_loss: 5.8471 - val_acc: 0.4100\nEpoch 229/1000\n700/700 [==============================] - 0s 201us/sample - loss: 0.2031 - acc: 0.9629 - val_loss: 5.8435 - val_acc: 0.4167\nEpoch 230/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.2030 - acc: 0.9614 - val_loss: 5.8219 - val_acc: 0.4067\nEpoch 231/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2032 - acc: 0.9629 - val_loss: 5.8195 - val_acc: 0.4067\nEpoch 232/1000\n700/700 [==============================] - 0s 160us/sample - loss: 0.2034 - acc: 0.9614 - val_loss: 5.8304 - val_acc: 0.4067\nEpoch 233/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2033 - acc: 0.9614 - val_loss: 5.8226 - val_acc: 0.4100\nEpoch 234/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2030 - acc: 0.9629 - val_loss: 5.8311 - val_acc: 0.4133\nEpoch 235/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2032 - acc: 0.9614 - val_loss: 5.8414 - val_acc: 0.4133\nEpoch 236/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2030 - acc: 0.9614 - val_loss: 5.8392 - val_acc: 0.4067\nEpoch 237/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2028 - acc: 0.9629 - val_loss: 5.8584 - val_acc: 0.4200\nEpoch 238/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2030 - acc: 0.9614 - val_loss: 5.8336 - val_acc: 0.4100\nEpoch 239/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2030 - acc: 0.9614 - val_loss: 5.8525 - val_acc: 0.4100\nEpoch 240/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2030 - acc: 0.9614 - val_loss: 5.8091 - val_acc: 0.4100\nEpoch 241/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2029 - acc: 0.9629 - val_loss: 5.8419 - val_acc: 0.4067\nEpoch 242/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2025 - acc: 0.9614 - val_loss: 5.8544 - val_acc: 0.4100\nEpoch 243/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2028 - acc: 0.9614 - val_loss: 5.8711 - val_acc: 0.4133\nEpoch 244/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2025 - acc: 0.9614 - val_loss: 5.8475 - val_acc: 0.4033\nEpoch 245/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2027 - acc: 0.9614 - val_loss: 5.8591 - val_acc: 0.4100\nEpoch 246/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2034 - acc: 0.9614 - val_loss: 5.8375 - val_acc: 0.4067\nEpoch 247/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2026 - acc: 0.9614 - val_loss: 5.8398 - val_acc: 0.4100\nEpoch 248/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2028 - acc: 0.9614 - val_loss: 5.8549 - val_acc: 0.4067\nEpoch 249/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2026 - acc: 0.9629 - val_loss: 5.8456 - val_acc: 0.4033\nEpoch 250/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2027 - acc: 0.9614 - val_loss: 5.8551 - val_acc: 0.4067\nEpoch 251/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.2023 - acc: 0.9643 - val_loss: 5.8873 - val_acc: 0.4200\nEpoch 252/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2026 - acc: 0.9614 - val_loss: 5.8467 - val_acc: 0.4067\nEpoch 253/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2026 - acc: 0.9629 - val_loss: 5.8453 - val_acc: 0.4067\nEpoch 254/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2025 - acc: 0.9600 - val_loss: 5.8773 - val_acc: 0.4100\nEpoch 255/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2025 - acc: 0.9614 - val_loss: 5.8573 - val_acc: 0.4100\nEpoch 256/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2021 - acc: 0.9629 - val_loss: 5.8232 - val_acc: 0.4067\nEpoch 257/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2029 - acc: 0.9629 - val_loss: 5.8497 - val_acc: 0.4100\nEpoch 258/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2024 - acc: 0.9629 - val_loss: 5.8467 - val_acc: 0.4033\nEpoch 259/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2024 - acc: 0.9614 - val_loss: 5.8670 - val_acc: 0.4067\nEpoch 260/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2021 - acc: 0.9629 - val_loss: 5.8740 - val_acc: 0.4100\nEpoch 261/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2023 - acc: 0.9629 - val_loss: 5.8535 - val_acc: 0.4100\nEpoch 262/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2023 - acc: 0.9614 - val_loss: 5.8885 - val_acc: 0.4200\nEpoch 263/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.2023 - acc: 0.9614 - val_loss: 5.8381 - val_acc: 0.4133\nEpoch 264/1000\n700/700 [==============================] - 0s 68us/sample - loss: 0.2022 - acc: 0.9629 - val_loss: 5.8814 - val_acc: 0.4167\nEpoch 265/1000\n700/700 [==============================] - 0s 174us/sample - loss: 0.2020 - acc: 0.9643 - val_loss: 5.8688 - val_acc: 0.4033\nEpoch 266/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.2019 - acc: 0.9614 - val_loss: 5.8653 - val_acc: 0.4100\nEpoch 267/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.2022 - acc: 0.9629 - val_loss: 5.8692 - val_acc: 0.4133\nEpoch 268/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2018 - acc: 0.9629 - val_loss: 5.8691 - val_acc: 0.4067\nEpoch 269/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2020 - acc: 0.9643 - val_loss: 5.8899 - val_acc: 0.4133\nEpoch 270/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2020 - acc: 0.9629 - val_loss: 5.8929 - val_acc: 0.4100\nEpoch 271/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2021 - acc: 0.9629 - val_loss: 5.8886 - val_acc: 0.4133\nEpoch 272/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2019 - acc: 0.9629 - val_loss: 5.8752 - val_acc: 0.4033\nEpoch 273/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.2021 - acc: 0.9614 - val_loss: 5.8756 - val_acc: 0.4133\nEpoch 274/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2018 - acc: 0.9629 - val_loss: 5.8797 - val_acc: 0.4100\nEpoch 275/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2016 - acc: 0.9629 - val_loss: 5.8973 - val_acc: 0.4067\nEpoch 276/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2023 - acc: 0.9629 - val_loss: 5.8719 - val_acc: 0.4033\nEpoch 277/1000\n 10/700 [..............................] - ETA: 0s - loss: 0.4099 - acc: 0.900700/700 [==============================] - 0s 83us/sample - loss: 0.2019 - acc: 0.9629 - val_loss: 5.8831 - val_acc: 0.4067\nEpoch 278/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2018 - acc: 0.9629 - val_loss: 5.8852 - val_acc: 0.4033\nEpoch 279/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2015 - acc: 0.9614 - val_loss: 5.9105 - val_acc: 0.4167\nEpoch 280/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2019 - acc: 0.9614 - val_loss: 5.8677 - val_acc: 0.4067\nEpoch 281/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2019 - acc: 0.9629 - val_loss: 5.9055 - val_acc: 0.4033\nEpoch 282/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2019 - acc: 0.9629 - val_loss: 5.8851 - val_acc: 0.4067\nEpoch 283/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2017 - acc: 0.9643 - val_loss: 5.8797 - val_acc: 0.4067\nEpoch 284/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2019 - acc: 0.9643 - val_loss: 5.8795 - val_acc: 0.4100\nEpoch 285/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.2018 - acc: 0.9614 - val_loss: 5.8850 - val_acc: 0.4033\nEpoch 286/1000\n700/700 [==============================] - 0s 144us/sample - loss: 0.2014 - acc: 0.9629 - val_loss: 5.8760 - val_acc: 0.4067\nEpoch 287/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2016 - acc: 0.9614 - val_loss: 5.8783 - val_acc: 0.4067\nEpoch 288/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2013 - acc: 0.9643 - val_loss: 5.8915 - val_acc: 0.4100\nEpoch 289/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2016 - acc: 0.9614 - val_loss: 5.9097 - val_acc: 0.4133\nEpoch 290/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2018 - acc: 0.9629 - val_loss: 5.8601 - val_acc: 0.4033\nEpoch 291/1000\n700/700 [==============================] - 0s 127us/sample - loss: 0.2012 - acc: 0.9629 - val_loss: 5.9084 - val_acc: 0.4067\nEpoch 292/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2014 - acc: 0.9629 - val_loss: 5.9256 - val_acc: 0.4133\nEpoch 293/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2014 - acc: 0.9614 - val_loss: 5.8808 - val_acc: 0.4067\nEpoch 294/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.2011 - acc: 0.9629 - val_loss: 5.8968 - val_acc: 0.4067\nEpoch 295/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.2014 - acc: 0.9614 - val_loss: 5.8851 - val_acc: 0.4067\nEpoch 296/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.2013 - acc: 0.9643 - val_loss: 5.9172 - val_acc: 0.4133\nEpoch 297/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2012 - acc: 0.9614 - val_loss: 5.8795 - val_acc: 0.4067\nEpoch 298/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2012 - acc: 0.9629 - val_loss: 5.9344 - val_acc: 0.4200\nEpoch 299/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.2009 - acc: 0.9629 - val_loss: 5.9239 - val_acc: 0.4133\nEpoch 300/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.2011 - acc: 0.9614 - val_loss: 5.8966 - val_acc: 0.4100\nEpoch 301/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2019 - acc: 0.9643 - val_loss: 5.9293 - val_acc: 0.4200\nEpoch 302/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2014 - acc: 0.9643 - val_loss: 5.9135 - val_acc: 0.4133\nEpoch 303/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2012 - acc: 0.9629 - val_loss: 5.8849 - val_acc: 0.4100\nEpoch 304/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2014 - acc: 0.9643 - val_loss: 5.9052 - val_acc: 0.4033\nEpoch 305/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.2009 - acc: 0.9643 - val_loss: 5.9140 - val_acc: 0.4033\nEpoch 306/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.2009 - acc: 0.9643 - val_loss: 5.9216 - val_acc: 0.4067\nEpoch 307/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2009 - acc: 0.9614 - val_loss: 5.9166 - val_acc: 0.4033\nEpoch 308/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.2011 - acc: 0.9614 - val_loss: 5.9171 - val_acc: 0.4067\nEpoch 309/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.2006 - acc: 0.9629 - val_loss: 5.9227 - val_acc: 0.4033\nEpoch 310/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2011 - acc: 0.9643 - val_loss: 5.9020 - val_acc: 0.4100\nEpoch 311/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.2010 - acc: 0.9614 - val_loss: 5.9159 - val_acc: 0.4100\nEpoch 312/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2010 - acc: 0.9614 - val_loss: 5.9027 - val_acc: 0.4033\nEpoch 313/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2007 - acc: 0.9643 - val_loss: 5.9545 - val_acc: 0.4200\nEpoch 314/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2011 - acc: 0.9643 - val_loss: 5.8916 - val_acc: 0.4033\nEpoch 315/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.2008 - acc: 0.9629 - val_loss: 5.9529 - val_acc: 0.4167\nEpoch 316/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.2014 - acc: 0.9643 - val_loss: 5.9103 - val_acc: 0.4033\nEpoch 317/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2009 - acc: 0.9629 - val_loss: 5.9430 - val_acc: 0.4167\nEpoch 318/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2009 - acc: 0.9643 - val_loss: 5.9320 - val_acc: 0.4133\nEpoch 319/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2009 - acc: 0.9629 - val_loss: 5.9480 - val_acc: 0.4167\nEpoch 320/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2010 - acc: 0.9643 - val_loss: 5.9232 - val_acc: 0.4033\nEpoch 321/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2009 - acc: 0.9643 - val_loss: 5.9133 - val_acc: 0.4033\nEpoch 322/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2011 - acc: 0.9643 - val_loss: 5.9017 - val_acc: 0.4067\nEpoch 323/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.2008 - acc: 0.9643 - val_loss: 5.9422 - val_acc: 0.4067\nEpoch 324/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2008 - acc: 0.9643 - val_loss: 5.9422 - val_acc: 0.4100\nEpoch 325/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2007 - acc: 0.9643 - val_loss: 5.9247 - val_acc: 0.4100\nEpoch 326/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2006 - acc: 0.9629 - val_loss: 5.9308 - val_acc: 0.4100\nEpoch 327/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.2000 - acc: 0.9643 - val_loss: 5.9299 - val_acc: 0.4067\nEpoch 328/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.2007 - acc: 0.9629 - val_loss: 5.9256 - val_acc: 0.4100\nEpoch 329/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2004 - acc: 0.9629 - val_loss: 5.9549 - val_acc: 0.4133\nEpoch 330/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2005 - acc: 0.9643 - val_loss: 5.9125 - val_acc: 0.4100\nEpoch 331/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2004 - acc: 0.9629 - val_loss: 5.9347 - val_acc: 0.4100\nEpoch 332/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2005 - acc: 0.9629 - val_loss: 5.9228 - val_acc: 0.4100\nEpoch 333/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2006 - acc: 0.9629 - val_loss: 5.9171 - val_acc: 0.4067\nEpoch 334/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2006 - acc: 0.9643 - val_loss: 5.9436 - val_acc: 0.4033\nEpoch 335/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2002 - acc: 0.9629 - val_loss: 5.9417 - val_acc: 0.4100\nEpoch 336/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2003 - acc: 0.9629 - val_loss: 5.9178 - val_acc: 0.4000\nEpoch 337/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2005 - acc: 0.9643 - val_loss: 5.9225 - val_acc: 0.4100\nEpoch 338/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2002 - acc: 0.9629 - val_loss: 5.9486 - val_acc: 0.4100\nEpoch 339/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2002 - acc: 0.9643 - val_loss: 5.9781 - val_acc: 0.4100\nEpoch 340/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2001 - acc: 0.9643 - val_loss: 5.9422 - val_acc: 0.4067\nEpoch 341/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2000 - acc: 0.9643 - val_loss: 5.9630 - val_acc: 0.4033\nEpoch 342/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2003 - acc: 0.9643 - val_loss: 5.9460 - val_acc: 0.4100\nEpoch 343/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.2001 - acc: 0.9643 - val_loss: 5.9581 - val_acc: 0.4133\nEpoch 344/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.2000 - acc: 0.9643 - val_loss: 5.9273 - val_acc: 0.4067\nEpoch 345/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.1998 - acc: 0.9629 - val_loss: 5.9546 - val_acc: 0.4033\nEpoch 346/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1999 - acc: 0.9629 - val_loss: 5.9628 - val_acc: 0.4133\nEpoch 347/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.2001 - acc: 0.9643 - val_loss: 5.9358 - val_acc: 0.4033\nEpoch 348/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1999 - acc: 0.9629 - val_loss: 5.9531 - val_acc: 0.4100\nEpoch 349/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1998 - acc: 0.9629 - val_loss: 5.9552 - val_acc: 0.4033\nEpoch 350/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.2002 - acc: 0.9643 - val_loss: 5.9871 - val_acc: 0.4100\nEpoch 351/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.1998 - acc: 0.9643 - val_loss: 5.9741 - val_acc: 0.4133\nEpoch 352/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1998 - acc: 0.9643 - val_loss: 5.9815 - val_acc: 0.4100\nEpoch 353/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1997 - acc: 0.9629 - val_loss: 5.9720 - val_acc: 0.4100\nEpoch 354/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1997 - acc: 0.9614 - val_loss: 5.9781 - val_acc: 0.4167\nEpoch 355/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.2000 - acc: 0.9629 - val_loss: 5.9704 - val_acc: 0.4100\nEpoch 356/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1999 - acc: 0.9629 - val_loss: 5.9584 - val_acc: 0.4100\nEpoch 357/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.1997 - acc: 0.9643 - val_loss: 5.9556 - val_acc: 0.4100\nEpoch 358/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1995 - acc: 0.9629 - val_loss: 5.9193 - val_acc: 0.4067\nEpoch 359/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1997 - acc: 0.9643 - val_loss: 5.9760 - val_acc: 0.4167\nEpoch 360/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.1999 - acc: 0.9629 - val_loss: 5.9679 - val_acc: 0.4067\nEpoch 361/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1996 - acc: 0.9643 - val_loss: 5.9749 - val_acc: 0.4100\nEpoch 362/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1996 - acc: 0.9643 - val_loss: 5.9684 - val_acc: 0.4033\nEpoch 363/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1992 - acc: 0.9614 - val_loss: 5.9624 - val_acc: 0.4100\nEpoch 364/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1996 - acc: 0.9629 - val_loss: 5.9800 - val_acc: 0.4033\nEpoch 365/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1997 - acc: 0.9643 - val_loss: 5.9878 - val_acc: 0.4100\nEpoch 366/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1995 - acc: 0.9629 - val_loss: 5.9917 - val_acc: 0.4100\nEpoch 367/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1995 - acc: 0.9643 - val_loss: 5.9787 - val_acc: 0.4067\nEpoch 368/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1996 - acc: 0.9643 - val_loss: 6.0050 - val_acc: 0.4133\nEpoch 369/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1995 - acc: 0.9643 - val_loss: 5.9764 - val_acc: 0.4033\nEpoch 370/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1998 - acc: 0.9643 - val_loss: 5.9817 - val_acc: 0.4100\nEpoch 371/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1992 - acc: 0.9629 - val_loss: 5.9421 - val_acc: 0.4000\nEpoch 372/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1995 - acc: 0.9643 - val_loss: 5.9791 - val_acc: 0.4100\nEpoch 373/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1995 - acc: 0.9643 - val_loss: 5.9892 - val_acc: 0.4100\nEpoch 374/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1996 - acc: 0.9629 - val_loss: 5.9931 - val_acc: 0.4133\nEpoch 375/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1995 - acc: 0.9643 - val_loss: 6.0073 - val_acc: 0.4067\nEpoch 376/1000\n700/700 [==============================] - 0s 124us/sample - loss: 0.1994 - acc: 0.9643 - val_loss: 5.9969 - val_acc: 0.4133\nEpoch 377/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.2000 - acc: 0.9643 - val_loss: 5.9779 - val_acc: 0.4033\nEpoch 378/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1994 - acc: 0.9643 - val_loss: 6.0056 - val_acc: 0.4100\nEpoch 379/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1991 - acc: 0.9643 - val_loss: 5.9886 - val_acc: 0.4067\nEpoch 380/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1990 - acc: 0.9629 - val_loss: 5.9969 - val_acc: 0.4100\nEpoch 381/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1992 - acc: 0.9629 - val_loss: 5.9624 - val_acc: 0.4033\nEpoch 382/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1993 - acc: 0.9643 - val_loss: 5.9657 - val_acc: 0.4033\nEpoch 383/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1991 - acc: 0.9643 - val_loss: 5.9949 - val_acc: 0.4067\nEpoch 384/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1992 - acc: 0.9643 - val_loss: 6.0036 - val_acc: 0.4067\nEpoch 385/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1995 - acc: 0.9643 - val_loss: 6.0075 - val_acc: 0.4067\nEpoch 386/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1992 - acc: 0.9643 - val_loss: 5.9780 - val_acc: 0.4100\nEpoch 387/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1992 - acc: 0.9643 - val_loss: 5.9781 - val_acc: 0.4033\nEpoch 388/1000\n700/700 [==============================] - 0s 70us/sample - loss: 0.1990 - acc: 0.9643 - val_loss: 6.0281 - val_acc: 0.4133\nEpoch 389/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1994 - acc: 0.9643 - val_loss: 5.9850 - val_acc: 0.4100\nEpoch 390/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1989 - acc: 0.9643 - val_loss: 5.9863 - val_acc: 0.4067\nEpoch 391/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1991 - acc: 0.9629 - val_loss: 6.0034 - val_acc: 0.4067\nEpoch 392/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1989 - acc: 0.9643 - val_loss: 6.0061 - val_acc: 0.4100\nEpoch 393/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1991 - acc: 0.9643 - val_loss: 5.9878 - val_acc: 0.4067\nEpoch 394/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1990 - acc: 0.9643 - val_loss: 5.9844 - val_acc: 0.4100\nEpoch 395/1000\n700/700 [==============================] - 0s 127us/sample - loss: 0.1991 - acc: 0.9629 - val_loss: 6.0196 - val_acc: 0.4067\nEpoch 396/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.1986 - acc: 0.9643 - val_loss: 6.0136 - val_acc: 0.4067\nEpoch 397/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1987 - acc: 0.9643 - val_loss: 5.9925 - val_acc: 0.4000\nEpoch 398/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1990 - acc: 0.9629 - val_loss: 6.0196 - val_acc: 0.4100\nEpoch 399/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1986 - acc: 0.9643 - val_loss: 5.9819 - val_acc: 0.4100\nEpoch 400/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1987 - acc: 0.9643 - val_loss: 6.0249 - val_acc: 0.4100\nEpoch 401/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.1984 - acc: 0.9629 - val_loss: 6.0060 - val_acc: 0.4033\nEpoch 402/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1987 - acc: 0.9643 - val_loss: 6.0203 - val_acc: 0.4067\nEpoch 403/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1989 - acc: 0.9643 - val_loss: 6.0116 - val_acc: 0.4000\nEpoch 404/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1988 - acc: 0.9629 - val_loss: 6.0048 - val_acc: 0.4033\nEpoch 405/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1988 - acc: 0.9629 - val_loss: 6.0009 - val_acc: 0.4000\nEpoch 406/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1989 - acc: 0.9643 - val_loss: 5.9845 - val_acc: 0.4033\nEpoch 407/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1989 - acc: 0.9643 - val_loss: 6.0243 - val_acc: 0.4067\nEpoch 408/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1987 - acc: 0.9643 - val_loss: 6.0181 - val_acc: 0.4067\nEpoch 409/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1985 - acc: 0.9643 - val_loss: 6.0041 - val_acc: 0.4033\nEpoch 410/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1985 - acc: 0.9643 - val_loss: 6.0099 - val_acc: 0.4000\nEpoch 411/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1984 - acc: 0.9629 - val_loss: 6.0180 - val_acc: 0.4033\nEpoch 412/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1988 - acc: 0.9629 - val_loss: 6.0308 - val_acc: 0.4167\nEpoch 413/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1983 - acc: 0.9629 - val_loss: 5.9955 - val_acc: 0.4067\nEpoch 414/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1983 - acc: 0.9643 - val_loss: 6.0307 - val_acc: 0.4033\nEpoch 415/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1986 - acc: 0.9643 - val_loss: 6.0451 - val_acc: 0.4133\nEpoch 416/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1986 - acc: 0.9629 - val_loss: 6.0088 - val_acc: 0.4033\nEpoch 417/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1983 - acc: 0.9643 - val_loss: 6.0267 - val_acc: 0.4100\nEpoch 418/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1984 - acc: 0.9643 - val_loss: 6.0340 - val_acc: 0.4067\nEpoch 419/1000\n700/700 [==============================] - 0s 157us/sample - loss: 0.1985 - acc: 0.9643 - val_loss: 6.0232 - val_acc: 0.4100\nEpoch 420/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1981 - acc: 0.9629 - val_loss: 6.0355 - val_acc: 0.4067\nEpoch 421/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1981 - acc: 0.9643 - val_loss: 6.0361 - val_acc: 0.4033\nEpoch 422/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1981 - acc: 0.9643 - val_loss: 6.0362 - val_acc: 0.4067\nEpoch 423/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1982 - acc: 0.9643 - val_loss: 6.0332 - val_acc: 0.4067\nEpoch 424/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1982 - acc: 0.9629 - val_loss: 6.0359 - val_acc: 0.4100\nEpoch 425/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1984 - acc: 0.9643 - val_loss: 6.0295 - val_acc: 0.4067\nEpoch 426/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1980 - acc: 0.9629 - val_loss: 6.0141 - val_acc: 0.4033\nEpoch 427/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1982 - acc: 0.9629 - val_loss: 6.0416 - val_acc: 0.4100\nEpoch 428/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1981 - acc: 0.9629 - val_loss: 6.0454 - val_acc: 0.4067\nEpoch 429/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1982 - acc: 0.9643 - val_loss: 6.0302 - val_acc: 0.4033\nEpoch 430/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1983 - acc: 0.9643 - val_loss: 6.0294 - val_acc: 0.4033\nEpoch 431/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1980 - acc: 0.9643 - val_loss: 6.0375 - val_acc: 0.4033\nEpoch 432/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1981 - acc: 0.9643 - val_loss: 6.0145 - val_acc: 0.4033\nEpoch 433/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.1978 - acc: 0.9643 - val_loss: 6.0329 - val_acc: 0.4033\nEpoch 434/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1981 - acc: 0.9643 - val_loss: 6.0540 - val_acc: 0.4100\nEpoch 435/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1984 - acc: 0.9643 - val_loss: 6.0531 - val_acc: 0.4033\nEpoch 436/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1981 - acc: 0.9643 - val_loss: 6.0301 - val_acc: 0.4033\nEpoch 437/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1977 - acc: 0.9643 - val_loss: 6.0429 - val_acc: 0.4100\nEpoch 438/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1980 - acc: 0.9643 - val_loss: 6.0498 - val_acc: 0.4067\nEpoch 439/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1978 - acc: 0.9643 - val_loss: 6.0647 - val_acc: 0.4100\nEpoch 440/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1980 - acc: 0.9643 - val_loss: 6.0433 - val_acc: 0.4000\nEpoch 441/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1979 - acc: 0.9643 - val_loss: 6.0416 - val_acc: 0.4067\nEpoch 442/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1982 - acc: 0.9643 - val_loss: 6.0487 - val_acc: 0.4000\nEpoch 443/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1981 - acc: 0.9643 - val_loss: 6.0720 - val_acc: 0.4100\nEpoch 444/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1982 - acc: 0.9643 - val_loss: 6.0398 - val_acc: 0.4033\nEpoch 445/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1977 - acc: 0.9643 - val_loss: 6.0359 - val_acc: 0.4033\nEpoch 446/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1977 - acc: 0.9643 - val_loss: 6.0646 - val_acc: 0.4067\nEpoch 447/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1982 - acc: 0.9643 - val_loss: 6.0628 - val_acc: 0.4100\nEpoch 448/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1976 - acc: 0.9643 - val_loss: 6.0836 - val_acc: 0.4100\nEpoch 449/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.1977 - acc: 0.9643 - val_loss: 6.0787 - val_acc: 0.4100\nEpoch 450/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.1977 - acc: 0.9643 - val_loss: 6.0587 - val_acc: 0.4100\nEpoch 451/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0586 - val_acc: 0.4100\nEpoch 452/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1974 - acc: 0.9643 - val_loss: 6.0600 - val_acc: 0.4033\nEpoch 453/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1975 - acc: 0.9643 - val_loss: 6.0588 - val_acc: 0.4067\nEpoch 454/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0713 - val_acc: 0.4033\nEpoch 455/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1975 - acc: 0.9643 - val_loss: 6.0782 - val_acc: 0.4100\nEpoch 456/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1975 - acc: 0.9643 - val_loss: 6.0783 - val_acc: 0.4067\nEpoch 457/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1975 - acc: 0.9643 - val_loss: 6.0573 - val_acc: 0.4000\nEpoch 458/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1974 - acc: 0.9643 - val_loss: 6.0957 - val_acc: 0.4100\nEpoch 459/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0564 - val_acc: 0.4000\nEpoch 460/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1974 - acc: 0.9643 - val_loss: 6.0514 - val_acc: 0.4000\nEpoch 461/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1972 - acc: 0.9643 - val_loss: 6.0571 - val_acc: 0.4000\nEpoch 462/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1972 - acc: 0.9643 - val_loss: 6.0787 - val_acc: 0.4100\nEpoch 463/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1971 - acc: 0.9643 - val_loss: 6.0842 - val_acc: 0.4100\nEpoch 464/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0902 - val_acc: 0.4133\nEpoch 465/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0753 - val_acc: 0.4033\nEpoch 466/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.1971 - acc: 0.9643 - val_loss: 6.0699 - val_acc: 0.4000\nEpoch 467/1000\n700/700 [==============================] - 0s 127us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0653 - val_acc: 0.4033\nEpoch 468/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.1969 - acc: 0.9643 - val_loss: 6.0702 - val_acc: 0.4033\nEpoch 469/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1968 - acc: 0.9643 - val_loss: 6.0717 - val_acc: 0.4067\nEpoch 470/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.1971 - acc: 0.9643 - val_loss: 6.0739 - val_acc: 0.4033\nEpoch 471/1000\n700/700 [==============================] - 0s 113us/sample - loss: 0.1968 - acc: 0.9643 - val_loss: 6.0876 - val_acc: 0.4100\nEpoch 472/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0929 - val_acc: 0.4067\nEpoch 473/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1975 - acc: 0.9643 - val_loss: 6.0872 - val_acc: 0.4067\nEpoch 474/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1973 - acc: 0.9643 - val_loss: 6.0894 - val_acc: 0.4067\nEpoch 475/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1971 - acc: 0.9643 - val_loss: 6.0649 - val_acc: 0.4033\nEpoch 476/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1972 - acc: 0.9643 - val_loss: 6.1131 - val_acc: 0.4100\nEpoch 477/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1969 - acc: 0.9643 - val_loss: 6.1054 - val_acc: 0.4133\nEpoch 478/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1969 - acc: 0.9643 - val_loss: 6.0844 - val_acc: 0.4033\nEpoch 479/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1967 - acc: 0.9643 - val_loss: 6.1060 - val_acc: 0.4100\nEpoch 480/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1970 - acc: 0.9643 - val_loss: 6.0695 - val_acc: 0.4000\nEpoch 481/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1968 - acc: 0.9643 - val_loss: 6.0678 - val_acc: 0.3967\nEpoch 482/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1968 - acc: 0.9643 - val_loss: 6.0854 - val_acc: 0.4033\nEpoch 483/1000\n700/700 [==============================] - 0s 124us/sample - loss: 0.1970 - acc: 0.9643 - val_loss: 6.0840 - val_acc: 0.4067\nEpoch 484/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1969 - acc: 0.9643 - val_loss: 6.0990 - val_acc: 0.4033\nEpoch 485/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1966 - acc: 0.9643 - val_loss: 6.0948 - val_acc: 0.4067\nEpoch 486/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1966 - acc: 0.9643 - val_loss: 6.0809 - val_acc: 0.4000\nEpoch 487/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1965 - acc: 0.9643 - val_loss: 6.0959 - val_acc: 0.4000\nEpoch 488/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1968 - acc: 0.9643 - val_loss: 6.1014 - val_acc: 0.4033\nEpoch 489/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1966 - acc: 0.9643 - val_loss: 6.0796 - val_acc: 0.4033\nEpoch 490/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1966 - acc: 0.9629 - val_loss: 6.1108 - val_acc: 0.4100\nEpoch 491/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1966 - acc: 0.9643 - val_loss: 6.1064 - val_acc: 0.4033\nEpoch 492/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1968 - acc: 0.9643 - val_loss: 6.0810 - val_acc: 0.4067\nEpoch 493/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1966 - acc: 0.9643 - val_loss: 6.1022 - val_acc: 0.4033\nEpoch 494/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1967 - acc: 0.9643 - val_loss: 6.1162 - val_acc: 0.4067\nEpoch 495/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1967 - acc: 0.9643 - val_loss: 6.1005 - val_acc: 0.4067\nEpoch 496/1000\n700/700 [==============================] - 0s 134us/sample - loss: 0.1964 - acc: 0.9643 - val_loss: 6.0988 - val_acc: 0.4000\nEpoch 497/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1965 - acc: 0.9643 - val_loss: 6.1013 - val_acc: 0.4000\nEpoch 498/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1969 - acc: 0.9643 - val_loss: 6.1118 - val_acc: 0.4000\nEpoch 499/1000\n700/700 [==============================] - 0s 123us/sample - loss: 0.1964 - acc: 0.9643 - val_loss: 6.1085 - val_acc: 0.4067\nEpoch 500/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1966 - acc: 0.9643 - val_loss: 6.1040 - val_acc: 0.4000\nEpoch 501/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1964 - acc: 0.9643 - val_loss: 6.1026 - val_acc: 0.4000\nEpoch 502/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1965 - acc: 0.9643 - val_loss: 6.1170 - val_acc: 0.4067\nEpoch 503/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1963 - acc: 0.9643 - val_loss: 6.1274 - val_acc: 0.4100\nEpoch 504/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1963 - acc: 0.9643 - val_loss: 6.1432 - val_acc: 0.4067\nEpoch 505/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1964 - acc: 0.9643 - val_loss: 6.0994 - val_acc: 0.4033\nEpoch 506/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1214 - val_acc: 0.4100\nEpoch 507/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1964 - acc: 0.9643 - val_loss: 6.1163 - val_acc: 0.4033\nEpoch 508/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1045 - val_acc: 0.3967\nEpoch 509/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1962 - acc: 0.9643 - val_loss: 6.1184 - val_acc: 0.4067\nEpoch 510/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1963 - acc: 0.9643 - val_loss: 6.1360 - val_acc: 0.4033\nEpoch 511/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1960 - acc: 0.9643 - val_loss: 6.1181 - val_acc: 0.4033\nEpoch 512/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1963 - acc: 0.9643 - val_loss: 6.1205 - val_acc: 0.4033\nEpoch 513/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1350 - val_acc: 0.4100\nEpoch 514/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1962 - acc: 0.9643 - val_loss: 6.1422 - val_acc: 0.4100\nEpoch 515/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1192 - val_acc: 0.3967\nEpoch 516/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1962 - acc: 0.9643 - val_loss: 6.1055 - val_acc: 0.4000\nEpoch 517/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1135 - val_acc: 0.4000\nEpoch 518/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1960 - acc: 0.9643 - val_loss: 6.1293 - val_acc: 0.4000\nEpoch 519/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1958 - acc: 0.9643 - val_loss: 6.1103 - val_acc: 0.3967\nEpoch 520/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1958 - acc: 0.9643 - val_loss: 6.1259 - val_acc: 0.4067\nEpoch 521/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1963 - acc: 0.9643 - val_loss: 6.1653 - val_acc: 0.4033\nEpoch 522/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1962 - acc: 0.9643 - val_loss: 6.1472 - val_acc: 0.4033\nEpoch 523/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1958 - acc: 0.9643 - val_loss: 6.1439 - val_acc: 0.4033\nEpoch 524/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1959 - acc: 0.9643 - val_loss: 6.1393 - val_acc: 0.4033\nEpoch 525/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1957 - acc: 0.9643 - val_loss: 6.1475 - val_acc: 0.4033\nEpoch 526/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1368 - val_acc: 0.4000\nEpoch 527/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1961 - acc: 0.9643 - val_loss: 6.1371 - val_acc: 0.3967\nEpoch 528/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1960 - acc: 0.9643 - val_loss: 6.1523 - val_acc: 0.4067\nEpoch 529/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1959 - acc: 0.9643 - val_loss: 6.1325 - val_acc: 0.4033\nEpoch 530/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1105 - val_acc: 0.4033\nEpoch 531/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1959 - acc: 0.9643 - val_loss: 6.1329 - val_acc: 0.4000\nEpoch 532/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1957 - acc: 0.9643 - val_loss: 6.1133 - val_acc: 0.3967\nEpoch 533/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1958 - acc: 0.9643 - val_loss: 6.1419 - val_acc: 0.4067\nEpoch 534/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1960 - acc: 0.9643 - val_loss: 6.1391 - val_acc: 0.4000\nEpoch 535/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1957 - acc: 0.9643 - val_loss: 6.1464 - val_acc: 0.4000\nEpoch 536/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1957 - acc: 0.9643 - val_loss: 6.1299 - val_acc: 0.3967\nEpoch 537/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1205 - val_acc: 0.4000\nEpoch 538/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1955 - acc: 0.9643 - val_loss: 6.1385 - val_acc: 0.4033\nEpoch 539/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1954 - acc: 0.9643 - val_loss: 6.1535 - val_acc: 0.4033\nEpoch 540/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1667 - val_acc: 0.4100\nEpoch 541/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1957 - acc: 0.9643 - val_loss: 6.1702 - val_acc: 0.4133\nEpoch 542/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1351 - val_acc: 0.3967\nEpoch 543/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1548 - val_acc: 0.4000\nEpoch 544/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1954 - acc: 0.9643 - val_loss: 6.1585 - val_acc: 0.4067\nEpoch 545/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1636 - val_acc: 0.4033\nEpoch 546/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1666 - val_acc: 0.4067\nEpoch 547/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1955 - acc: 0.9643 - val_loss: 6.1641 - val_acc: 0.4067\nEpoch 548/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1615 - val_acc: 0.4033\nEpoch 549/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1953 - acc: 0.9643 - val_loss: 6.1465 - val_acc: 0.4033\nEpoch 550/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1611 - val_acc: 0.4033\nEpoch 551/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1954 - acc: 0.9643 - val_loss: 6.1691 - val_acc: 0.4100\nEpoch 552/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.1950 - acc: 0.9643 - val_loss: 6.1847 - val_acc: 0.4033\nEpoch 553/1000\n700/700 [==============================] - 0s 140us/sample - loss: 0.1956 - acc: 0.9643 - val_loss: 6.1426 - val_acc: 0.4000\nEpoch 554/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1397 - val_acc: 0.4000\nEpoch 555/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1954 - acc: 0.9643 - val_loss: 6.1411 - val_acc: 0.4000\nEpoch 556/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1954 - acc: 0.9643 - val_loss: 6.1391 - val_acc: 0.4000\nEpoch 557/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1951 - acc: 0.9643 - val_loss: 6.1899 - val_acc: 0.4033\nEpoch 558/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1954 - acc: 0.9643 - val_loss: 6.1447 - val_acc: 0.3967\nEpoch 559/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1835 - val_acc: 0.4067\nEpoch 560/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1951 - acc: 0.9643 - val_loss: 6.1605 - val_acc: 0.4000\nEpoch 561/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1950 - acc: 0.9643 - val_loss: 6.1563 - val_acc: 0.4000\nEpoch 562/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1951 - acc: 0.9643 - val_loss: 6.1424 - val_acc: 0.4000\nEpoch 563/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1951 - acc: 0.9643 - val_loss: 6.1750 - val_acc: 0.4000\nEpoch 564/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1949 - acc: 0.9643 - val_loss: 6.1797 - val_acc: 0.4000\nEpoch 565/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1951 - acc: 0.9643 - val_loss: 6.1624 - val_acc: 0.4033\nEpoch 566/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1659 - val_acc: 0.4067\nEpoch 567/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 6.1499 - val_acc: 0.4000\nEpoch 568/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1949 - acc: 0.9643 - val_loss: 6.1895 - val_acc: 0.4067\nEpoch 569/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1949 - acc: 0.9643 - val_loss: 6.1844 - val_acc: 0.4033\nEpoch 570/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1953 - acc: 0.9643 - val_loss: 6.1532 - val_acc: 0.3967\nEpoch 571/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1948 - acc: 0.9643 - val_loss: 6.1997 - val_acc: 0.4033\nEpoch 572/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1947 - acc: 0.9643 - val_loss: 6.2029 - val_acc: 0.4067\nEpoch 573/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1946 - acc: 0.9643 - val_loss: 6.1746 - val_acc: 0.4000\nEpoch 574/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1948 - acc: 0.9643 - val_loss: 6.1601 - val_acc: 0.3967\nEpoch 575/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1949 - acc: 0.9643 - val_loss: 6.2064 - val_acc: 0.4067\nEpoch 576/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1949 - acc: 0.9643 - val_loss: 6.1728 - val_acc: 0.4033\nEpoch 577/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1945 - acc: 0.9643 - val_loss: 6.1872 - val_acc: 0.3967\nEpoch 578/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1948 - acc: 0.9643 - val_loss: 6.1991 - val_acc: 0.4033\nEpoch 579/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1950 - acc: 0.9643 - val_loss: 6.1944 - val_acc: 0.4033\nEpoch 580/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1945 - acc: 0.9643 - val_loss: 6.1949 - val_acc: 0.4033\nEpoch 581/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1946 - acc: 0.9643 - val_loss: 6.1923 - val_acc: 0.4000\nEpoch 582/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1948 - acc: 0.9643 - val_loss: 6.1838 - val_acc: 0.4000\nEpoch 583/1000\n700/700 [==============================] - 0s 189us/sample - loss: 0.1947 - acc: 0.9643 - val_loss: 6.1737 - val_acc: 0.3967\nEpoch 584/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1948 - acc: 0.9643 - val_loss: 6.1900 - val_acc: 0.4000\nEpoch 585/1000\n530/700 [=====================>........] - ETA: 0s - loss: 0.1991 - acc: 0.966700/700 [==============================] - 0s 105us/sample - loss: 0.1944 - acc: 0.9643 - val_loss: 6.1784 - val_acc: 0.3967\nEpoch 586/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1946 - acc: 0.9643 - val_loss: 6.1906 - val_acc: 0.4067\nEpoch 587/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1943 - acc: 0.9643 - val_loss: 6.1815 - val_acc: 0.4000\nEpoch 588/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1945 - acc: 0.9643 - val_loss: 6.1953 - val_acc: 0.4100\nEpoch 589/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1943 - acc: 0.9643 - val_loss: 6.1974 - val_acc: 0.4000\nEpoch 590/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1947 - acc: 0.9643 - val_loss: 6.1983 - val_acc: 0.4000\nEpoch 591/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1947 - acc: 0.9643 - val_loss: 6.1798 - val_acc: 0.4033\nEpoch 592/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1948 - acc: 0.9643 - val_loss: 6.2048 - val_acc: 0.4000\nEpoch 593/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 6.1941 - val_acc: 0.4067\nEpoch 594/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1945 - acc: 0.9643 - val_loss: 6.1878 - val_acc: 0.3967\nEpoch 595/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1946 - acc: 0.9643 - val_loss: 6.1865 - val_acc: 0.3967\nEpoch 596/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1941 - acc: 0.9643 - val_loss: 6.2076 - val_acc: 0.4000\nEpoch 597/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1944 - acc: 0.9643 - val_loss: 6.1779 - val_acc: 0.4000\nEpoch 598/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1941 - acc: 0.9643 - val_loss: 6.2375 - val_acc: 0.4067\nEpoch 599/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1943 - acc: 0.9643 - val_loss: 6.2058 - val_acc: 0.4067\nEpoch 600/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 6.1977 - val_acc: 0.3967\nEpoch 601/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1944 - acc: 0.9643 - val_loss: 6.1713 - val_acc: 0.3967\nEpoch 602/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1940 - acc: 0.9643 - val_loss: 6.2074 - val_acc: 0.4000\nEpoch 603/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2114 - val_acc: 0.4000\nEpoch 604/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.1941 - acc: 0.9643 - val_loss: 6.1918 - val_acc: 0.3967\nEpoch 605/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 6.2115 - val_acc: 0.4000\nEpoch 606/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1939 - acc: 0.9643 - val_loss: 6.2189 - val_acc: 0.4000\nEpoch 607/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1944 - acc: 0.9643 - val_loss: 6.2088 - val_acc: 0.4000\nEpoch 608/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 6.1979 - val_acc: 0.3967\nEpoch 609/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1943 - acc: 0.9643 - val_loss: 6.2327 - val_acc: 0.4067\nEpoch 610/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2033 - val_acc: 0.3967\nEpoch 611/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1944 - acc: 0.9643 - val_loss: 6.2086 - val_acc: 0.3967\nEpoch 612/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1945 - acc: 0.9643 - val_loss: 6.2189 - val_acc: 0.4033\nEpoch 613/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 6.2298 - val_acc: 0.4067\nEpoch 614/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1940 - acc: 0.9643 - val_loss: 6.2243 - val_acc: 0.4033\nEpoch 615/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1939 - acc: 0.9643 - val_loss: 6.2375 - val_acc: 0.4033\nEpoch 616/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2399 - val_acc: 0.4067\nEpoch 617/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 6.2400 - val_acc: 0.4067\nEpoch 618/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1937 - acc: 0.9643 - val_loss: 6.2404 - val_acc: 0.4067\nEpoch 619/1000\n700/700 [==============================] - 0s 130us/sample - loss: 0.1943 - acc: 0.9643 - val_loss: 6.2442 - val_acc: 0.4033\nEpoch 620/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1939 - acc: 0.9643 - val_loss: 6.2520 - val_acc: 0.4133\nEpoch 621/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.1939 - acc: 0.9643 - val_loss: 6.2316 - val_acc: 0.4067\nEpoch 622/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2215 - val_acc: 0.3967\nEpoch 623/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2582 - val_acc: 0.4033\nEpoch 624/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2487 - val_acc: 0.4067\nEpoch 625/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1937 - acc: 0.9643 - val_loss: 6.2208 - val_acc: 0.3967\nEpoch 626/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1941 - acc: 0.9643 - val_loss: 6.2187 - val_acc: 0.4000\nEpoch 627/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2274 - val_acc: 0.4000\nEpoch 628/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1937 - acc: 0.9643 - val_loss: 6.2395 - val_acc: 0.4033\nEpoch 629/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1936 - acc: 0.9643 - val_loss: 6.2267 - val_acc: 0.4000\nEpoch 630/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1939 - acc: 0.9643 - val_loss: 6.2342 - val_acc: 0.4033\nEpoch 631/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2351 - val_acc: 0.4000\nEpoch 632/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1935 - acc: 0.9643 - val_loss: 6.2306 - val_acc: 0.4000\nEpoch 633/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1935 - acc: 0.9643 - val_loss: 6.2294 - val_acc: 0.4000\nEpoch 634/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1938 - acc: 0.9643 - val_loss: 6.2611 - val_acc: 0.4067\nEpoch 635/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2693 - val_acc: 0.4067\nEpoch 636/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.1934 - acc: 0.9643 - val_loss: 6.2060 - val_acc: 0.3967\nEpoch 637/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.1935 - acc: 0.9643 - val_loss: 6.2564 - val_acc: 0.4067\nEpoch 638/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2469 - val_acc: 0.4033\nEpoch 639/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1934 - acc: 0.9643 - val_loss: 6.2562 - val_acc: 0.4033\nEpoch 640/1000\n700/700 [==============================] - 0s 135us/sample - loss: 0.1934 - acc: 0.9643 - val_loss: 6.2343 - val_acc: 0.4033\nEpoch 641/1000\n700/700 [==============================] - 0s 164us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2579 - val_acc: 0.4067\nEpoch 642/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1935 - acc: 0.9643 - val_loss: 6.2477 - val_acc: 0.4033\nEpoch 643/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.1931 - acc: 0.9643 - val_loss: 6.2401 - val_acc: 0.4000\nEpoch 644/1000\n700/700 [==============================] - 0s 131us/sample - loss: 0.1933 - acc: 0.9643 - val_loss: 6.2539 - val_acc: 0.4033\nEpoch 645/1000\n700/700 [==============================] - 0s 113us/sample - loss: 0.1931 - acc: 0.9643 - val_loss: 6.2780 - val_acc: 0.4167\nEpoch 646/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.1934 - acc: 0.9643 - val_loss: 6.2598 - val_acc: 0.3967\nEpoch 647/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1939 - acc: 0.9643 - val_loss: 6.2705 - val_acc: 0.4133\nEpoch 648/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2613 - val_acc: 0.4033\nEpoch 649/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1933 - acc: 0.9643 - val_loss: 6.2509 - val_acc: 0.4000\nEpoch 650/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.1931 - acc: 0.9643 - val_loss: 6.2534 - val_acc: 0.4033\nEpoch 651/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2611 - val_acc: 0.4067\nEpoch 652/1000\n700/700 [==============================] - 0s 131us/sample - loss: 0.1933 - acc: 0.9643 - val_loss: 6.2499 - val_acc: 0.4000\nEpoch 653/1000\n700/700 [==============================] - 0s 114us/sample - loss: 0.1933 - acc: 0.9643 - val_loss: 6.2566 - val_acc: 0.4100\nEpoch 654/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2549 - val_acc: 0.4067\nEpoch 655/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1929 - acc: 0.9643 - val_loss: 6.2564 - val_acc: 0.3967\nEpoch 656/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1932 - acc: 0.9643 - val_loss: 6.2350 - val_acc: 0.4067\nEpoch 657/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1933 - acc: 0.9643 - val_loss: 6.2643 - val_acc: 0.4033\nEpoch 658/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1930 - acc: 0.9643 - val_loss: 6.2784 - val_acc: 0.4067\nEpoch 659/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1930 - acc: 0.9643 - val_loss: 6.2777 - val_acc: 0.4000\nEpoch 660/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1931 - acc: 0.9643 - val_loss: 6.2844 - val_acc: 0.4033\nEpoch 661/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1931 - acc: 0.9643 - val_loss: 6.2743 - val_acc: 0.4000\nEpoch 662/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1928 - acc: 0.9643 - val_loss: 6.2640 - val_acc: 0.3967\nEpoch 663/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1931 - acc: 0.9643 - val_loss: 6.2446 - val_acc: 0.3967\nEpoch 664/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1930 - acc: 0.9643 - val_loss: 6.2741 - val_acc: 0.4033\nEpoch 665/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1929 - acc: 0.9643 - val_loss: 6.2635 - val_acc: 0.3967\nEpoch 666/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1929 - acc: 0.9643 - val_loss: 6.2857 - val_acc: 0.4033\nEpoch 667/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1927 - acc: 0.9643 - val_loss: 6.2819 - val_acc: 0.4033\nEpoch 668/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1929 - acc: 0.9643 - val_loss: 6.2823 - val_acc: 0.4033\nEpoch 669/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1927 - acc: 0.9643 - val_loss: 6.2760 - val_acc: 0.4033\nEpoch 670/1000\n700/700 [==============================] - 0s 125us/sample - loss: 0.1930 - acc: 0.9643 - val_loss: 6.2753 - val_acc: 0.4000\nEpoch 671/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1928 - acc: 0.9643 - val_loss: 6.2692 - val_acc: 0.3967\nEpoch 672/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1927 - acc: 0.9643 - val_loss: 6.2977 - val_acc: 0.4067\nEpoch 673/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1928 - acc: 0.9643 - val_loss: 6.2788 - val_acc: 0.4033\nEpoch 674/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1926 - acc: 0.9643 - val_loss: 6.2719 - val_acc: 0.4000\nEpoch 675/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1926 - acc: 0.9643 - val_loss: 6.2803 - val_acc: 0.4033\nEpoch 676/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.2657 - val_acc: 0.4000\nEpoch 677/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1927 - acc: 0.9643 - val_loss: 6.2717 - val_acc: 0.4033\nEpoch 678/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1925 - acc: 0.9643 - val_loss: 6.2620 - val_acc: 0.3967\nEpoch 679/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1926 - acc: 0.9643 - val_loss: 6.2665 - val_acc: 0.4000\nEpoch 680/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1925 - acc: 0.9643 - val_loss: 6.2576 - val_acc: 0.3967\nEpoch 681/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1928 - acc: 0.9643 - val_loss: 6.2873 - val_acc: 0.4000\nEpoch 682/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1923 - acc: 0.9643 - val_loss: 6.2898 - val_acc: 0.4033\nEpoch 683/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1927 - acc: 0.9643 - val_loss: 6.2673 - val_acc: 0.3967\nEpoch 684/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1928 - acc: 0.9643 - val_loss: 6.2776 - val_acc: 0.3967\nEpoch 685/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.2901 - val_acc: 0.4033\nEpoch 686/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1923 - acc: 0.9643 - val_loss: 6.3002 - val_acc: 0.4033\nEpoch 687/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.2720 - val_acc: 0.4000\nEpoch 688/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1922 - acc: 0.9643 - val_loss: 6.3082 - val_acc: 0.4033\nEpoch 689/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1923 - acc: 0.9643 - val_loss: 6.2939 - val_acc: 0.4033\nEpoch 690/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.2873 - val_acc: 0.4000\nEpoch 691/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1925 - acc: 0.9643 - val_loss: 6.2495 - val_acc: 0.3967\nEpoch 692/1000\n700/700 [==============================] - 0s 124us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.2856 - val_acc: 0.4000\nEpoch 693/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1925 - acc: 0.9643 - val_loss: 6.3122 - val_acc: 0.4033\nEpoch 694/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.3139 - val_acc: 0.4100\nEpoch 695/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1922 - acc: 0.9643 - val_loss: 6.3085 - val_acc: 0.4067\nEpoch 696/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1926 - acc: 0.9643 - val_loss: 6.2937 - val_acc: 0.4067\nEpoch 697/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1920 - acc: 0.9643 - val_loss: 6.2667 - val_acc: 0.4000\nEpoch 698/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1923 - acc: 0.9643 - val_loss: 6.2941 - val_acc: 0.4033\nEpoch 699/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1925 - acc: 0.9643 - val_loss: 6.3035 - val_acc: 0.4000\nEpoch 700/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1921 - acc: 0.9643 - val_loss: 6.3161 - val_acc: 0.4067\nEpoch 701/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1922 - acc: 0.9643 - val_loss: 6.3020 - val_acc: 0.4000\nEpoch 702/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1921 - acc: 0.9643 - val_loss: 6.2984 - val_acc: 0.3967\nEpoch 703/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1921 - acc: 0.9643 - val_loss: 6.3047 - val_acc: 0.4000\nEpoch 704/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1924 - acc: 0.9643 - val_loss: 6.2863 - val_acc: 0.4000\nEpoch 705/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1920 - acc: 0.9643 - val_loss: 6.2991 - val_acc: 0.4000\nEpoch 706/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1920 - acc: 0.9643 - val_loss: 6.2971 - val_acc: 0.3967\nEpoch 707/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1923 - acc: 0.9643 - val_loss: 6.2906 - val_acc: 0.3967\nEpoch 708/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1920 - acc: 0.9643 - val_loss: 6.3346 - val_acc: 0.4100\nEpoch 709/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1920 - acc: 0.9643 - val_loss: 6.3028 - val_acc: 0.3967\nEpoch 710/1000\n700/700 [==============================] - 0s 137us/sample - loss: 0.1921 - acc: 0.9643 - val_loss: 6.2849 - val_acc: 0.3967\nEpoch 711/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.1922 - acc: 0.9643 - val_loss: 6.3126 - val_acc: 0.4033\nEpoch 712/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1919 - acc: 0.9643 - val_loss: 6.3198 - val_acc: 0.4067\nEpoch 713/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1919 - acc: 0.9643 - val_loss: 6.3340 - val_acc: 0.4100\nEpoch 714/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1920 - acc: 0.9643 - val_loss: 6.3278 - val_acc: 0.4133\nEpoch 715/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1918 - acc: 0.9643 - val_loss: 6.3364 - val_acc: 0.4100\nEpoch 716/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3207 - val_acc: 0.4033\nEpoch 717/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1919 - acc: 0.9643 - val_loss: 6.3211 - val_acc: 0.4067\nEpoch 718/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1916 - acc: 0.9643 - val_loss: 6.3380 - val_acc: 0.4067\nEpoch 719/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1918 - acc: 0.9643 - val_loss: 6.2916 - val_acc: 0.3967\nEpoch 720/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1916 - acc: 0.9643 - val_loss: 6.2936 - val_acc: 0.3967\nEpoch 721/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1919 - acc: 0.9643 - val_loss: 6.3047 - val_acc: 0.3967\nEpoch 722/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1918 - acc: 0.9643 - val_loss: 6.3222 - val_acc: 0.3967\nEpoch 723/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1921 - acc: 0.9643 - val_loss: 6.3015 - val_acc: 0.4000\nEpoch 724/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1918 - acc: 0.9643 - val_loss: 6.2982 - val_acc: 0.3967\nEpoch 725/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1916 - acc: 0.9643 - val_loss: 6.3010 - val_acc: 0.3967\nEpoch 726/1000\n700/700 [==============================] - 0s 108us/sample - loss: 0.1919 - acc: 0.9643 - val_loss: 6.3248 - val_acc: 0.4100\nEpoch 727/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1916 - acc: 0.9643 - val_loss: 6.3088 - val_acc: 0.4000\nEpoch 728/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1916 - acc: 0.9643 - val_loss: 6.3370 - val_acc: 0.4033\nEpoch 729/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1914 - acc: 0.9643 - val_loss: 6.3301 - val_acc: 0.4067\nEpoch 730/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3451 - val_acc: 0.4000\nEpoch 731/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1917 - acc: 0.9643 - val_loss: 6.2948 - val_acc: 0.3967\nEpoch 732/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3119 - val_acc: 0.4000\nEpoch 733/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3455 - val_acc: 0.4067\nEpoch 734/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3174 - val_acc: 0.3967\nEpoch 735/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1912 - acc: 0.9643 - val_loss: 6.3384 - val_acc: 0.4000\nEpoch 736/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3209 - val_acc: 0.4000\nEpoch 737/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3302 - val_acc: 0.3967\nEpoch 738/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3330 - val_acc: 0.4000\nEpoch 739/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1914 - acc: 0.9643 - val_loss: 6.3292 - val_acc: 0.4033\nEpoch 740/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1916 - acc: 0.9643 - val_loss: 6.3479 - val_acc: 0.4100\nEpoch 741/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3400 - val_acc: 0.4067\nEpoch 742/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3102 - val_acc: 0.4000\nEpoch 743/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3494 - val_acc: 0.4067\nEpoch 744/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1914 - acc: 0.9643 - val_loss: 6.3390 - val_acc: 0.4033\nEpoch 745/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1914 - acc: 0.9643 - val_loss: 6.3675 - val_acc: 0.4100\nEpoch 746/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3514 - val_acc: 0.4033\nEpoch 747/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1911 - acc: 0.9643 - val_loss: 6.3317 - val_acc: 0.4000\nEpoch 748/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1912 - acc: 0.9643 - val_loss: 6.3474 - val_acc: 0.4067\nEpoch 749/1000\n700/700 [==============================] - 0s 98us/sample - loss: 0.1915 - acc: 0.9643 - val_loss: 6.3200 - val_acc: 0.4033\nEpoch 750/1000\n700/700 [==============================] - 0s 100us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3337 - val_acc: 0.3967\nEpoch 751/1000\n700/700 [==============================] - 0s 120us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3603 - val_acc: 0.4067\nEpoch 752/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1912 - acc: 0.9643 - val_loss: 6.3254 - val_acc: 0.4000\nEpoch 753/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3632 - val_acc: 0.4033\nEpoch 754/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1914 - acc: 0.9643 - val_loss: 6.3493 - val_acc: 0.4000\nEpoch 755/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3524 - val_acc: 0.3967\nEpoch 756/1000\n700/700 [==============================] - 0s 121us/sample - loss: 0.1912 - acc: 0.9643 - val_loss: 6.3629 - val_acc: 0.4000\nEpoch 757/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1911 - acc: 0.9643 - val_loss: 6.3495 - val_acc: 0.4000\nEpoch 758/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1910 - acc: 0.9643 - val_loss: 6.3624 - val_acc: 0.4033\nEpoch 759/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3530 - val_acc: 0.3967\nEpoch 760/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1913 - acc: 0.9643 - val_loss: 6.3532 - val_acc: 0.3967\nEpoch 761/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1908 - acc: 0.9643 - val_loss: 6.3262 - val_acc: 0.3967\nEpoch 762/1000\n700/700 [==============================] - 0s 103us/sample - loss: 0.1908 - acc: 0.9643 - val_loss: 6.3508 - val_acc: 0.4000\nEpoch 763/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1910 - acc: 0.9643 - val_loss: 6.3465 - val_acc: 0.3967\nEpoch 764/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3410 - val_acc: 0.4000\nEpoch 765/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3425 - val_acc: 0.3967\nEpoch 766/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3516 - val_acc: 0.3967\nEpoch 767/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3456 - val_acc: 0.3967\nEpoch 768/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3809 - val_acc: 0.4033\nEpoch 769/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1910 - acc: 0.9643 - val_loss: 6.3441 - val_acc: 0.4000\nEpoch 770/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3598 - val_acc: 0.4000\nEpoch 771/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3570 - val_acc: 0.3967\nEpoch 772/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.1908 - acc: 0.9643 - val_loss: 6.3610 - val_acc: 0.4033\nEpoch 773/1000\n700/700 [==============================] - 0s 130us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3482 - val_acc: 0.3967\nEpoch 774/1000\n700/700 [==============================] - 0s 124us/sample - loss: 0.1909 - acc: 0.9643 - val_loss: 6.3697 - val_acc: 0.4100\nEpoch 775/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.1908 - acc: 0.9643 - val_loss: 6.3661 - val_acc: 0.3967\nEpoch 776/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3821 - val_acc: 0.4100\nEpoch 777/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3683 - val_acc: 0.4000\nEpoch 778/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1904 - acc: 0.9643 - val_loss: 6.3728 - val_acc: 0.4033\nEpoch 779/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1905 - acc: 0.9643 - val_loss: 6.3786 - val_acc: 0.4000\nEpoch 780/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1904 - acc: 0.9643 - val_loss: 6.3779 - val_acc: 0.4000\nEpoch 781/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1906 - acc: 0.9643 - val_loss: 6.3698 - val_acc: 0.3967\nEpoch 782/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.3591 - val_acc: 0.4000\nEpoch 783/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1912 - acc: 0.9643 - val_loss: 6.3771 - val_acc: 0.4067\nEpoch 784/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1906 - acc: 0.9643 - val_loss: 6.3633 - val_acc: 0.3967\nEpoch 785/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.3887 - val_acc: 0.4100\nEpoch 786/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.1904 - acc: 0.9643 - val_loss: 6.3830 - val_acc: 0.4067\nEpoch 787/1000\n700/700 [==============================] - 0s 138us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.4058 - val_acc: 0.4067\nEpoch 788/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1905 - acc: 0.9643 - val_loss: 6.4067 - val_acc: 0.4100\nEpoch 789/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1905 - acc: 0.9643 - val_loss: 6.3867 - val_acc: 0.4000\nEpoch 790/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1907 - acc: 0.9643 - val_loss: 6.4056 - val_acc: 0.4033\nEpoch 791/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.3715 - val_acc: 0.3967\nEpoch 792/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.3897 - val_acc: 0.3967\nEpoch 793/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1904 - acc: 0.9643 - val_loss: 6.3869 - val_acc: 0.4000\nEpoch 794/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1904 - acc: 0.9643 - val_loss: 6.3942 - val_acc: 0.3967\nEpoch 795/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.3943 - val_acc: 0.4033\nEpoch 796/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.3934 - val_acc: 0.4100\nEpoch 797/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.3863 - val_acc: 0.3967\nEpoch 798/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.3994 - val_acc: 0.4033\nEpoch 799/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1901 - acc: 0.9643 - val_loss: 6.3839 - val_acc: 0.3967\nEpoch 800/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.3899 - val_acc: 0.4000\nEpoch 801/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1904 - acc: 0.9643 - val_loss: 6.3731 - val_acc: 0.4000\nEpoch 802/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1900 - acc: 0.9643 - val_loss: 6.4040 - val_acc: 0.4067\nEpoch 803/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1901 - acc: 0.9643 - val_loss: 6.4012 - val_acc: 0.4067\nEpoch 804/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1899 - acc: 0.9643 - val_loss: 6.3871 - val_acc: 0.4033\nEpoch 805/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.3889 - val_acc: 0.4000\nEpoch 806/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1899 - acc: 0.9643 - val_loss: 6.4113 - val_acc: 0.4067\nEpoch 807/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1899 - acc: 0.9643 - val_loss: 6.4160 - val_acc: 0.4033\nEpoch 808/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1901 - acc: 0.9643 - val_loss: 6.3947 - val_acc: 0.4033\nEpoch 809/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.3968 - val_acc: 0.4000\nEpoch 810/1000\n700/700 [==============================] - 0s 94us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.4018 - val_acc: 0.4000\nEpoch 811/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1899 - acc: 0.9643 - val_loss: 6.4202 - val_acc: 0.4033\nEpoch 812/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.4074 - val_acc: 0.4033\nEpoch 813/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1899 - acc: 0.9643 - val_loss: 6.3967 - val_acc: 0.4033\nEpoch 814/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1901 - acc: 0.9643 - val_loss: 6.4071 - val_acc: 0.4033\nEpoch 815/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1898 - acc: 0.9643 - val_loss: 6.3976 - val_acc: 0.4067\nEpoch 816/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1903 - acc: 0.9643 - val_loss: 6.4221 - val_acc: 0.4033\nEpoch 817/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1901 - acc: 0.9643 - val_loss: 6.3630 - val_acc: 0.3967\nEpoch 818/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.3765 - val_acc: 0.4000\nEpoch 819/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.3650 - val_acc: 0.4000\nEpoch 820/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.1900 - acc: 0.9643 - val_loss: 6.3888 - val_acc: 0.4000\nEpoch 821/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1900 - acc: 0.9643 - val_loss: 6.4052 - val_acc: 0.4000\nEpoch 822/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1898 - acc: 0.9643 - val_loss: 6.3968 - val_acc: 0.4000\nEpoch 823/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1902 - acc: 0.9643 - val_loss: 6.4034 - val_acc: 0.4000\nEpoch 824/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.3962 - val_acc: 0.4033\nEpoch 825/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1898 - acc: 0.9643 - val_loss: 6.4178 - val_acc: 0.4033\nEpoch 826/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.3691 - val_acc: 0.4000\nEpoch 827/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1900 - acc: 0.9643 - val_loss: 6.4234 - val_acc: 0.4067\nEpoch 828/1000\n700/700 [==============================] - 0s 93us/sample - loss: 0.1896 - acc: 0.9643 - val_loss: 6.4242 - val_acc: 0.4000\nEpoch 829/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1895 - acc: 0.9643 - val_loss: 6.4048 - val_acc: 0.4000\nEpoch 830/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.4227 - val_acc: 0.4000\nEpoch 831/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1899 - acc: 0.9643 - val_loss: 6.4318 - val_acc: 0.4033\nEpoch 832/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1898 - acc: 0.9643 - val_loss: 6.4210 - val_acc: 0.4067\nEpoch 833/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1896 - acc: 0.9643 - val_loss: 6.4274 - val_acc: 0.4067\nEpoch 834/1000\n700/700 [==============================] - 0s 97us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.4404 - val_acc: 0.4067\nEpoch 835/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.4189 - val_acc: 0.4000\nEpoch 836/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1895 - acc: 0.9643 - val_loss: 6.4034 - val_acc: 0.4000\nEpoch 837/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1894 - acc: 0.9643 - val_loss: 6.4314 - val_acc: 0.4100\nEpoch 838/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1896 - acc: 0.9643 - val_loss: 6.4483 - val_acc: 0.4100\nEpoch 839/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1894 - acc: 0.9643 - val_loss: 6.4282 - val_acc: 0.4100\nEpoch 840/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.1896 - acc: 0.9643 - val_loss: 6.4359 - val_acc: 0.4000\nEpoch 841/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1897 - acc: 0.9643 - val_loss: 6.4153 - val_acc: 0.4000\nEpoch 842/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1893 - acc: 0.9643 - val_loss: 6.4487 - val_acc: 0.4033\nEpoch 843/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1896 - acc: 0.9643 - val_loss: 6.4390 - val_acc: 0.4067\nEpoch 844/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1895 - acc: 0.9643 - val_loss: 6.4501 - val_acc: 0.4067\nEpoch 845/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1893 - acc: 0.9643 - val_loss: 6.4885 - val_acc: 0.4067\nEpoch 846/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1895 - acc: 0.9643 - val_loss: 6.4047 - val_acc: 0.4033\nEpoch 847/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1895 - acc: 0.9643 - val_loss: 6.4177 - val_acc: 0.4033\nEpoch 848/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4529 - val_acc: 0.4100\nEpoch 849/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4463 - val_acc: 0.4100\nEpoch 850/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1892 - acc: 0.9643 - val_loss: 6.4311 - val_acc: 0.4067\nEpoch 851/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4279 - val_acc: 0.4067\nEpoch 852/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1893 - acc: 0.9643 - val_loss: 6.4251 - val_acc: 0.3967\nEpoch 853/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1892 - acc: 0.9643 - val_loss: 6.4205 - val_acc: 0.4000\nEpoch 854/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1894 - acc: 0.9643 - val_loss: 6.4534 - val_acc: 0.4067\nEpoch 855/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4405 - val_acc: 0.4000\nEpoch 856/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1893 - acc: 0.9643 - val_loss: 6.4335 - val_acc: 0.4033\nEpoch 857/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1892 - acc: 0.9643 - val_loss: 6.4558 - val_acc: 0.4000\nEpoch 858/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1893 - acc: 0.9643 - val_loss: 6.4497 - val_acc: 0.4033\nEpoch 859/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1894 - acc: 0.9643 - val_loss: 6.4344 - val_acc: 0.4000\nEpoch 860/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4613 - val_acc: 0.4067\nEpoch 861/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4569 - val_acc: 0.4067\nEpoch 862/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4222 - val_acc: 0.4000\nEpoch 863/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4821 - val_acc: 0.4067\nEpoch 864/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1893 - acc: 0.9643 - val_loss: 6.4417 - val_acc: 0.4000\nEpoch 865/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4568 - val_acc: 0.4067\nEpoch 866/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4264 - val_acc: 0.4000\nEpoch 867/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4342 - val_acc: 0.4033\nEpoch 868/1000\n700/700 [==============================] - 0s 107us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4359 - val_acc: 0.4000\nEpoch 869/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4356 - val_acc: 0.4000\nEpoch 870/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1890 - acc: 0.9643 - val_loss: 6.4462 - val_acc: 0.4033\nEpoch 871/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4734 - val_acc: 0.4067\nEpoch 872/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4464 - val_acc: 0.4033\nEpoch 873/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4622 - val_acc: 0.4033\nEpoch 874/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1887 - acc: 0.9643 - val_loss: 6.4577 - val_acc: 0.4000\nEpoch 875/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4814 - val_acc: 0.4067\nEpoch 876/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4687 - val_acc: 0.4033\nEpoch 877/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4694 - val_acc: 0.4067\nEpoch 878/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1891 - acc: 0.9643 - val_loss: 6.4454 - val_acc: 0.4000\nEpoch 879/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1888 - acc: 0.9643 - val_loss: 6.4647 - val_acc: 0.4033\nEpoch 880/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.5041 - val_acc: 0.4100\nEpoch 881/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1889 - acc: 0.9643 - val_loss: 6.4655 - val_acc: 0.4067\nEpoch 882/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1888 - acc: 0.9643 - val_loss: 6.4761 - val_acc: 0.4100\nEpoch 883/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1887 - acc: 0.9643 - val_loss: 6.4717 - val_acc: 0.4100\nEpoch 884/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1882 - acc: 0.9643 - val_loss: 6.5016 - val_acc: 0.4067\nEpoch 885/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1888 - acc: 0.9643 - val_loss: 6.4678 - val_acc: 0.4000\nEpoch 886/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.4807 - val_acc: 0.4033\nEpoch 887/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1884 - acc: 0.9643 - val_loss: 6.4793 - val_acc: 0.4067\nEpoch 888/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1887 - acc: 0.9643 - val_loss: 6.4547 - val_acc: 0.4000\nEpoch 889/1000\n700/700 [==============================] - 0s 73us/sample - loss: 0.1887 - acc: 0.9643 - val_loss: 6.4916 - val_acc: 0.4100\nEpoch 890/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1883 - acc: 0.9643 - val_loss: 6.4890 - val_acc: 0.4033\nEpoch 891/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.4547 - val_acc: 0.4000\nEpoch 892/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1887 - acc: 0.9643 - val_loss: 6.5011 - val_acc: 0.4067\nEpoch 893/1000\n700/700 [==============================] - 0s 104us/sample - loss: 0.1884 - acc: 0.9643 - val_loss: 6.4735 - val_acc: 0.4033\nEpoch 894/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1886 - acc: 0.9643 - val_loss: 6.4702 - val_acc: 0.4033\nEpoch 895/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1886 - acc: 0.9643 - val_loss: 6.4642 - val_acc: 0.4000\nEpoch 896/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.4858 - val_acc: 0.4033\nEpoch 897/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.4926 - val_acc: 0.4100\nEpoch 898/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1883 - acc: 0.9643 - val_loss: 6.4899 - val_acc: 0.4067\nEpoch 899/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.4816 - val_acc: 0.4067\nEpoch 900/1000\n700/700 [==============================] - 0s 105us/sample - loss: 0.1883 - acc: 0.9643 - val_loss: 6.4670 - val_acc: 0.4067\nEpoch 901/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.4666 - val_acc: 0.4000\nEpoch 902/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1885 - acc: 0.9643 - val_loss: 6.4647 - val_acc: 0.4000\nEpoch 903/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1884 - acc: 0.9643 - val_loss: 6.4927 - val_acc: 0.4067\nEpoch 904/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1883 - acc: 0.9643 - val_loss: 6.5071 - val_acc: 0.4100\nEpoch 905/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.4880 - val_acc: 0.4067\nEpoch 906/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1883 - acc: 0.9643 - val_loss: 6.4850 - val_acc: 0.4067\nEpoch 907/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.5355 - val_acc: 0.4067\nEpoch 908/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.5263 - val_acc: 0.4067\nEpoch 909/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1882 - acc: 0.9643 - val_loss: 6.4734 - val_acc: 0.4067\nEpoch 910/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1882 - acc: 0.9643 - val_loss: 6.4863 - val_acc: 0.4000\nEpoch 911/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1883 - acc: 0.9643 - val_loss: 6.4952 - val_acc: 0.4100\nEpoch 912/1000\n700/700 [==============================] - 0s 101us/sample - loss: 0.1882 - acc: 0.9643 - val_loss: 6.4886 - val_acc: 0.4033\nEpoch 913/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.5067 - val_acc: 0.4033\nEpoch 914/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.4947 - val_acc: 0.4067\nEpoch 915/1000\n700/700 [==============================] - 0s 95us/sample - loss: 0.1882 - acc: 0.9643 - val_loss: 6.5170 - val_acc: 0.4033\nEpoch 916/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5201 - val_acc: 0.4033\nEpoch 917/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.4879 - val_acc: 0.4033\nEpoch 918/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1880 - acc: 0.9643 - val_loss: 6.5052 - val_acc: 0.4033\nEpoch 919/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.5249 - val_acc: 0.4133\nEpoch 920/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1880 - acc: 0.9643 - val_loss: 6.5137 - val_acc: 0.4067\nEpoch 921/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5344 - val_acc: 0.4033\nEpoch 922/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1882 - acc: 0.9643 - val_loss: 6.5261 - val_acc: 0.4100\nEpoch 923/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1881 - acc: 0.9643 - val_loss: 6.5233 - val_acc: 0.4067\nEpoch 924/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5091 - val_acc: 0.4000\nEpoch 925/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5044 - val_acc: 0.4033\nEpoch 926/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5149 - val_acc: 0.4033\nEpoch 927/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5109 - val_acc: 0.4033\nEpoch 928/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5442 - val_acc: 0.4067\nEpoch 929/1000\n700/700 [==============================] - 0s 111us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5295 - val_acc: 0.4033\nEpoch 930/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.5151 - val_acc: 0.4000\nEpoch 931/1000\n700/700 [==============================] - 0s 110us/sample - loss: 0.1878 - acc: 0.9643 - val_loss: 6.5271 - val_acc: 0.4033\nEpoch 932/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.4976 - val_acc: 0.4000\nEpoch 933/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1878 - acc: 0.9643 - val_loss: 6.4906 - val_acc: 0.4033\nEpoch 934/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1880 - acc: 0.9643 - val_loss: 6.5271 - val_acc: 0.4100\nEpoch 935/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.5296 - val_acc: 0.4033\nEpoch 936/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.5399 - val_acc: 0.4033\nEpoch 937/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.5340 - val_acc: 0.4067\nEpoch 938/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1880 - acc: 0.9643 - val_loss: 6.5107 - val_acc: 0.4000\nEpoch 939/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1878 - acc: 0.9643 - val_loss: 6.5688 - val_acc: 0.4067\nEpoch 940/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1879 - acc: 0.9643 - val_loss: 6.5211 - val_acc: 0.4033\nEpoch 941/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.4955 - val_acc: 0.4000\nEpoch 942/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1880 - acc: 0.9643 - val_loss: 6.5035 - val_acc: 0.4000\nEpoch 943/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5308 - val_acc: 0.4033\nEpoch 944/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 6.5204 - val_acc: 0.4000\nEpoch 945/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.5258 - val_acc: 0.4000\nEpoch 946/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1874 - acc: 0.9643 - val_loss: 6.5412 - val_acc: 0.4000\nEpoch 947/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1877 - acc: 0.9643 - val_loss: 6.5273 - val_acc: 0.4033\nEpoch 948/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5140 - val_acc: 0.4033\nEpoch 949/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5242 - val_acc: 0.4033\nEpoch 950/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1874 - acc: 0.9643 - val_loss: 6.5301 - val_acc: 0.3967\nEpoch 951/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5175 - val_acc: 0.4033\nEpoch 952/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 6.5426 - val_acc: 0.4000\nEpoch 953/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5430 - val_acc: 0.4067\nEpoch 954/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 6.5483 - val_acc: 0.4067\nEpoch 955/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 6.5351 - val_acc: 0.4033\nEpoch 956/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1872 - acc: 0.9643 - val_loss: 6.5162 - val_acc: 0.4033\nEpoch 957/1000\n700/700 [==============================] - 0s 84us/sample - loss: 0.1874 - acc: 0.9643 - val_loss: 6.5733 - val_acc: 0.4067\nEpoch 958/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5416 - val_acc: 0.4000\nEpoch 959/1000\n700/700 [==============================] - 0s 118us/sample - loss: 0.1873 - acc: 0.9643 - val_loss: 6.5418 - val_acc: 0.4033\nEpoch 960/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1876 - acc: 0.9643 - val_loss: 6.5338 - val_acc: 0.4000\nEpoch 961/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 6.5269 - val_acc: 0.3967\nEpoch 962/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1872 - acc: 0.9643 - val_loss: 6.5368 - val_acc: 0.4033\nEpoch 963/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1873 - acc: 0.9643 - val_loss: 6.5360 - val_acc: 0.4033\nEpoch 964/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 6.5442 - val_acc: 0.4033\nEpoch 965/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1872 - acc: 0.9643 - val_loss: 6.4966 - val_acc: 0.4033\nEpoch 966/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1873 - acc: 0.9643 - val_loss: 6.5455 - val_acc: 0.4033\nEpoch 967/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1870 - acc: 0.9643 - val_loss: 6.5468 - val_acc: 0.4000\nEpoch 968/1000\n700/700 [==============================] - 0s 74us/sample - loss: 0.1870 - acc: 0.9643 - val_loss: 6.5587 - val_acc: 0.4033\nEpoch 969/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5504 - val_acc: 0.4067\nEpoch 970/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1873 - acc: 0.9643 - val_loss: 6.5351 - val_acc: 0.4000\nEpoch 971/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5264 - val_acc: 0.4033\nEpoch 972/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5070 - val_acc: 0.4033\nEpoch 973/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5532 - val_acc: 0.4033\nEpoch 974/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5465 - val_acc: 0.4033\nEpoch 975/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1872 - acc: 0.9643 - val_loss: 6.5650 - val_acc: 0.4000\nEpoch 976/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5643 - val_acc: 0.4033\nEpoch 977/1000\n700/700 [==============================] - 0s 91us/sample - loss: 0.1870 - acc: 0.9643 - val_loss: 6.5633 - val_acc: 0.4000\nEpoch 978/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1873 - acc: 0.9643 - val_loss: 6.5529 - val_acc: 0.4067\nEpoch 979/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5432 - val_acc: 0.4033\nEpoch 980/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5554 - val_acc: 0.4033\nEpoch 981/1000\n700/700 [==============================] - 0s 83us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5548 - val_acc: 0.4033\nEpoch 982/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5280 - val_acc: 0.4033\nEpoch 983/1000\n700/700 [==============================] - 0s 115us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5453 - val_acc: 0.4067\nEpoch 984/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5720 - val_acc: 0.4033\nEpoch 985/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5548 - val_acc: 0.4000\nEpoch 986/1000\n700/700 [==============================] - 0s 80us/sample - loss: 0.1870 - acc: 0.9643 - val_loss: 6.5745 - val_acc: 0.4067\nEpoch 987/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5640 - val_acc: 0.4000\nEpoch 988/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1871 - acc: 0.9643 - val_loss: 6.5589 - val_acc: 0.4033\nEpoch 989/1000\n700/700 [==============================] - 0s 71us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5676 - val_acc: 0.4000\nEpoch 990/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1867 - acc: 0.9643 - val_loss: 6.5804 - val_acc: 0.4067\nEpoch 991/1000\n700/700 [==============================] - 0s 90us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5699 - val_acc: 0.4033\nEpoch 992/1000\n700/700 [==============================] - 0s 85us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5789 - val_acc: 0.4067\nEpoch 993/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5682 - val_acc: 0.4033\nEpoch 994/1000\n700/700 [==============================] - 0s 117us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5777 - val_acc: 0.4067\nEpoch 995/1000\n700/700 [==============================] - 0s 76us/sample - loss: 0.1867 - acc: 0.9643 - val_loss: 6.5686 - val_acc: 0.4067\nEpoch 996/1000\n700/700 [==============================] - 0s 87us/sample - loss: 0.1869 - acc: 0.9643 - val_loss: 6.5751 - val_acc: 0.4033\nEpoch 997/1000\n700/700 [==============================] - 0s 81us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5316 - val_acc: 0.4033\nEpoch 998/1000\n700/700 [==============================] - 0s 78us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5941 - val_acc: 0.4133\nEpoch 999/1000\n700/700 [==============================] - 0s 77us/sample - loss: 0.1870 - acc: 0.9643 - val_loss: 6.5705 - val_acc: 0.4067\nEpoch 1000/1000\n700/700 [==============================] - 0s 88us/sample - loss: 0.1868 - acc: 0.9643 - val_loss: 6.5563 - val_acc: 0.4033\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.20953827883516038,\n 0.20974751359650068,\n 0.20988616387226752,\n 0.2098862015775272,\n 0.2096648889194642,\n 0.20947348667042595,\n 0.20928910640733583,\n 0.2095818084797689,\n 0.20974011681973934,\n 0.2095817204830902,\n 0.209705385964896,\n 0.20919602241899285,\n 0.20963052404778346,\n 0.20937177639986787,\n 0.20932099052837916,\n 0.20910887845924922,\n 0.20942247941025666,\n 0.20912160210843597,\n 0.20902903521699565,\n 0.2090635592916182,\n 0.20899390796465533,\n 0.20918846138353858,\n 0.20907475650310517,\n 0.20877539116357055,\n 0.20896003948790687,\n 0.20913171523383686,\n 0.2089643342686551,\n 0.20873394821371352,\n 0.20879491471818515,\n 0.20866189157324178,\n 0.20904108895254986,\n 0.2085856718676431,\n 0.20887737753135818,\n 0.2090086149850062,\n 0.20850151958210128,\n 0.20890640911779235,\n 0.2084608379751444,\n 0.20897047940109456,\n 0.2088641729738031,\n 0.20875029768794776,\n 0.20814772940107754,\n 0.20865202945257935,\n 0.20838958386863982,\n 0.20878962581711155,\n 0.2083591709711722,\n 0.20832092541136912,\n 0.20808148022208894,\n 0.20827955667461667,\n 0.20874313238476003,\n 0.2082823700670685,\n 0.20809438563883303,\n 0.20805988641721862,\n 0.20813538535897222,\n 0.2081643659621477,\n 0.20825577207974025,\n 0.2080630352454526,\n 0.20814436966819422,\n 0.20823498762079648,\n 0.2076344080801521,\n 0.2078566491071667,\n 0.20800786034337113,\n 0.208008565221514,\n 0.20809203231973308,\n 0.20763677097856997,\n 0.20785588220294032,\n 0.20771083161234855,\n 0.2076745366943734,\n 0.20803600874330316,\n 0.20785333780305726,\n 0.2073910877108574,\n 0.20754717378211873,\n 0.20756479858287744,\n 0.20746586546301843,\n 0.20732878622199807,\n 0.2073995619480099,\n 0.20715127353157317,\n 0.2075246734810727,\n 0.20703216870980604,\n 0.20747158085661274,\n 0.20739874765276908,\n 0.20745407063513993,\n 0.20723617800644467,\n 0.20721743862543787,\n 0.2070606742054224,\n 0.20717647549297127,\n 0.20714545649077212,\n 0.2067247139023883,\n 0.20717055701783726,\n 0.20705377624503205,\n 0.20721280159694808,\n 0.20678092565919673,\n 0.20690608700471266,\n 0.20706344012703215,\n 0.20691341810992786,\n 0.20691485942474433,\n 0.20698546527751854,\n 0.20654426073389395,\n 0.20703722201287747,\n 0.20676665742482458,\n 0.2066921144191708,\n 0.20635617625500474,\n 0.20665483682283334,\n 0.2066504802820938,\n 0.2065284613519907,\n 0.20679422872407097,\n 0.20697618600513254,\n 0.20616700638617788,\n 0.2065622159412929,\n 0.206270243493574,\n 0.20650836157479457,\n 0.20603007014308658,\n 0.20636641329952649,\n 0.2064196256122419,\n 0.20610138247055668,\n 0.2064727455909763,\n 0.20638424078268663,\n 0.20609859393111296,\n 0.2063967056040253,\n 0.20630089342594146,\n 0.20601334827286857,\n 0.20622203443199397,\n 0.20620245797825712,\n 0.20594178012439182,\n 0.2063158806413412,\n 0.2060954842184271,\n 0.20594819704336778,\n 0.20590452535876205,\n 0.20586352007729666,\n 0.20600990280508996,\n 0.20586571456598385,\n 0.20593062620609998,\n 0.20599709233003002,\n 0.2056209850524153,\n 0.20602603376443898,\n 0.2057483338617853,\n 0.20573815863047326,\n 0.20595394559204577,\n 0.20554987804165908,\n 0.2054803860506841,\n 0.20557490661740302,\n 0.20566901532667023,\n 0.20572066104837827,\n 0.20561487546988896,\n 0.2055770886263677,\n 0.20542890865887914,\n 0.2053356916244541,\n 0.20511459532592977,\n 0.20545111484825612,\n 0.20501125981765134,\n 0.20549870729446412,\n 0.20543568022549152,\n 0.20505213226590838,\n 0.2052582312375307,\n 0.20539633040981634,\n 0.20498349496296475,\n 0.20516633125288145,\n 0.2053963840007782,\n 0.20502181308610098,\n 0.2051807994821242,\n 0.20488807042794568,\n 0.20516608692705632,\n 0.20498399404542786,\n 0.20506576608334268,\n 0.20493196499134814,\n 0.20491746020104204,\n 0.20494012162089348,\n 0.20496101158538035,\n 0.20516215161021267,\n 0.2049117257020303,\n 0.2046917595501457,\n 0.20492380064513002,\n 0.20446847804955073,\n 0.20497927995664733,\n 0.20452605214502131,\n 0.20457895712128707,\n 0.20491019053650752,\n 0.2045295616345746,\n 0.2045055880610432,\n 0.2044564717582294,\n 0.20451739579439163,\n 0.20459507256746293,\n 0.20430435083274331,\n 0.20431009871619088,\n 0.20442592432456358,\n 0.2043371105832713,\n 0.20463323130139283,\n 0.2042441921574729,\n 0.20449855710778916,\n 0.20431763851749046,\n 0.20408293660730123,\n 0.20411934676979268,\n 0.20408420599997043,\n 0.20395296407597405,\n 0.20391616374254226,\n 0.2042605312275035,\n 0.20406959876418113,\n 0.20408057384192943,\n 0.20405386643750326,\n 0.20370156770305975,\n 0.2042690362515194,\n 0.20383527989366224,\n 0.20400592466550213,\n 0.2037331549184663,\n 0.20402581340500286,\n 0.2038272752559611,\n 0.2036655856030328,\n 0.20381131736295563,\n 0.20369726927684886,\n 0.2036658637225628,\n 0.20347996630838938,\n 0.20416465103626252,\n 0.20360576515751225,\n 0.20362296306661198,\n 0.20358808327998434,\n 0.2036611710808107,\n 0.20325408298522235,\n 0.20372568323676074,\n 0.20344401699091708,\n 0.2033134503023965,\n 0.20329132303595543,\n 0.2034363573949252,\n 0.20321098752319813,\n 0.20309411446963038,\n 0.2032076555171183,\n 0.20339363821383033,\n 0.20330988956349236,\n 0.2031212619904961,\n 0.20314225708799702,\n 0.20308569105608124,\n 0.2029880174036537,\n 0.20324682055839471,\n 0.20343418797211987,\n 0.2032586253115109,\n 0.20301299755062377,\n 0.20316353496164083,\n 0.203004832512566,\n 0.20281561804669243,\n 0.20302045728479112,\n 0.20295927551175866,\n 0.2029887438352619,\n 0.20288221399698939,\n 0.20254948972059147,\n 0.20279964937695436,\n 0.2025107676429408,\n 0.20265541635453702,\n 0.20338299487318312,\n 0.20259435663798026,\n 0.20275256000459194,\n 0.20258713915411916,\n 0.20270092215921198,\n 0.20226375218480824,\n 0.2025738104645695,\n 0.2026317458599806,\n 0.20251508275313038,\n 0.20253455979483467,\n 0.2021219605047788,\n 0.20289422957492725,\n 0.202350517708276,\n 0.2024282499083451,\n 0.20209165162273815,\n 0.20227993625615323,\n 0.20234311909547875,\n 0.2022833756570305,\n 0.20223353962813104,\n 0.2020420463755727,\n 0.2019329414835998,\n 0.2022338274334158,\n 0.20181074259536608,\n 0.2019555665020432,\n 0.20195031190024956,\n 0.20209523891764028,\n 0.2018941987838064,\n 0.20209131645304815,\n 0.20182604640722274,\n 0.2016199146530458,\n 0.20233873812747852,\n 0.2019474931593452,\n 0.2017658261316163,\n 0.20150552783161402,\n 0.20185943469405174,\n 0.20188893675804137,\n 0.20190820215003832,\n 0.20169609955378942,\n 0.20191061736217567,\n 0.2017665846539395,\n 0.20139974680330072,\n 0.2016103626361915,\n 0.20128133754645075,\n 0.20163583446826253,\n 0.2018303803035191,\n 0.2011963126914842,\n 0.20141694891665662,\n 0.2013971547995295,\n 0.2011019461389099,\n 0.20138469471463136,\n 0.2012696546103273,\n 0.20118708365729876,\n 0.20120981729456355,\n 0.2009277408676488,\n 0.2011333347431251,\n 0.20186984006847655,\n 0.20144022846860546,\n 0.20122000308973448,\n 0.20142768384622675,\n 0.2009115271270275,\n 0.20088025368750095,\n 0.2008908636601908,\n 0.20107781668858868,\n 0.20058606969458717,\n 0.20108802568699632,\n 0.20100397590015615,\n 0.20100976383047445,\n 0.2007471192095961,\n 0.20112910456955432,\n 0.20080269133406026,\n 0.20137757850544794,\n 0.2008547501904624,\n 0.2008947665137904,\n 0.20088503382035663,\n 0.2010176951863936,\n 0.20091165373367922,\n 0.20106866216020924,\n 0.20075115380542619,\n 0.2007850815142904,\n 0.20066723799599068,\n 0.20057419118072306,\n 0.19997079877981117,\n 0.2006859209920679,\n 0.20041601011263474,\n 0.20048299809651715,\n 0.20042026162679707,\n 0.20046160237065383,\n 0.20055184795388153,\n 0.20058720005410058,\n 0.200238472116845,\n 0.20029174145311118,\n 0.20051465705037116,\n 0.20019745392990965,\n 0.20016931419127754,\n 0.20008084209901947,\n 0.20003273534987653,\n 0.20025905250970807,\n 0.20005703382194043,\n 0.200019707663783,\n 0.19976634244833674,\n 0.19993459305592945,\n 0.20008357646209854,\n 0.19991456594850335,\n 0.1997976775148085,\n 0.20022014273064478,\n 0.19980940861361368,\n 0.19982403814792632,\n 0.19967052127633775,\n 0.19965151441948756,\n 0.1999729409813881,\n 0.19993227299835,\n 0.19966678212263755,\n 0.1994881102016994,\n 0.19970253024782453,\n 0.19987318521099431,\n 0.199569553190044,\n 0.19959173646888562,\n 0.19924489124012845,\n 0.1995527108865125,\n 0.1997389303786414,\n 0.199472542319979,\n 0.19953706195311888,\n 0.19957897609898023,\n 0.19947122670710088,\n 0.1997517829494817,\n 0.19918988751513617,\n 0.1994710478399481,\n 0.19947743775056942,\n 0.19958896107439483,\n 0.1994569029659033,\n 0.19940001405775548,\n 0.19995683458234584,\n 0.1993549777993134,\n 0.19907566495239734,\n 0.19904718840760843,\n 0.19915104542991946,\n 0.1992506849446467,\n 0.1991228923201561,\n 0.1992266152852348,\n 0.19949999696442058,\n 0.19916320858257158,\n 0.19920078872569968,\n 0.19903583776737963,\n 0.19944134881453854,\n 0.19889261959386723,\n 0.19914178129817758,\n 0.1989302330251251,\n 0.19912719769137247,\n 0.19896491670182773,\n 0.1990820348528879,\n 0.19860781295491117,\n 0.19868227395095994,\n 0.19901123761332462,\n 0.1986001419169562,\n 0.19874997958540916,\n 0.19841315166226456,\n 0.1986806944278734,\n 0.19888965104307446,\n 0.19881784532751356,\n 0.19877599397940296,\n 0.19888854138553141,\n 0.1988506474399141,\n 0.1986859393971307,\n 0.19850948676466942,\n 0.19851962280060564,\n 0.19837355885122504,\n 0.19883295324231898,\n 0.19831012913158963,\n 0.19826969717230117,\n 0.19863255662577492,\n 0.1986285326736314,\n 0.19834307783416338,\n 0.19842667739306177,\n 0.1984504739620856,\n 0.19805960844137838,\n 0.19809216601508003,\n 0.19809517211147717,\n 0.198228336338486,\n 0.19819650860237223,\n 0.19839937804000718,\n 0.1980178611619132,\n 0.19818236449999468,\n 0.1980732419395021,\n 0.19822684180523667,\n 0.19830201119184493,\n 0.19799811688384839,\n 0.19808235817721911,\n 0.19784731790423393,\n 0.1980646083929709,\n 0.19839027380304677,\n 0.19811677818319628,\n 0.19772598480007478,\n 0.19798771733684198,\n 0.1978393309882709,\n 0.1980437097937933,\n 0.19787555895745754,\n 0.19816556429224355,\n 0.19810187944344113,\n 0.19822967600609576,\n 0.19769608993083237,\n 0.19771834665111132,\n 0.19817028790712357,\n 0.1976179037243128,\n 0.19767128830509526,\n 0.19765996020287274,\n 0.1973138059356383,\n 0.19741467035242488,\n 0.1974506539957864,\n 0.1972978938370943,\n 0.1974765551409551,\n 0.19748223743268423,\n 0.1974825478025845,\n 0.19739366439836367,\n 0.1972646964447839,\n 0.19738453115735735,\n 0.19721180514565537,\n 0.19717791958578995,\n 0.1971144310065678,\n 0.19725798964500427,\n 0.19730539778247475,\n 0.1970531243564827,\n 0.1972545484879187,\n 0.19693441864635264,\n 0.19681304608072553,\n 0.19707038266850369,\n 0.19682012713913408,\n 0.1972619664456163,\n 0.19754656585199493,\n 0.1973081176834447,\n 0.19714293549103395,\n 0.19721770805439778,\n 0.19692682070391518,\n 0.19688362952853952,\n 0.19673579601304872,\n 0.19696137247873205,\n 0.19679265762014048,\n 0.19677328153380325,\n 0.19696827842188733,\n 0.1968760102189013,\n 0.1966005718069417,\n 0.19657347989933832,\n 0.19650693727391108,\n 0.1968417544982263,\n 0.19659911798579352,\n 0.19657839818724565,\n 0.19659890891718013,\n 0.19679095721138376,\n 0.196559724850314,\n 0.1966795883008412,\n 0.19669925070234706,\n 0.19640219184969152,\n 0.19652708965752805,\n 0.19688884613237212,\n 0.1964435738910522,\n 0.19657167055244956,\n 0.19638005787772791,\n 0.1964730833790132,\n 0.19628236895161016,\n 0.19630225997950349,\n 0.19639151391706297,\n 0.1961497258927141,\n 0.1963830403983593,\n 0.19607573204806872,\n 0.19621729648539,\n 0.19634737997714963,\n 0.19603222768221581,\n 0.1962759548266019,\n 0.1961063413215535,\n 0.19622123371809722,\n 0.19609090206878527,\n 0.1962032202365143,\n 0.1961345500977976,\n 0.19598536895854132,\n 0.19576403708862408,\n 0.19580312999231475,\n 0.19633764800216472,\n 0.19621430656739644,\n 0.1957664296030998,\n 0.19590302615293434,\n 0.19573426664407764,\n 0.19605205673724413,\n 0.1960691743397287,\n 0.19603338363979544,\n 0.19591666901750224,\n 0.195643823114889,\n 0.1959440115839243,\n 0.19568008157823766,\n 0.1958124119256224,\n 0.19598775431513787,\n 0.19570387035076106,\n 0.19568552231150013,\n 0.19563220047524998,\n 0.19549757010702576,\n 0.1953740119934082,\n 0.1955744727115546,\n 0.19573341459035873,\n 0.19557356211755958,\n 0.1955868617764541,\n 0.19537928359849113,\n 0.19520009245191303,\n 0.19558089606996093,\n 0.19548989278929574,\n 0.19522468027259623,\n 0.19531047785920755,\n 0.19522236508450339,\n 0.19537996921156134,\n 0.1949758521680321,\n 0.19556206983647176,\n 0.19524510372430087,\n 0.19540160495255673,\n 0.1953948049140828,\n 0.1951089216928397,\n 0.19538870866277389,\n 0.19515942622508323,\n 0.19508061573973723,\n 0.1949998603867633,\n 0.19510180239698716,\n 0.19506850077637605,\n 0.19489950793130056,\n 0.19514262899756432,\n 0.19519160310072559,\n 0.19516200569591352,\n 0.19491874974753176,\n 0.194916185098035,\n 0.19529695899358818,\n 0.19481681883335114,\n 0.19472573359629938,\n 0.19457852068756307,\n 0.19476755447685717,\n 0.1948587957237448,\n 0.19489326535591056,\n 0.19450451021215745,\n 0.19477928930095265,\n 0.19504410363733768,\n 0.19452056639960835,\n 0.1945665976564799,\n 0.19483535960316659,\n 0.19465276077389718,\n 0.19476849910404,\n 0.1943673986941576,\n 0.1946237097361258,\n 0.19434847943484784,\n 0.1945438051862376,\n 0.1943493242774691,\n 0.19465559731636728,\n 0.19472921453416348,\n 0.1947686905041337,\n 0.19421821662357874,\n 0.19447601735591888,\n 0.19462825618684293,\n 0.194069469081504,\n 0.19437721132167748,\n 0.1941321711987257,\n 0.19430149623325893,\n 0.19422892723232507,\n 0.19435487408190966,\n 0.19397841888879028,\n 0.1937649261738573,\n 0.19411776922643184,\n 0.1941906987024205,\n 0.19394640323839019,\n 0.19436039924621581,\n 0.19420209244957992,\n 0.19429235088505914,\n 0.19380598025662557,\n 0.19440963193774224,\n 0.19448306704206125,\n 0.19420452469161578,\n 0.19401896577328442,\n 0.19389306772500275,\n 0.19375243248151883,\n 0.19419089337544782,\n 0.19369485761438096,\n 0.19426908192357847,\n 0.19387138672173024,\n 0.193902304608907,\n 0.19382029652063335,\n 0.1937999447009393,\n 0.1937650284862944,\n 0.19366957217987094,\n 0.19408279779766288,\n 0.19376829862594605,\n 0.19371402471193244,\n 0.1935832909175328,\n 0.19386825641351088,\n 0.19377846281443323,\n 0.19352289023143904,\n 0.19349850182022368,\n 0.1937881788238883,\n 0.19320134557783603,\n 0.19337849505245686,\n 0.19352318037833485,\n 0.19323438964784145,\n 0.19340430609881878,\n 0.19337345590548857,\n 0.1931605360071574,\n 0.1935487003464784,\n 0.1931302907477532,\n 0.19330306494874613,\n 0.19314677119255066,\n 0.19335735158196518,\n 0.19389564134180545,\n 0.1931693704000541,\n 0.1932856880660568,\n 0.19307818646941866,\n 0.19321849676115171,\n 0.19329471457749606,\n 0.19333294933395725,\n 0.1932105831269707,\n 0.19294957686215639,\n 0.19323690377974084,\n 0.19330609781401498,\n 0.19298355502209494,\n 0.19295632897743156,\n 0.1931256436077612,\n 0.19309663120657206,\n 0.19283685242491108,\n 0.19312057511082717,\n 0.19303697778710296,\n 0.19292650528784308,\n 0.1929231065192393,\n 0.1927052550550018,\n 0.19292660733418807,\n 0.1927273891334023,\n 0.19295114459736007,\n 0.19276254837002074,\n 0.19272723605058023,\n 0.192755642373647,\n 0.19256503369127,\n 0.1926420025261385,\n 0.19240977045680796,\n 0.19274070507713725,\n 0.19248560510043586,\n 0.19264447915234736,\n 0.19254248275288513,\n 0.19282148725220136,\n 0.1923331312303032,\n 0.19265710610364165,\n 0.1927705650084785,\n 0.19242756558316096,\n 0.19231869751321418,\n 0.19238771413053785,\n 0.19220833890140057,\n 0.19227239106382643,\n 0.1923964740176286,\n 0.1924573568095054,\n 0.192357917076775,\n 0.192485095720206,\n 0.19243034568748305,\n 0.19224417864211968,\n 0.19256444573402404,\n 0.19200294161481515,\n 0.1922624642827681,\n 0.19252717816936119,\n 0.1921190766617656,\n 0.19221964914883885,\n 0.19209456874855926,\n 0.1920743861102632,\n 0.19238699397870473,\n 0.19204311099435603,\n 0.19202577232250145,\n 0.19234025784369027,\n 0.19200848120131664,\n 0.19202331536050354,\n 0.1920835269348962,\n 0.19222152403422765,\n 0.1919297788824354,\n 0.19191041950668608,\n 0.19197962709835598,\n 0.19177492409944535,\n 0.19149663573397058,\n 0.1919027946091124,\n 0.19162142417792763,\n 0.1917899202555418,\n 0.1915564253926277,\n 0.19188407664852483,\n 0.19175372051873377,\n 0.1920575998723507,\n 0.19180664255150726,\n 0.19163141772150993,\n 0.191858897837145,\n 0.1916001571608441,\n 0.19160270895808934,\n 0.19139294978231192,\n 0.19146933521011045,\n 0.19171860380364317,\n 0.19151674211025238,\n 0.19150648771652154,\n 0.19150724331183092,\n 0.19118167773953507,\n 0.19151637801634414,\n 0.19129193856247834,\n 0.19148805511317082,\n 0.1914321410336665,\n 0.19156372943626984,\n 0.19146806217197862,\n 0.19125644394329616,\n 0.1913055291665452,\n 0.1914066285959312,\n 0.1913738390430808,\n 0.19134312314646584,\n 0.19113830977252552,\n 0.19120949325816972,\n 0.19146569254142898,\n 0.19129576201417617,\n 0.19131400055651154,\n 0.19119216541626624,\n 0.19128435073154312,\n 0.19137056802532504,\n 0.1908947470997061,\n 0.19120739860726255,\n 0.1910614200202482,\n 0.19100753845913068,\n 0.19087834507226945,\n 0.1912648302635976,\n 0.19075018111616374,\n 0.19076791557350328,\n 0.1910020899027586,\n 0.19073908956987518,\n 0.19088979879660264,\n 0.19091233738831112,\n 0.19089060593396426,\n 0.19066694849835975,\n 0.19096741266548634,\n 0.1908875181206635,\n 0.19067415557801723,\n 0.19083338012652737,\n 0.19074757764382022,\n 0.19088264299290522,\n 0.1908276476498161,\n 0.190663593262434,\n 0.19066180224929538,\n 0.19044220923845256,\n 0.1905026001855731,\n 0.19035524137850318,\n 0.19056637909795557,\n 0.19034972254719054,\n 0.19121879738356387,\n 0.1905610748433641,\n 0.19071920053767308,\n 0.1903920451445239,\n 0.19029488638043404,\n 0.1904793587646314,\n 0.19045962944094624,\n 0.19067055590982948,\n 0.19033768364627446,\n 0.19033877179026604,\n 0.19042927979358604,\n 0.190435936222119,\n 0.19030977423701967,\n 0.19026313652949675,\n 0.1902990292225565,\n 0.1902468236695443,\n 0.1900795648938843,\n 0.19023109525442122,\n 0.1904274975082704,\n 0.19003930312714407,\n 0.19005393029323647,\n 0.1899373714945146,\n 0.19024176429957151,\n 0.18991967852094344,\n 0.1898559941244977,\n 0.19011130633630924,\n 0.1901962797822697,\n 0.19018264620431832,\n 0.1899337245683585,\n 0.1897450335855995,\n 0.18985794708132744,\n 0.19009449976895537,\n 0.18983701515410628,\n 0.19027438938085522,\n 0.19007167906633446,\n 0.1901721224987081,\n 0.1901670264080167,\n 0.18995450788310597,\n 0.18997263440064022,\n 0.18975999533597912,\n 0.1902096372629915,\n 0.1897126799981509,\n 0.18984137656433242,\n 0.18965129956070867,\n 0.1899837006947824,\n 0.1896101215588195,\n 0.18946705630847385,\n 0.18969918191432952,\n 0.18989230596593448,\n 0.18977291610624109,\n 0.18960127457976342,\n 0.18966593199542592,\n 0.18967953260455814,\n 0.18948397269206388,\n 0.1894005213198917,\n 0.1895764421671629,\n 0.1893938035038965,\n 0.18956782493208135,\n 0.1897265418831791,\n 0.1892736931730594,\n 0.18955453038215636,\n 0.18945393604891642,\n 0.18925337275224072,\n 0.18946703377046756,\n 0.18946546848331178,\n 0.18904884023857968,\n 0.18900886342993806,\n 0.18923790896577494,\n 0.18911535420588085,\n 0.18926170324640615,\n 0.18918123740170684,\n 0.18937155798609767,\n 0.18896619842520782,\n 0.18927006918404785,\n 0.18922013020409004,\n 0.18934813956064836,\n 0.18936575089714358,\n 0.18913764873785632,\n 0.18898877070418427,\n 0.18913460678554006,\n 0.1891016676755888,\n 0.1892535761397864,\n 0.1890731027882014,\n 0.1889643189630338,\n 0.1889278453375612,\n 0.18896609659173658,\n 0.18899939709476063,\n 0.18903264509780066,\n 0.18894369511732034,\n 0.18914837475333895,\n 0.188932311215571,\n 0.18866751667644296,\n 0.1889036537813289,\n 0.18886790254286356,\n 0.18891074436583688,\n 0.18911593332886695,\n 0.18881718537637165,\n 0.18853927810809443,\n 0.18886179700493813,\n 0.188752764011068,\n 0.1886900526072298,\n 0.18819078454481705,\n 0.18880545518227987,\n 0.18854879707630193,\n 0.18844749669411354,\n 0.18868809390280927,\n 0.18866457183446203,\n 0.18833780448351586,\n 0.18852564474301678,\n 0.18867244111107928,\n 0.18836815311972585,\n 0.18857546033603803,\n 0.18863926649625812,\n 0.18853827587195804,\n 0.18805592735963209,\n 0.18831216336361,\n 0.18854135908186437,\n 0.18828142583370208,\n 0.1885099701051201,\n 0.18851457804973637,\n 0.18838232619954007,\n 0.18825930508651903,\n 0.18809264594955102,\n 0.18834672772458622,\n 0.18811404103679316,\n 0.18811569320304053,\n 0.1882458663412503,\n 0.1882414492645434,\n 0.18827008897704736,\n 0.18817576515887466,\n 0.18811212943068573,\n 0.18812588187200682,\n 0.18818186638610704,\n 0.18793360782521112,\n 0.18807743697294166,\n 0.18801156713494233,\n 0.18812127829130207,\n 0.18797775224915572,\n 0.18786182531288692,\n 0.18821317220904998,\n 0.18807280643710067,\n 0.1878999407270125,\n 0.1879392608734114,\n 0.18787062941119076,\n 0.18786655379725353,\n 0.187619292922318,\n 0.18791369420609305,\n 0.18773761104260173,\n 0.18784063458442687,\n 0.1877408768715603,\n 0.18780953075204576,\n 0.18798688019492796,\n 0.18766329708908286,\n 0.18767832477710078,\n 0.18768240575279507,\n 0.18797090873122216,\n 0.18778382396059376,\n 0.18788786301655427,\n 0.18766171660806452,\n 0.1879525950444596,\n 0.18760305403598718,\n 0.18746113920850413,\n 0.1876902260152357,\n 0.1873617806338838,\n 0.18767925141645328,\n 0.1875827030145696,\n 0.18757045676133463,\n 0.18737235580171857,\n 0.18764309569128923,\n 0.18752751408943108,\n 0.1875987586964454,\n 0.18747507948428394,\n 0.1875466094485351,\n 0.18723109063825438,\n 0.18744003392223801,\n 0.18755283089620725,\n 0.18731201647647788,\n 0.18760557792016438,\n 0.1875314639881253,\n 0.1871941360245858,\n 0.187281938589045,\n 0.1875039312190243,\n 0.18715434758258717,\n 0.187284428147333,\n 0.18704482418085847,\n 0.1869746406163488,\n 0.18694377014679567,\n 0.18732604464249952,\n 0.1871435803228191,\n 0.18705747907183,\n 0.187107447588018,\n 0.18709716754300254,\n 0.18722332974097558,\n 0.18694002662918396,\n 0.18695635878081832,\n 0.18725156419511352,\n 0.18708464269127165,\n 0.18691645307200297,\n 0.18713001481124333,\n 0.18710754327476026,\n 0.18694747923208135,\n 0.18684580456465483,\n 0.18682176207325288,\n 0.18704466048095908,\n 0.18690648129475967,\n 0.18710868821612425,\n 0.1869299780311329,\n 0.1866962050486888,\n 0.18687759792166098,\n 0.1867823277999248,\n 0.18677535404318146,\n 0.18686032760888338,\n 0.1866734582398619,\n 0.18687423810895,\n 0.1867658808561308,\n 0.18681066004293306,\n 0.18697013610175678,\n 0.1867777541811977]"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "hist = model.fit(xtrain, ytrain, batch_size=10,  epochs=1000, validation_data=(xval, yval))\n",
    "\n",
    "hist.history['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1698366ee88>"
     },
     "metadata": {},
     "execution_count": 37
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 412.821875 262.19625\" width=\"412.821875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 412.821875 262.19625 \r\nL 412.821875 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 34.240625 224.64 \r\nL 369.040625 224.64 \r\nL 369.040625 7.2 \r\nL 34.240625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m0ad1c3a35b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.458807\" xlink:href=\"#m0ad1c3a35b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(46.277557 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.392468\" xlink:href=\"#m0ad1c3a35b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 200 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(100.848718 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.326129\" xlink:href=\"#m0ad1c3a35b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 400 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(161.782379 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.25979\" xlink:href=\"#m0ad1c3a35b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 600 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(222.71604 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.193451\" xlink:href=\"#m0ad1c3a35b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 800 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(283.649701 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"354.127111\" xlink:href=\"#m0ad1c3a35b\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 1000 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(341.402111 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- epoch -->\r\n     <defs>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n     </defs>\r\n     <g transform=\"translate(186.4125 252.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mff539baf74\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"220.515355\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(20.878125 224.314573)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"189.66474\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 1 -->\r\n      <g transform=\"translate(20.878125 193.463958)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"158.814125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(20.878125 162.613344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"127.96351\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 3 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 131.762729)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"97.112895\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(20.878125 100.912114)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"66.26228\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 70.061499)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mff539baf74\" y=\"35.411665\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 6 -->\r\n      <g transform=\"translate(20.878125 39.210884)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_15\">\r\n     <!-- cost -->\r\n     <defs>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798437 126.293437)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"116.162109\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"168.261719\" xlink:href=\"#DejaVuSans-116\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p508ee491aa)\" d=\"M 49.458807 214.05097 \r\nL 54.3335 214.054542 \r\nL 58.294188 214.078007 \r\nL 61.036202 214.071766 \r\nL 75.050944 214.123833 \r\nL 235.306473 214.517698 \r\nL 244.75119 214.544258 \r\nL 247.493205 214.554445 \r\nL 258.461264 214.580075 \r\nL 265.163967 214.591317 \r\nL 278.87404 214.611455 \r\nL 281.311387 214.630047 \r\nL 285.576743 214.633266 \r\nL 353.822443 214.753146 \r\nL 353.822443 214.753146 \r\n\" style=\"fill:none;stroke:#bfbf00;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p508ee491aa)\" d=\"M 49.458807 47.807916 \r\nL 49.763475 48.702979 \r\nL 50.372812 48.174973 \r\nL 50.982148 48.55918 \r\nL 51.286817 47.51903 \r\nL 51.591485 47.727007 \r\nL 51.896153 48.380179 \r\nL 52.200822 47.594767 \r\nL 52.50549 48.239941 \r\nL 52.810158 47.228269 \r\nL 53.114826 48.446749 \r\nL 53.419495 48.235437 \r\nL 53.724163 47.751617 \r\nL 54.028831 47.881447 \r\nL 54.3335 47.684029 \r\nL 54.638168 47.702512 \r\nL 55.247505 47.926644 \r\nL 55.552173 48.547282 \r\nL 55.856841 47.929445 \r\nL 56.16151 48.245654 \r\nL 56.466178 47.210523 \r\nL 57.075514 47.539863 \r\nL 57.380183 47.341927 \r\nL 57.684851 47.764443 \r\nL 57.989519 47.594464 \r\nL 58.294188 46.176598 \r\nL 58.598856 47.19429 \r\nL 58.903524 47.070143 \r\nL 59.208193 47.170459 \r\nL 59.512861 47.11218 \r\nL 59.817529 46.583654 \r\nL 60.122197 47.345158 \r\nL 60.426866 47.249649 \r\nL 60.731534 47.36195 \r\nL 61.036202 47.012416 \r\nL 61.340871 47.184195 \r\nL 61.645539 47.208268 \r\nL 61.950207 47.045832 \r\nL 62.254876 47.662059 \r\nL 62.864212 47.005794 \r\nL 63.168881 47.246505 \r\nL 63.473549 46.458535 \r\nL 64.082885 47.890592 \r\nL 64.387554 46.443054 \r\nL 64.692222 47.003434 \r\nL 64.99689 46.859233 \r\nL 65.301559 46.236109 \r\nL 65.606227 46.683674 \r\nL 65.910895 46.163388 \r\nL 66.520232 47.191182 \r\nL 66.8249 46.426744 \r\nL 67.129568 46.729124 \r\nL 67.434237 45.661414 \r\nL 67.738905 46.838082 \r\nL 68.043573 46.689056 \r\nL 68.348242 46.285755 \r\nL 68.957578 46.4193 \r\nL 69.262247 45.920939 \r\nL 69.566915 45.136941 \r\nL 69.871583 46.500772 \r\nL 70.176252 46.156181 \r\nL 70.48092 46.951211 \r\nL 70.785588 46.024264 \r\nL 71.394925 45.219311 \r\nL 71.699593 45.480098 \r\nL 72.004261 45.584393 \r\nL 72.30893 46.747445 \r\nL 72.613598 46.225646 \r\nL 72.918266 45.426815 \r\nL 73.527603 46.16105 \r\nL 73.832271 45.300712 \r\nL 74.136939 45.803634 \r\nL 74.441608 45.407442 \r\nL 74.746276 45.456005 \r\nL 75.050944 45.924977 \r\nL 75.355613 45.559993 \r\nL 75.660281 45.558307 \r\nL 75.964949 45.802791 \r\nL 76.269618 45.679577 \r\nL 76.878954 45.29601 \r\nL 77.183623 45.822036 \r\nL 77.488291 45.162546 \r\nL 77.792959 45.840035 \r\nL 78.097627 45.843761 \r\nL 78.402296 44.614882 \r\nL 79.011632 45.285273 \r\nL 79.620969 45.308806 \r\nL 79.925637 44.471304 \r\nL 80.230306 45.000839 \r\nL 80.534974 44.500578 \r\nL 81.144311 45.094846 \r\nL 81.448979 44.68448 \r\nL 81.753647 43.866277 \r\nL 82.058315 45.588811 \r\nL 82.362984 44.786881 \r\nL 82.667652 44.731474 \r\nL 82.97232 45.282452 \r\nL 83.276989 43.942795 \r\nL 83.581657 44.691538 \r\nL 83.886325 44.455966 \r\nL 84.190994 43.822207 \r\nL 84.495662 43.912642 \r\nL 85.104998 44.620918 \r\nL 85.409667 44.616966 \r\nL 85.714335 44.181379 \r\nL 86.019003 44.360369 \r\nL 86.323672 44.131328 \r\nL 86.62834 45.332053 \r\nL 86.933008 44.034623 \r\nL 87.237677 43.929368 \r\nL 87.542345 44.088406 \r\nL 88.151682 43.605174 \r\nL 88.45635 44.365252 \r\nL 89.065686 42.937865 \r\nL 89.675023 44.540978 \r\nL 89.979691 44.495107 \r\nL 90.28436 44.695399 \r\nL 90.589028 44.420577 \r\nL 90.893696 43.562293 \r\nL 91.198365 43.911302 \r\nL 91.503033 43.732201 \r\nL 91.807701 43.252488 \r\nL 92.112369 43.69053 \r\nL 92.417038 43.744096 \r\nL 92.721706 43.153707 \r\nL 93.026374 43.190961 \r\nL 93.331043 44.01769 \r\nL 93.635711 43.721546 \r\nL 93.940379 43.598407 \r\nL 94.245048 43.631142 \r\nL 94.549716 44.158751 \r\nL 94.854384 43.00695 \r\nL 95.159053 43.536258 \r\nL 95.463721 43.063189 \r\nL 95.768389 43.845455 \r\nL 96.073057 43.007245 \r\nL 96.377726 43.149902 \r\nL 96.682394 42.744829 \r\nL 96.987062 42.67695 \r\nL 97.291731 42.179477 \r\nL 97.596399 43.263311 \r\nL 97.901067 43.283754 \r\nL 98.205736 42.910086 \r\nL 98.815072 43.285964 \r\nL 99.11974 43.14094 \r\nL 99.424409 42.670458 \r\nL 99.729077 43.094148 \r\nL 100.033745 43.14814 \r\nL 100.338414 43.59751 \r\nL 100.643082 42.146115 \r\nL 100.94775 42.235156 \r\nL 101.252419 42.511856 \r\nL 101.557087 42.473557 \r\nL 101.861755 42.823672 \r\nL 102.471092 42.348109 \r\nL 103.080428 43.059436 \r\nL 103.689765 42.195628 \r\nL 103.994433 42.61228 \r\nL 104.299102 42.108108 \r\nL 104.60377 42.517047 \r\nL 104.908438 41.564095 \r\nL 105.213107 41.773378 \r\nL 105.517775 42.455458 \r\nL 105.822443 41.785202 \r\nL 106.127111 42.075439 \r\nL 106.43178 41.540068 \r\nL 106.736448 41.599773 \r\nL 107.041116 41.905048 \r\nL 107.345785 42.039889 \r\nL 107.650453 42.377824 \r\nL 107.955121 41.959959 \r\nL 108.25979 42.051199 \r\nL 108.564458 42.377446 \r\nL 108.869126 41.455939 \r\nL 109.173795 42.344879 \r\nL 109.783131 40.244528 \r\nL 110.087799 42.190852 \r\nL 110.392468 41.009516 \r\nL 111.001804 41.958571 \r\nL 111.306473 41.475012 \r\nL 111.611141 42.15832 \r\nL 111.915809 40.730108 \r\nL 112.220478 40.898668 \r\nL 112.829814 41.924913 \r\nL 113.134482 41.191093 \r\nL 113.439151 41.061469 \r\nL 113.743819 41.700485 \r\nL 114.048487 40.794659 \r\nL 114.353156 40.948522 \r\nL 114.657824 41.723026 \r\nL 114.962492 41.007135 \r\nL 115.267161 41.207444 \r\nL 115.571829 41.185185 \r\nL 115.876497 40.85511 \r\nL 116.181166 40.335905 \r\nL 116.485834 40.751086 \r\nL 117.09517 40.686773 \r\nL 117.399839 40.476289 \r\nL 117.704507 41.471616 \r\nL 118.009175 40.808306 \r\nL 118.313844 40.777115 \r\nL 118.618512 40.129035 \r\nL 118.92318 40.241183 \r\nL 119.227849 40.905223 \r\nL 119.532517 40.979593 \r\nL 119.837185 40.642895 \r\nL 120.141854 40.883087 \r\nL 120.75119 40.304547 \r\nL 121.055858 40.372992 \r\nL 121.360527 39.779562 \r\nL 121.665195 40.545376 \r\nL 121.969863 39.962033 \r\nL 122.274532 41.300366 \r\nL 122.5792 40.288757 \r\nL 123.188537 39.38895 \r\nL 123.493205 40.115882 \r\nL 123.797873 39.759571 \r\nL 124.102541 40.423783 \r\nL 124.40721 40.353987 \r\nL 124.711878 39.886646 \r\nL 125.016546 40.174492 \r\nL 125.321215 39.883113 \r\nL 125.625883 38.88755 \r\nL 125.930551 40.140692 \r\nL 126.23522 40.184596 \r\nL 126.539888 39.196925 \r\nL 126.844556 39.813759 \r\nL 127.149225 40.867208 \r\nL 127.453893 40.047225 \r\nL 127.758561 40.140162 \r\nL 128.063229 39.516082 \r\nL 128.367898 39.298621 \r\nL 128.672566 39.93055 \r\nL 128.977234 38.853014 \r\nL 129.281903 40.406415 \r\nL 129.586571 39.070681 \r\nL 129.891239 39.45847 \r\nL 130.195908 39.565824 \r\nL 130.500576 39.446136 \r\nL 130.805244 39.448704 \r\nL 131.109912 38.809414 \r\nL 131.414581 38.715553 \r\nL 131.719249 38.848438 \r\nL 132.023917 39.260701 \r\nL 132.328586 39.249874 \r\nL 132.633254 39.121484 \r\nL 132.937922 38.580693 \r\nL 133.242591 39.364552 \r\nL 133.547259 39.016825 \r\nL 133.851927 38.952734 \r\nL 134.156596 38.171953 \r\nL 134.461264 39.494064 \r\nL 134.765932 38.326384 \r\nL 135.0706 38.955197 \r\nL 135.375269 39.124001 \r\nL 135.679937 39.127781 \r\nL 135.984605 38.959866 \r\nL 136.289274 39.238282 \r\nL 136.593942 39.167068 \r\nL 137.203279 38.197631 \r\nL 137.507947 39.728876 \r\nL 137.812615 38.236672 \r\nL 138.117283 37.708183 \r\nL 138.421952 39.090345 \r\nL 138.72662 38.594516 \r\nL 139.031288 38.955352 \r\nL 139.335957 37.966753 \r\nL 139.640625 39.128666 \r\nL 139.945293 37.436448 \r\nL 140.249962 37.757995 \r\nL 140.55463 38.602448 \r\nL 140.859298 37.593997 \r\nL 141.163967 38.080858 \r\nL 141.468635 38.961513 \r\nL 141.773303 38.335676 \r\nL 142.38264 37.831649 \r\nL 142.687308 37.985292 \r\nL 142.991976 37.969316 \r\nL 143.296645 37.797383 \r\nL 143.601313 38.435743 \r\nL 143.905981 38.006064 \r\nL 144.21065 38.414718 \r\nL 144.515318 36.814138 \r\nL 144.819986 38.755171 \r\nL 145.124654 36.864476 \r\nL 145.429323 38.179535 \r\nL 145.733991 37.170428 \r\nL 146.038659 37.508726 \r\nL 146.343328 37.016219 \r\nL 146.647996 37.780408 \r\nL 147.257333 38.443995 \r\nL 147.562001 37.194294 \r\nL 147.866669 37.193552 \r\nL 148.171338 37.733826 \r\nL 148.476006 37.545313 \r\nL 149.085342 37.707706 \r\nL 149.390011 36.802115 \r\nL 149.694679 38.110824 \r\nL 149.999347 37.427195 \r\nL 150.304016 37.794819 \r\nL 150.608684 37.970245 \r\nL 150.913352 37.152474 \r\nL 151.218021 37.211777 \r\nL 151.522689 37.947691 \r\nL 151.827357 37.802836 \r\nL 152.436694 36.088657 \r\nL 152.741362 37.196144 \r\nL 153.04603 36.554005 \r\nL 153.350699 37.078847 \r\nL 153.655367 36.704651 \r\nL 153.960035 37.654798 \r\nL 154.264704 36.81311 \r\nL 154.569372 36.55969 \r\nL 154.87404 37.391734 \r\nL 155.178709 36.859345 \r\nL 155.483377 36.792665 \r\nL 155.788045 35.809478 \r\nL 156.092713 36.211666 \r\nL 156.397382 35.98353 \r\nL 156.70205 36.274297 \r\nL 157.006718 36.088462 \r\nL 157.920723 36.782156 \r\nL 158.225392 37.901015 \r\nL 158.53006 36.153159 \r\nL 158.834728 36.401754 \r\nL 159.139396 36.185178 \r\nL 159.748733 36.572076 \r\nL 160.053401 36.027569 \r\nL 160.662738 35.668354 \r\nL 160.967406 36.068268 \r\nL 161.272075 35.256654 \r\nL 161.576743 36.140523 \r\nL 161.881411 35.975102 \r\nL 162.18608 37.197514 \r\nL 162.490748 36.057984 \r\nL 162.795416 35.744472 \r\nL 163.100084 35.625706 \r\nL 163.404753 35.187232 \r\nL 163.709421 35.505846 \r\nL 164.014089 36.09365 \r\nL 164.318758 35.240384 \r\nL 164.623426 35.762226 \r\nL 164.928094 35.506572 \r\nL 165.232763 36.572208 \r\nL 165.537431 36.470389 \r\nL 165.842099 35.568093 \r\nL 166.451436 35.179603 \r\nL 166.756104 36.091216 \r\nL 167.060772 36.087741 \r\nL 167.365441 34.543912 \r\nL 167.670109 35.875347 \r\nL 167.974777 35.834582 \r\nL 168.279446 35.306621 \r\nL 168.584114 35.223002 \r\nL 168.888782 35.789021 \r\nL 169.193451 35.894412 \r\nL 169.498119 34.807404 \r\nL 169.802787 34.991728 \r\nL 170.107455 35.644061 \r\nL 170.412124 34.807919 \r\nL 170.716792 35.971179 \r\nL 171.02146 34.64285 \r\nL 171.326129 35.227337 \r\nL 171.630797 34.785951 \r\nL 172.240134 35.262717 \r\nL 172.544802 35.383631 \r\nL 172.84947 35.889202 \r\nL 173.154139 34.66092 \r\nL 173.458807 34.851761 \r\nL 173.763475 35.284837 \r\nL 174.372812 34.855104 \r\nL 174.67748 34.461087 \r\nL 174.982148 35.549442 \r\nL 175.286817 34.465255 \r\nL 175.591485 34.020516 \r\nL 175.896153 35.140514 \r\nL 176.200822 34.587327 \r\nL 176.50549 34.362869 \r\nL 176.810158 34.694873 \r\nL 177.114826 34.315542 \r\nL 177.724163 34.296289 \r\nL 178.028831 34.386407 \r\nL 178.3335 34.304651 \r\nL 178.638168 34.502191 \r\nL 178.942836 34.975892 \r\nL 179.247505 34.129487 \r\nL 179.552173 34.009941 \r\nL 179.856841 34.481073 \r\nL 180.16151 34.50408 \r\nL 180.466178 34.255307 \r\nL 180.770846 34.965256 \r\nL 181.380183 33.744402 \r\nL 181.684851 33.774896 \r\nL 181.989519 34.482318 \r\nL 182.903524 33.41437 \r\nL 183.208193 34.075704 \r\nL 183.512861 34.127499 \r\nL 183.817529 33.909764 \r\nL 184.122197 33.190284 \r\nL 184.426866 34.185031 \r\nL 184.731534 34.305217 \r\nL 185.036202 33.420199 \r\nL 185.340871 33.474244 \r\nL 185.645539 32.833672 \r\nL 185.950207 32.984373 \r\nL 186.254876 33.600799 \r\nL 187.168881 33.597935 \r\nL 187.778217 32.999308 \r\nL 188.082885 32.996727 \r\nL 188.387554 33.642728 \r\nL 188.692222 32.458156 \r\nL 188.99689 33.670505 \r\nL 189.301559 33.825399 \r\nL 189.606227 33.649726 \r\nL 189.910895 32.985248 \r\nL 190.520232 32.628561 \r\nL 190.8249 33.089982 \r\nL 191.434237 33.397925 \r\nL 192.043573 33.198419 \r\nL 192.348242 33.13102 \r\nL 192.65291 32.708129 \r\nL 192.957578 32.546584 \r\nL 193.262247 32.720373 \r\nL 193.566915 32.65491 \r\nL 193.871583 33.410203 \r\nL 194.176252 31.921017 \r\nL 194.48092 32.158555 \r\nL 194.785588 32.809208 \r\nL 195.090256 32.141218 \r\nL 195.394925 33.268053 \r\nL 195.699593 33.318882 \r\nL 196.004261 32.778143 \r\nL 196.30893 32.819492 \r\nL 196.613598 32.357914 \r\nL 196.918266 32.485975 \r\nL 197.222935 32.914531 \r\nL 197.527603 32.453936 \r\nL 197.832271 32.284952 \r\nL 198.136939 32.956068 \r\nL 198.441608 31.992118 \r\nL 198.746276 32.129259 \r\nL 199.050944 32.913975 \r\nL 199.660281 31.825681 \r\nL 199.964949 32.310571 \r\nL 200.269618 32.362317 \r\nL 200.574286 32.287176 \r\nL 200.878954 31.961843 \r\nL 201.792959 32.247194 \r\nL 202.706964 30.992744 \r\nL 203.011632 32.345172 \r\nL 203.316301 31.667167 \r\nL 203.620969 31.824891 \r\nL 203.925637 32.189262 \r\nL 204.534974 31.217364 \r\nL 204.839642 31.767624 \r\nL 205.144311 31.694341 \r\nL 205.448979 31.246827 \r\nL 205.753647 31.026074 \r\nL 206.058315 31.734875 \r\nL 206.362984 32.156134 \r\nL 206.667652 31.909881 \r\nL 206.97232 31.423289 \r\nL 207.276989 32.010091 \r\nL 207.581657 31.526493 \r\nL 207.886325 30.311016 \r\nL 208.190994 30.869883 \r\nL 208.80033 31.114318 \r\nL 209.104998 30.861782 \r\nL 209.409667 31.191429 \r\nL 209.714335 31.182052 \r\nL 210.019003 30.714528 \r\nL 210.62834 32.003548 \r\nL 210.933008 31.312555 \r\nL 211.237677 31.916837 \r\nL 211.542345 31.033545 \r\nL 211.847013 31.120213 \r\nL 212.151682 30.895046 \r\nL 212.45635 31.403847 \r\nL 212.761018 31.694128 \r\nL 213.370355 30.676757 \r\nL 213.675023 30.268847 \r\nL 213.979691 30.160359 \r\nL 214.28436 31.244808 \r\nL 214.589028 30.637026 \r\nL 215.503033 30.27043 \r\nL 216.112369 30.429061 \r\nL 216.417038 30.893531 \r\nL 216.721706 30.440148 \r\nL 217.026374 30.195344 \r\nL 217.331043 29.714591 \r\nL 217.635711 31.01337 \r\nL 217.940379 31.100604 \r\nL 218.549716 31.119443 \r\nL 218.854384 29.551926 \r\nL 219.159053 30.94886 \r\nL 219.463721 29.750521 \r\nL 219.768389 30.459609 \r\nL 220.073057 30.590556 \r\nL 220.377726 31.018789 \r\nL 220.682394 30.011545 \r\nL 220.987062 29.867075 \r\nL 221.291731 30.401553 \r\nL 221.596399 30.29321 \r\nL 221.901067 30.785769 \r\nL 222.205736 29.566694 \r\nL 222.510404 29.722607 \r\nL 222.815072 30.68677 \r\nL 223.11974 29.251321 \r\nL 223.424409 29.151477 \r\nL 223.729077 30.024757 \r\nL 224.033745 30.473917 \r\nL 224.338414 29.045309 \r\nL 224.643082 30.082175 \r\nL 225.252419 29.26992 \r\nL 225.557087 29.414885 \r\nL 226.166424 29.479497 \r\nL 226.77576 30.053234 \r\nL 227.080428 29.551249 \r\nL 227.385097 29.906598 \r\nL 227.689765 29.532045 \r\nL 227.994433 29.813619 \r\nL 228.299102 29.385276 \r\nL 228.908438 29.292972 \r\nL 229.213107 29.865762 \r\nL 229.517775 29.093404 \r\nL 230.127111 29.617986 \r\nL 230.43178 29.657428 \r\nL 230.736448 29.007688 \r\nL 231.041116 29.922117 \r\nL 231.345785 28.085389 \r\nL 231.650453 29.063675 \r\nL 231.955121 29.31229 \r\nL 232.25979 30.127464 \r\nL 232.564458 29.011857 \r\nL 232.869126 28.889414 \r\nL 233.173795 29.495697 \r\nL 233.478463 28.886929 \r\nL 233.783131 28.658657 \r\nL 234.392468 29.305182 \r\nL 234.697136 28.231686 \r\nL 235.001804 29.139705 \r\nL 235.306473 28.975493 \r\nL 235.915809 28.321242 \r\nL 236.220478 28.490512 \r\nL 236.525146 28.084598 \r\nL 237.134482 28.008257 \r\nL 237.743819 27.876947 \r\nL 238.048487 27.636866 \r\nL 238.353156 28.266692 \r\nL 238.657824 28.578219 \r\nL 238.962492 27.445148 \r\nL 239.267161 27.738317 \r\nL 239.571829 28.59977 \r\nL 239.876497 28.663169 \r\nL 240.485834 28.024212 \r\nL 240.790502 28.41931 \r\nL 241.09517 28.185742 \r\nL 241.399839 28.159049 \r\nL 242.009175 28.334866 \r\nL 242.313844 27.355717 \r\nL 242.618512 27.102664 \r\nL 242.92318 29.055123 \r\nL 243.227849 27.502125 \r\nL 243.532517 27.794848 \r\nL 243.837185 27.508385 \r\nL 244.141854 28.182159 \r\nL 244.446522 27.456386 \r\nL 245.055858 28.004874 \r\nL 245.360527 27.578517 \r\nL 245.665195 26.834665 \r\nL 245.969863 27.397111 \r\nL 246.274532 27.065806 \r\nL 246.883868 27.671464 \r\nL 247.188537 27.594892 \r\nL 247.493205 27.357133 \r\nL 247.797873 27.702213 \r\nL 248.102541 27.495728 \r\nL 248.711878 27.503048 \r\nL 249.016546 28.160354 \r\nL 249.321215 27.258014 \r\nL 249.625883 26.822679 \r\nL 249.930551 26.843868 \r\nL 250.23522 26.638423 \r\nL 250.844556 27.265698 \r\nL 251.149225 27.866797 \r\nL 251.453893 26.955911 \r\nL 251.758561 27.28373 \r\nL 252.063229 26.596166 \r\nL 252.367898 26.714267 \r\nL 252.672566 26.702961 \r\nL 252.977234 26.895932 \r\nL 253.281903 26.918995 \r\nL 253.586571 27.10754 \r\nL 253.891239 26.227372 \r\nL 254.195908 26.81125 \r\nL 254.500576 27.024861 \r\nL 254.805244 26.763108 \r\nL 255.109912 27.215998 \r\nL 255.414581 27.029239 \r\nL 255.719249 27.330125 \r\nL 256.023917 27.190658 \r\nL 256.328586 27.464286 \r\nL 256.633254 26.547024 \r\nL 256.937922 26.472387 \r\nL 257.242591 27.164468 \r\nL 258.156596 26.150791 \r\nL 258.461264 27.019867 \r\nL 258.765932 25.90339 \r\nL 259.0706 26.343301 \r\nL 259.375269 26.547658 \r\nL 259.679937 27.714571 \r\nL 260.289274 25.779322 \r\nL 260.593942 25.728989 \r\nL 260.89861 25.894742 \r\nL 261.203279 26.352135 \r\nL 261.507947 27.183841 \r\nL 261.812615 26.3378 \r\nL 262.421952 25.660832 \r\nL 262.72662 26.095774 \r\nL 263.031288 26.206639 \r\nL 263.335957 26.012949 \r\nL 263.640625 26.57819 \r\nL 263.945293 26.185553 \r\nL 264.249962 26.245404 \r\nL 264.55463 26.446157 \r\nL 264.859298 25.090332 \r\nL 265.163967 26.070842 \r\nL 265.468635 26.621583 \r\nL 265.773303 25.769234 \r\nL 266.077971 25.544531 \r\nL 266.38264 25.107793 \r\nL 266.687308 25.298746 \r\nL 266.991976 25.032911 \r\nL 267.296645 25.518204 \r\nL 267.601313 25.506827 \r\nL 267.905981 24.982985 \r\nL 268.21065 26.41449 \r\nL 268.515318 26.355451 \r\nL 268.819986 26.011381 \r\nL 269.124654 25.470994 \r\nL 269.429323 26.110637 \r\nL 269.733991 26.212254 \r\nL 270.038659 26.124971 \r\nL 270.343328 25.391843 \r\nL 270.647996 25.883974 \r\nL 270.952664 25.013991 \r\nL 271.257333 25.228563 \r\nL 271.562001 24.764941 \r\nL 271.866669 26.317461 \r\nL 272.171338 25.788075 \r\nL 272.476006 24.752302 \r\nL 272.780674 25.619021 \r\nL 273.085342 24.973302 \r\nL 273.390011 25.510426 \r\nL 273.694679 25.223575 \r\nL 273.999347 25.137682 \r\nL 274.304016 25.256311 \r\nL 274.608684 24.679906 \r\nL 274.913352 24.922259 \r\nL 275.218021 25.843055 \r\nL 275.522689 24.632304 \r\nL 275.827357 24.95412 \r\nL 276.132025 24.072682 \r\nL 276.741362 25.17881 \r\nL 277.04603 24.694931 \r\nL 277.350699 25.539741 \r\nL 277.655367 25.118188 \r\nL 277.960035 24.297447 \r\nL 278.264704 25.374143 \r\nL 278.569372 24.205385 \r\nL 278.87404 24.636323 \r\nL 279.178709 24.53989 \r\nL 279.483377 24.216732 \r\nL 279.788045 24.628343 \r\nL 280.092713 24.231933 \r\nL 280.397382 24.521526 \r\nL 280.70205 24.514106 \r\nL 281.006718 25.347478 \r\nL 281.311387 24.589644 \r\nL 281.920723 24.892154 \r\nL 282.225392 24.844653 \r\nL 282.53006 24.564753 \r\nL 282.834728 24.748868 \r\nL 283.139396 23.66169 \r\nL 283.444065 24.796741 \r\nL 283.748733 24.310609 \r\nL 284.053401 24.396703 \r\nL 284.35807 24.273337 \r\nL 284.662738 24.670181 \r\nL 284.967406 24.00678 \r\nL 285.272075 24.11719 \r\nL 285.576743 23.623694 \r\nL 285.881411 24.050286 \r\nL 286.490748 23.732948 \r\nL 286.795416 23.753558 \r\nL 287.404753 24.333687 \r\nL 287.709421 23.778278 \r\nL 288.014089 24.202338 \r\nL 288.318758 23.420646 \r\nL 288.623426 23.597027 \r\nL 288.928094 22.891724 \r\nL 289.232763 22.863361 \r\nL 289.537431 23.480631 \r\nL 289.842099 22.89846 \r\nL 290.146768 23.950004 \r\nL 290.451436 23.389502 \r\nL 290.756104 23.474913 \r\nL 291.060772 23.250278 \r\nL 291.670109 23.275012 \r\nL 291.974777 23.493474 \r\nL 292.279446 23.089049 \r\nL 292.584114 23.566778 \r\nL 292.888782 23.381557 \r\nL 293.193451 23.900335 \r\nL 293.498119 22.949475 \r\nL 293.802787 23.035002 \r\nL 294.107455 23.468123 \r\nL 294.412124 23.414299 \r\nL 294.716792 22.723258 \r\nL 295.02146 22.577012 \r\nL 295.326129 23.23565 \r\nL 295.935465 23.015647 \r\nL 296.240134 22.449109 \r\nL 296.84947 23.17337 \r\nL 297.154139 22.851002 \r\nL 297.458807 23.146958 \r\nL 297.763475 22.391054 \r\nL 298.068143 24.213402 \r\nL 298.372812 23.796104 \r\nL 298.67748 24.150939 \r\nL 299.286817 22.911182 \r\nL 299.591485 23.170883 \r\nL 299.896153 22.965712 \r\nL 300.200822 23.188897 \r\nL 300.50549 22.52263 \r\nL 300.810158 24.024798 \r\nL 301.114826 22.350225 \r\nL 301.419495 22.325329 \r\nL 301.724163 22.923287 \r\nL 302.028831 22.369912 \r\nL 302.3335 22.089887 \r\nL 302.638168 22.422432 \r\nL 302.942836 22.227372 \r\nL 303.247505 21.826234 \r\nL 303.856841 22.966689 \r\nL 304.16151 22.101771 \r\nL 304.466178 21.580974 \r\nL 304.770846 22.200774 \r\nL 305.075514 21.962505 \r\nL 305.380183 22.600622 \r\nL 305.684851 21.568189 \r\nL 305.989519 21.869631 \r\nL 306.294188 21.524924 \r\nL 306.598856 20.340604 \r\nL 306.903524 22.926798 \r\nL 307.208193 22.525688 \r\nL 307.512861 21.439742 \r\nL 307.817529 21.641929 \r\nL 308.122197 22.110975 \r\nL 309.036202 22.438796 \r\nL 309.340871 21.424257 \r\nL 309.950207 22.039298 \r\nL 310.254876 21.351063 \r\nL 310.559544 21.539672 \r\nL 310.864212 22.010012 \r\nL 311.168881 21.179764 \r\nL 311.473549 21.316341 \r\nL 311.778217 22.385266 \r\nL 312.082885 20.537752 \r\nL 312.387554 21.784213 \r\nL 312.692222 21.320226 \r\nL 312.99689 22.257434 \r\nL 313.301559 22.015374 \r\nL 313.910895 21.971785 \r\nL 314.215564 21.646026 \r\nL 314.520232 20.807804 \r\nL 314.8249 21.639456 \r\nL 315.129568 21.152623 \r\nL 315.434237 21.29092 \r\nL 315.738905 20.560221 \r\nL 316.043573 20.952135 \r\nL 316.348242 20.930499 \r\nL 316.65291 21.671533 \r\nL 316.957578 21.07396 \r\nL 317.262247 19.860074 \r\nL 317.566915 21.051383 \r\nL 317.871583 20.724957 \r\nL 318.176252 20.85888 \r\nL 318.48092 19.938239 \r\nL 318.785588 20.980296 \r\nL 319.090256 20.581912 \r\nL 319.394925 20.624047 \r\nL 319.699593 21.383539 \r\nL 320.004261 20.245873 \r\nL 320.30893 20.327056 \r\nL 320.613598 21.384361 \r\nL 320.918266 19.952567 \r\nL 321.222935 20.802541 \r\nL 321.832271 21.091929 \r\nL 322.136939 20.425778 \r\nL 322.441608 20.213335 \r\nL 322.746276 20.298304 \r\nL 323.050944 20.553986 \r\nL 323.355613 21.005932 \r\nL 323.964949 21.075416 \r\nL 324.269618 20.213044 \r\nL 324.574286 19.766292 \r\nL 324.878954 20.355635 \r\nL 325.183623 20.449603 \r\nL 325.488291 18.890031 \r\nL 325.792959 19.175058 \r\nL 326.097627 20.808318 \r\nL 326.706964 20.135649 \r\nL 327.011632 20.338092 \r\nL 327.316301 19.78062 \r\nL 327.620969 20.149336 \r\nL 327.925637 19.46291 \r\nL 328.230306 19.365115 \r\nL 328.534974 20.359278 \r\nL 329.144311 19.219347 \r\nL 329.448979 19.564141 \r\nL 329.753647 18.92443 \r\nL 330.058315 19.182058 \r\nL 330.362984 19.268493 \r\nL 330.667652 19.706592 \r\nL 330.97232 19.849703 \r\nL 331.276989 19.525911 \r\nL 331.581657 19.650427 \r\nL 331.886325 18.621992 \r\nL 332.495662 19.521009 \r\nL 332.80033 19.151718 \r\nL 333.104998 20.059994 \r\nL 333.409667 20.277227 \r\nL 333.714335 19.15156 \r\nL 334.019003 19.07299 \r\nL 334.323672 18.753969 \r\nL 334.62834 18.937358 \r\nL 334.933008 19.655214 \r\nL 335.237677 17.864646 \r\nL 335.542345 19.336849 \r\nL 335.847013 20.126308 \r\nL 336.151682 19.876903 \r\nL 336.45635 19.035872 \r\nL 336.761018 19.355493 \r\nL 337.065686 19.190557 \r\nL 337.370355 18.715083 \r\nL 337.979691 19.554669 \r\nL 338.589028 19.057175 \r\nL 338.893696 19.444964 \r\nL 339.198365 18.671371 \r\nL 339.503033 18.660313 \r\nL 339.807701 18.496923 \r\nL 340.417038 19.487962 \r\nL 340.721706 17.725957 \r\nL 341.026374 18.704163 \r\nL 341.331043 18.696612 \r\nL 341.940379 19.155153 \r\nL 342.245048 18.852492 \r\nL 342.549716 18.874913 \r\nL 342.854384 18.622918 \r\nL 343.159053 20.091975 \r\nL 343.463721 18.583001 \r\nL 343.768389 18.543803 \r\nL 344.073057 18.175106 \r\nL 344.377726 18.43196 \r\nL 345.291731 19.770484 \r\nL 345.596399 18.346096 \r\nL 345.901067 18.551416 \r\nL 346.205736 17.982269 \r\nL 346.815072 18.033977 \r\nL 347.424409 18.653538 \r\nL 347.729077 18.278214 \r\nL 348.033745 18.296685 \r\nL 348.338414 19.122679 \r\nL 348.643082 18.588921 \r\nL 348.94775 17.76518 \r\nL 349.252419 18.295468 \r\nL 349.557087 17.686667 \r\nL 349.861755 18.012411 \r\nL 350.166424 18.170444 \r\nL 350.77576 17.504506 \r\nL 351.080428 17.829241 \r\nL 351.385097 17.551241 \r\nL 351.689765 17.881467 \r\nL 351.994433 17.589633 \r\nL 352.299102 17.87052 \r\nL 352.60377 17.669521 \r\nL 352.908438 19.01037 \r\nL 353.213107 17.083636 \r\nL 353.517775 17.811462 \r\nL 353.822443 18.249875 \r\nL 353.822443 18.249875 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 34.240625 224.64 \r\nL 34.240625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 369.040625 224.64 \r\nL 369.040625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 34.240625 224.64 \r\nL 369.040625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 34.240625 7.2 \r\nL 369.040625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 41.240625 45.1125 \r\nL 120.83125 45.1125 \r\nQ 122.83125 45.1125 122.83125 43.1125 \r\nL 122.83125 14.2 \r\nQ 122.83125 12.2 120.83125 12.2 \r\nL 41.240625 12.2 \r\nQ 39.240625 12.2 39.240625 14.2 \r\nL 39.240625 43.1125 \r\nQ 39.240625 45.1125 41.240625 45.1125 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 43.240625 20.298437 \r\nL 63.240625 20.298437 \r\n\" style=\"fill:none;stroke:#bfbf00;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_16\">\r\n     <!-- train_loss -->\r\n     <defs>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <g transform=\"translate(71.240625 23.798437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"310.546875\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"371.728516\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"423.828125\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 43.240625 35.254687 \r\nL 63.240625 35.254687 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_17\">\r\n     <!-- val_loss -->\r\n     <defs>\r\n      <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n     </defs>\r\n     <g transform=\"translate(71.240625 38.754687)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_20\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 3.5 0 \r\n\" id=\"m32fa8e7316\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m32fa8e7316\" y=\"213.595537\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 0.4 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(376.040625 217.394756)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m32fa8e7316\" y=\"178.770644\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(376.040625 182.569863)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m32fa8e7316\" y=\"143.945752\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(376.040625 147.74497)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m32fa8e7316\" y=\"109.120859\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 0.7 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(376.040625 112.920078)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m32fa8e7316\" y=\"74.295966\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(376.040625 78.095185)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m32fa8e7316\" y=\"39.471073\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 0.9 -->\r\n      <defs>\r\n       <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n      </defs>\r\n      <g transform=\"translate(376.040625 43.270292)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_24\">\r\n     <!-- accuracy -->\r\n     <defs>\r\n      <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n     </defs>\r\n     <g transform=\"translate(403.542188 138.479375)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#p508ee491aa)\" d=\"M 49.458807 20.566122 \r\nL 49.763475 20.566122 \r\nL 50.068143 19.073634 \r\nL 50.67748 20.068633 \r\nL 50.982148 20.068633 \r\nL 51.286817 21.063632 \r\nL 51.896153 19.073634 \r\nL 52.50549 20.068633 \r\nL 53.114826 20.068633 \r\nL 53.419495 19.073634 \r\nL 53.724163 19.073634 \r\nL 54.028831 20.068633 \r\nL 54.3335 20.566122 \r\nL 54.638168 20.068633 \r\nL 54.942836 20.068633 \r\nL 55.247505 19.073634 \r\nL 55.552173 19.073634 \r\nL 55.856841 20.068633 \r\nL 56.16151 18.078635 \r\nL 56.466178 20.068633 \r\nL 56.770846 19.571144 \r\nL 57.684851 19.571144 \r\nL 57.989519 19.073634 \r\nL 58.294188 19.571144 \r\nL 58.598856 20.566122 \r\nL 58.903524 19.073634 \r\nL 59.512861 20.068633 \r\nL 59.817529 19.073634 \r\nL 60.426866 19.073634 \r\nL 60.731534 20.068633 \r\nL 61.036202 19.571144 \r\nL 61.340871 18.576145 \r\nL 61.645539 20.566122 \r\nL 61.950207 19.073634 \r\nL 62.254876 19.073634 \r\nL 62.559544 19.571144 \r\nL 62.864212 18.576145 \r\nL 63.168881 19.571144 \r\nL 63.473549 19.571144 \r\nL 63.778217 18.078635 \r\nL 64.082885 19.073634 \r\nL 64.387554 19.571144 \r\nL 64.692222 18.576145 \r\nL 65.301559 18.576145 \r\nL 65.606227 19.571144 \r\nL 66.215564 19.571144 \r\nL 66.520232 18.576145 \r\nL 66.8249 20.566122 \r\nL 67.129568 19.073634 \r\nL 67.434237 19.571144 \r\nL 67.738905 18.576145 \r\nL 68.043573 19.571144 \r\nL 68.348242 19.073634 \r\nL 68.65291 19.571144 \r\nL 68.957578 18.078635 \r\nL 69.262247 19.073634 \r\nL 69.566915 19.571144 \r\nL 69.871583 19.571144 \r\nL 70.176252 19.073634 \r\nL 70.48092 19.073634 \r\nL 70.785588 19.571144 \r\nL 71.394925 18.576145 \r\nL 71.699593 18.576145 \r\nL 72.004261 19.073634 \r\nL 72.30893 18.576145 \r\nL 73.222935 18.576145 \r\nL 73.527603 19.073634 \r\nL 73.832271 18.576145 \r\nL 74.136939 19.073634 \r\nL 74.441608 18.576145 \r\nL 74.746276 18.576145 \r\nL 75.050944 19.571144 \r\nL 75.355613 18.078635 \r\nL 75.660281 19.073634 \r\nL 75.964949 18.576145 \r\nL 76.269618 18.576145 \r\nL 76.574286 19.571144 \r\nL 76.878954 18.078635 \r\nL 77.183623 19.073634 \r\nL 77.488291 18.576145 \r\nL 78.097627 18.576145 \r\nL 78.402296 18.078635 \r\nL 78.706964 19.073634 \r\nL 79.011632 19.073634 \r\nL 79.316301 18.576145 \r\nL 79.620969 19.073634 \r\nL 80.230306 18.078635 \r\nL 80.534974 19.571144 \r\nL 80.839642 18.078635 \r\nL 81.144311 18.576145 \r\nL 81.448979 18.078635 \r\nL 81.753647 18.078635 \r\nL 82.058315 20.068633 \r\nL 82.362984 18.078635 \r\nL 82.97232 19.073634 \r\nL 83.581657 19.073634 \r\nL 83.886325 18.576145 \r\nL 84.495662 18.576145 \r\nL 84.80033 18.078635 \r\nL 85.104998 18.576145 \r\nL 85.409667 18.078635 \r\nL 85.714335 18.576145 \r\nL 86.019003 18.078635 \r\nL 86.323672 19.571144 \r\nL 86.62834 18.576145 \r\nL 86.933008 18.078635 \r\nL 87.237677 18.576145 \r\nL 87.542345 18.576145 \r\nL 87.847013 18.078635 \r\nL 88.151682 19.571144 \r\nL 88.45635 19.073634 \r\nL 88.761018 18.078635 \r\nL 89.370355 18.078635 \r\nL 89.675023 19.073634 \r\nL 89.979691 18.078635 \r\nL 90.28436 18.576145 \r\nL 90.589028 18.078635 \r\nL 90.893696 18.078635 \r\nL 91.198365 18.576145 \r\nL 91.503033 18.078635 \r\nL 92.721706 18.078635 \r\nL 93.026374 18.576145 \r\nL 93.331043 18.078635 \r\nL 94.854384 18.078635 \r\nL 95.159053 19.073634 \r\nL 95.463721 18.078635 \r\nL 96.073057 18.078635 \r\nL 96.377726 18.576145 \r\nL 96.682394 18.078635 \r\nL 96.987062 18.576145 \r\nL 97.291731 18.078635 \r\nL 97.901067 18.078635 \r\nL 98.205736 19.073634 \r\nL 98.510404 18.078635 \r\nL 98.815072 18.078635 \r\nL 99.11974 18.576145 \r\nL 99.729077 17.581146 \r\nL 100.033745 18.078635 \r\nL 101.252419 18.078635 \r\nL 101.557087 17.581146 \r\nL 101.861755 17.581146 \r\nL 102.166424 18.078635 \r\nL 102.77576 18.078635 \r\nL 103.080428 18.576145 \r\nL 103.385097 18.078635 \r\nL 103.994433 18.078635 \r\nL 104.299102 18.576145 \r\nL 104.60377 18.078635 \r\nL 105.822443 18.078635 \r\nL 106.127111 17.581146 \r\nL 106.43178 18.078635 \r\nL 106.736448 18.078635 \r\nL 107.041116 17.581146 \r\nL 107.345785 18.576145 \r\nL 107.955121 17.581146 \r\nL 108.25979 18.576145 \r\nL 108.564458 18.576145 \r\nL 108.869126 18.078635 \r\nL 109.478463 18.078635 \r\nL 109.783131 17.581146 \r\nL 110.087799 17.581146 \r\nL 110.392468 18.078635 \r\nL 110.697136 17.581146 \r\nL 111.001804 18.078635 \r\nL 111.611141 18.078635 \r\nL 111.915809 18.576145 \r\nL 112.220478 18.078635 \r\nL 113.743819 18.078635 \r\nL 114.048487 18.576145 \r\nL 114.657824 17.581146 \r\nL 114.962492 17.581146 \r\nL 115.571829 18.576145 \r\nL 115.876497 18.078635 \r\nL 116.181166 18.576145 \r\nL 116.790502 17.581146 \r\nL 117.09517 18.078635 \r\nL 117.399839 17.581146 \r\nL 117.704507 18.078635 \r\nL 118.009175 17.581146 \r\nL 118.313844 18.078635 \r\nL 118.618512 17.581146 \r\nL 118.92318 17.581146 \r\nL 119.227849 18.078635 \r\nL 119.532517 17.581146 \r\nL 119.837185 18.078635 \r\nL 120.141854 18.078635 \r\nL 120.446522 17.581146 \r\nL 120.75119 18.078635 \r\nL 121.055858 18.078635 \r\nL 121.360527 17.581146 \r\nL 121.665195 18.078635 \r\nL 122.274532 18.078635 \r\nL 122.5792 17.581146 \r\nL 122.883868 18.078635 \r\nL 124.711878 18.078635 \r\nL 125.016546 17.581146 \r\nL 125.321215 18.078635 \r\nL 125.625883 17.083636 \r\nL 125.930551 18.078635 \r\nL 126.23522 17.581146 \r\nL 126.539888 18.576145 \r\nL 127.149225 17.581146 \r\nL 127.758561 17.581146 \r\nL 128.063229 18.078635 \r\nL 128.367898 17.581146 \r\nL 128.672566 17.581146 \r\nL 128.977234 18.078635 \r\nL 129.281903 18.078635 \r\nL 129.891239 17.083636 \r\nL 130.195908 18.078635 \r\nL 130.500576 17.581146 \r\nL 130.805244 17.581146 \r\nL 131.109912 17.083636 \r\nL 131.414581 17.581146 \r\nL 132.023917 17.581146 \r\nL 132.328586 18.078635 \r\nL 132.633254 17.581146 \r\nL 133.851927 17.581146 \r\nL 134.156596 18.078635 \r\nL 134.461264 18.078635 \r\nL 134.765932 17.581146 \r\nL 135.0706 17.581146 \r\nL 135.375269 17.083636 \r\nL 135.679937 17.083636 \r\nL 135.984605 18.078635 \r\nL 136.289274 17.581146 \r\nL 136.593942 18.078635 \r\nL 136.89861 17.083636 \r\nL 137.203279 18.078635 \r\nL 137.507947 17.581146 \r\nL 138.117283 17.581146 \r\nL 138.421952 18.078635 \r\nL 138.72662 17.581146 \r\nL 139.031288 18.078635 \r\nL 139.335957 17.083636 \r\nL 139.640625 18.078635 \r\nL 139.945293 17.581146 \r\nL 140.249962 17.581146 \r\nL 140.55463 18.078635 \r\nL 140.859298 17.083636 \r\nL 141.163967 17.083636 \r\nL 141.468635 17.581146 \r\nL 141.773303 17.083636 \r\nL 142.38264 17.083636 \r\nL 142.687308 18.078635 \r\nL 142.991976 18.078635 \r\nL 143.601313 17.083636 \r\nL 143.905981 18.078635 \r\nL 144.21065 18.078635 \r\nL 144.515318 17.083636 \r\nL 144.819986 17.083636 \r\nL 145.124654 17.581146 \r\nL 145.429323 17.083636 \r\nL 145.733991 17.581146 \r\nL 146.038659 17.083636 \r\nL 146.343328 17.581146 \r\nL 146.647996 17.083636 \r\nL 148.171338 17.083636 \r\nL 148.476006 17.581146 \r\nL 148.780674 17.083636 \r\nL 149.085342 17.581146 \r\nL 149.390011 17.581146 \r\nL 149.694679 17.083636 \r\nL 149.999347 17.581146 \r\nL 150.608684 17.581146 \r\nL 150.913352 17.083636 \r\nL 151.218021 17.581146 \r\nL 151.522689 17.581146 \r\nL 151.827357 17.083636 \r\nL 152.132025 17.581146 \r\nL 152.436694 17.083636 \r\nL 153.960035 17.083636 \r\nL 154.264704 17.581146 \r\nL 154.569372 17.581146 \r\nL 154.87404 17.083636 \r\nL 155.178709 17.581146 \r\nL 155.483377 17.581146 \r\nL 155.788045 17.083636 \r\nL 156.397382 17.083636 \r\nL 157.006718 18.078635 \r\nL 157.311387 17.581146 \r\nL 157.616055 17.581146 \r\nL 157.920723 17.083636 \r\nL 158.225392 17.581146 \r\nL 158.53006 17.083636 \r\nL 158.834728 17.581146 \r\nL 159.139396 17.083636 \r\nL 159.444065 17.083636 \r\nL 159.748733 18.078635 \r\nL 160.35807 17.083636 \r\nL 160.662738 17.581146 \r\nL 160.967406 17.083636 \r\nL 161.881411 17.083636 \r\nL 162.18608 17.581146 \r\nL 162.490748 17.083636 \r\nL 162.795416 17.083636 \r\nL 163.100084 17.581146 \r\nL 163.404753 17.083636 \r\nL 164.623426 17.083636 \r\nL 164.928094 17.581146 \r\nL 165.232763 17.581146 \r\nL 165.537431 17.083636 \r\nL 167.974777 17.083636 \r\nL 168.279446 17.581146 \r\nL 168.584114 17.083636 \r\nL 169.193451 17.083636 \r\nL 169.498119 17.581146 \r\nL 169.802787 17.083636 \r\nL 170.107455 17.083636 \r\nL 170.412124 17.581146 \r\nL 170.716792 17.083636 \r\nL 171.02146 17.083636 \r\nL 171.326129 17.581146 \r\nL 171.630797 17.083636 \r\nL 171.935465 17.083636 \r\nL 172.240134 17.581146 \r\nL 172.544802 17.581146 \r\nL 172.84947 17.083636 \r\nL 174.068143 17.083636 \r\nL 174.372812 17.581146 \r\nL 174.982148 17.581146 \r\nL 175.286817 17.083636 \r\nL 175.591485 17.083636 \r\nL 175.896153 17.581146 \r\nL 176.200822 17.083636 \r\nL 176.810158 17.083636 \r\nL 177.114826 17.581146 \r\nL 177.419495 17.083636 \r\nL 178.028831 17.083636 \r\nL 178.3335 17.581146 \r\nL 178.638168 17.083636 \r\nL 178.942836 17.581146 \r\nL 179.552173 17.581146 \r\nL 179.856841 17.083636 \r\nL 198.136939 17.083636 \r\nL 198.441608 17.581146 \r\nL 198.746276 17.083636 \r\nL 353.822443 17.083636 \r\nL 353.822443 17.083636 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p508ee491aa)\" d=\"M 49.458807 208.95222 \r\nL 50.372812 208.95222 \r\nL 50.982148 211.273878 \r\nL 51.286817 207.791392 \r\nL 51.591485 207.791392 \r\nL 52.200822 210.113049 \r\nL 52.50549 210.113049 \r\nL 52.810158 207.791392 \r\nL 53.114826 210.113049 \r\nL 53.419495 208.95222 \r\nL 54.028831 208.95222 \r\nL 54.3335 211.273878 \r\nL 54.638168 210.113049 \r\nL 54.942836 210.113049 \r\nL 55.247505 208.95222 \r\nL 55.552173 210.113049 \r\nL 56.16151 210.113049 \r\nL 56.466178 207.791392 \r\nL 56.770846 210.113049 \r\nL 57.075514 207.791392 \r\nL 57.380183 207.791392 \r\nL 57.684851 211.273878 \r\nL 58.294188 206.630563 \r\nL 58.598856 207.791392 \r\nL 58.903524 206.630563 \r\nL 59.208193 206.630563 \r\nL 59.512861 207.791392 \r\nL 59.817529 207.791392 \r\nL 60.122197 210.113049 \r\nL 60.426866 210.113049 \r\nL 60.731534 211.273878 \r\nL 61.036202 208.95222 \r\nL 61.340871 208.95222 \r\nL 61.645539 210.113049 \r\nL 61.950207 208.95222 \r\nL 62.254876 210.113049 \r\nL 62.559544 207.791392 \r\nL 63.168881 210.113049 \r\nL 63.473549 208.95222 \r\nL 63.778217 208.95222 \r\nL 64.082885 211.273878 \r\nL 64.387554 207.791392 \r\nL 64.692222 208.95222 \r\nL 65.301559 208.95222 \r\nL 65.606227 210.113049 \r\nL 65.910895 207.791392 \r\nL 66.215564 210.113049 \r\nL 66.8249 207.791392 \r\nL 67.129568 210.113049 \r\nL 67.434237 206.630563 \r\nL 67.738905 211.273878 \r\nL 68.043573 211.273878 \r\nL 68.348242 208.95222 \r\nL 68.65291 210.113049 \r\nL 69.262247 207.791392 \r\nL 69.566915 207.791392 \r\nL 69.871583 211.273878 \r\nL 70.48092 208.95222 \r\nL 70.785588 208.95222 \r\nL 71.090256 206.630563 \r\nL 71.394925 208.95222 \r\nL 71.699593 208.95222 \r\nL 72.004261 207.791392 \r\nL 72.30893 210.113049 \r\nL 72.613598 208.95222 \r\nL 73.222935 208.95222 \r\nL 73.527603 210.113049 \r\nL 73.832271 207.791392 \r\nL 74.441608 210.113049 \r\nL 75.355613 210.113049 \r\nL 75.660281 211.273878 \r\nL 75.964949 210.113049 \r\nL 76.269618 211.273878 \r\nL 76.574286 211.273878 \r\nL 76.878954 210.113049 \r\nL 77.183623 211.273878 \r\nL 77.488291 210.113049 \r\nL 78.097627 210.113049 \r\nL 78.402296 208.95222 \r\nL 78.706964 208.95222 \r\nL 79.011632 210.113049 \r\nL 79.316301 210.113049 \r\nL 79.925637 207.791392 \r\nL 80.230306 210.113049 \r\nL 80.534974 208.95222 \r\nL 80.839642 208.95222 \r\nL 81.144311 211.273878 \r\nL 81.448979 211.273878 \r\nL 81.753647 206.630563 \r\nL 82.058315 210.113049 \r\nL 82.362984 208.95222 \r\nL 82.667652 211.273878 \r\nL 83.276989 208.95222 \r\nL 83.581657 210.113049 \r\nL 83.886325 208.95222 \r\nL 84.190994 206.630563 \r\nL 84.495662 211.273878 \r\nL 84.80033 208.95222 \r\nL 85.104998 211.273878 \r\nL 85.409667 208.95222 \r\nL 85.714335 208.95222 \r\nL 86.019003 211.273878 \r\nL 86.323672 210.113049 \r\nL 86.62834 210.113049 \r\nL 86.933008 207.791392 \r\nL 87.237677 207.791392 \r\nL 87.542345 211.273878 \r\nL 87.847013 211.273878 \r\nL 88.151682 208.95222 \r\nL 88.45635 211.273878 \r\nL 88.761018 211.273878 \r\nL 89.065686 207.791392 \r\nL 89.370355 210.113049 \r\nL 89.979691 210.113049 \r\nL 90.28436 208.95222 \r\nL 90.589028 210.113049 \r\nL 91.198365 207.791392 \r\nL 91.503033 210.113049 \r\nL 91.807701 207.791392 \r\nL 92.112369 212.434706 \r\nL 92.417038 211.273878 \r\nL 92.721706 207.791392 \r\nL 93.026374 210.113049 \r\nL 93.331043 211.273878 \r\nL 93.635711 211.273878 \r\nL 93.940379 210.113049 \r\nL 94.245048 210.113049 \r\nL 94.549716 211.273878 \r\nL 94.854384 211.273878 \r\nL 95.159053 210.113049 \r\nL 95.768389 210.113049 \r\nL 96.073057 211.273878 \r\nL 96.377726 210.113049 \r\nL 96.682394 207.791392 \r\nL 96.987062 210.113049 \r\nL 97.291731 207.791392 \r\nL 97.596399 208.95222 \r\nL 97.901067 208.95222 \r\nL 98.205736 211.273878 \r\nL 98.510404 208.95222 \r\nL 98.815072 211.273878 \r\nL 99.11974 211.273878 \r\nL 99.424409 208.95222 \r\nL 99.729077 211.273878 \r\nL 100.338414 211.273878 \r\nL 100.643082 207.791392 \r\nL 100.94775 211.273878 \r\nL 101.252419 210.113049 \r\nL 101.557087 211.273878 \r\nL 101.861755 207.791392 \r\nL 102.166424 210.113049 \r\nL 102.471092 210.113049 \r\nL 102.77576 211.273878 \r\nL 103.080428 210.113049 \r\nL 103.385097 210.113049 \r\nL 103.689765 211.273878 \r\nL 103.994433 211.273878 \r\nL 104.299102 208.95222 \r\nL 104.60377 210.113049 \r\nL 104.908438 207.791392 \r\nL 105.213107 211.273878 \r\nL 105.517775 210.113049 \r\nL 105.822443 206.630563 \r\nL 106.127111 211.273878 \r\nL 107.041116 207.791392 \r\nL 107.345785 211.273878 \r\nL 107.650453 211.273878 \r\nL 107.955121 212.434706 \r\nL 108.25979 211.273878 \r\nL 108.564458 211.273878 \r\nL 108.869126 206.630563 \r\nL 109.173795 210.113049 \r\nL 109.478463 210.113049 \r\nL 109.783131 208.95222 \r\nL 110.087799 212.434706 \r\nL 110.392468 207.791392 \r\nL 110.697136 210.113049 \r\nL 111.611141 210.113049 \r\nL 111.915809 208.95222 \r\nL 112.220478 208.95222 \r\nL 112.525146 210.113049 \r\nL 113.439151 210.113049 \r\nL 113.743819 211.273878 \r\nL 114.048487 208.95222 \r\nL 114.657824 211.273878 \r\nL 115.267161 211.273878 \r\nL 115.571829 210.113049 \r\nL 115.876497 212.434706 \r\nL 116.181166 208.95222 \r\nL 116.485834 211.273878 \r\nL 116.790502 211.273878 \r\nL 117.09517 207.791392 \r\nL 117.704507 212.434706 \r\nL 118.009175 211.273878 \r\nL 118.313844 212.434706 \r\nL 118.92318 207.791392 \r\nL 119.227849 211.273878 \r\nL 119.837185 211.273878 \r\nL 120.446522 208.95222 \r\nL 120.75119 208.95222 \r\nL 121.055858 211.273878 \r\nL 121.360527 206.630563 \r\nL 121.665195 210.113049 \r\nL 122.274532 210.113049 \r\nL 122.5792 211.273878 \r\nL 123.188537 208.95222 \r\nL 123.493205 212.434706 \r\nL 123.797873 210.113049 \r\nL 124.102541 211.273878 \r\nL 124.40721 210.113049 \r\nL 125.016546 212.434706 \r\nL 125.321215 211.273878 \r\nL 125.625883 206.630563 \r\nL 125.930551 211.273878 \r\nL 126.23522 211.273878 \r\nL 126.539888 210.113049 \r\nL 126.844556 210.113049 \r\nL 127.149225 211.273878 \r\nL 127.453893 210.113049 \r\nL 127.758561 212.434706 \r\nL 128.367898 210.113049 \r\nL 128.672566 210.113049 \r\nL 128.977234 206.630563 \r\nL 129.281903 208.95222 \r\nL 129.586571 207.791392 \r\nL 129.891239 212.434706 \r\nL 130.195908 210.113049 \r\nL 130.500576 208.95222 \r\nL 130.805244 211.273878 \r\nL 131.109912 208.95222 \r\nL 131.414581 210.113049 \r\nL 131.719249 208.95222 \r\nL 132.023917 212.434706 \r\nL 132.328586 208.95222 \r\nL 133.242591 212.434706 \r\nL 133.547259 211.273878 \r\nL 133.851927 212.434706 \r\nL 134.156596 207.791392 \r\nL 134.461264 211.273878 \r\nL 134.765932 212.434706 \r\nL 135.0706 211.273878 \r\nL 135.375269 211.273878 \r\nL 135.679937 210.113049 \r\nL 135.984605 212.434706 \r\nL 136.289274 211.273878 \r\nL 136.593942 211.273878 \r\nL 137.203279 208.95222 \r\nL 137.507947 212.434706 \r\nL 137.812615 211.273878 \r\nL 138.117283 208.95222 \r\nL 138.421952 211.273878 \r\nL 139.031288 211.273878 \r\nL 139.335957 208.95222 \r\nL 139.640625 211.273878 \r\nL 139.945293 206.630563 \r\nL 140.249962 208.95222 \r\nL 140.55463 210.113049 \r\nL 140.859298 206.630563 \r\nL 141.163967 208.95222 \r\nL 141.468635 210.113049 \r\nL 141.773303 212.434706 \r\nL 142.077971 212.434706 \r\nL 142.38264 211.273878 \r\nL 142.687308 212.434706 \r\nL 142.991976 211.273878 \r\nL 143.296645 212.434706 \r\nL 143.601313 210.113049 \r\nL 143.905981 210.113049 \r\nL 144.21065 212.434706 \r\nL 144.515318 206.630563 \r\nL 144.819986 212.434706 \r\nL 145.124654 207.791392 \r\nL 145.429323 212.434706 \r\nL 145.733991 207.791392 \r\nL 146.038659 208.95222 \r\nL 146.343328 207.791392 \r\nL 146.647996 212.434706 \r\nL 146.952664 212.434706 \r\nL 147.257333 211.273878 \r\nL 147.562001 211.273878 \r\nL 147.866669 210.113049 \r\nL 148.476006 210.113049 \r\nL 148.780674 211.273878 \r\nL 149.390011 208.95222 \r\nL 149.694679 210.113049 \r\nL 150.304016 210.113049 \r\nL 150.913352 212.434706 \r\nL 151.218021 210.113049 \r\nL 151.522689 213.595535 \r\nL 151.827357 210.113049 \r\nL 152.436694 210.113049 \r\nL 153.04603 212.434706 \r\nL 153.350699 210.113049 \r\nL 153.655367 208.95222 \r\nL 153.960035 211.273878 \r\nL 154.264704 212.434706 \r\nL 154.569372 208.95222 \r\nL 154.87404 212.434706 \r\nL 155.178709 210.113049 \r\nL 155.483377 212.434706 \r\nL 155.788045 210.113049 \r\nL 156.092713 208.95222 \r\nL 156.397382 210.113049 \r\nL 156.70205 210.113049 \r\nL 157.006718 207.791392 \r\nL 157.311387 210.113049 \r\nL 157.920723 210.113049 \r\nL 158.225392 211.273878 \r\nL 158.53006 207.791392 \r\nL 158.834728 211.273878 \r\nL 159.139396 210.113049 \r\nL 159.444065 212.434706 \r\nL 159.748733 210.113049 \r\nL 160.053401 212.434706 \r\nL 160.35807 210.113049 \r\nL 160.662738 210.113049 \r\nL 160.967406 211.273878 \r\nL 161.272075 208.95222 \r\nL 161.576743 212.434706 \r\nL 161.881411 210.113049 \r\nL 162.18608 213.595535 \r\nL 162.490748 210.113049 \r\nL 162.795416 210.113049 \r\nL 163.100084 208.95222 \r\nL 163.404753 211.273878 \r\nL 163.709421 208.95222 \r\nL 164.014089 212.434706 \r\nL 164.318758 210.113049 \r\nL 164.623426 211.273878 \r\nL 164.928094 210.113049 \r\nL 165.232763 212.434706 \r\nL 165.537431 212.434706 \r\nL 165.842099 211.273878 \r\nL 166.451436 211.273878 \r\nL 166.756104 210.113049 \r\nL 167.060772 212.434706 \r\nL 167.365441 208.95222 \r\nL 167.974777 211.273878 \r\nL 168.279446 211.273878 \r\nL 168.584114 210.113049 \r\nL 168.888782 211.273878 \r\nL 169.193451 210.113049 \r\nL 169.498119 211.273878 \r\nL 169.802787 211.273878 \r\nL 170.107455 213.595535 \r\nL 170.412124 210.113049 \r\nL 171.02146 210.113049 \r\nL 171.326129 212.434706 \r\nL 171.630797 211.273878 \r\nL 171.935465 213.595535 \r\nL 172.240134 212.434706 \r\nL 172.544802 213.595535 \r\nL 173.154139 211.273878 \r\nL 173.458807 211.273878 \r\nL 174.068143 213.595535 \r\nL 174.372812 212.434706 \r\nL 174.67748 207.791392 \r\nL 174.982148 211.273878 \r\nL 175.286817 212.434706 \r\nL 175.591485 208.95222 \r\nL 175.896153 212.434706 \r\nL 176.200822 210.113049 \r\nL 176.50549 211.273878 \r\nL 176.810158 210.113049 \r\nL 177.419495 212.434706 \r\nL 177.724163 211.273878 \r\nL 178.028831 211.273878 \r\nL 178.3335 210.113049 \r\nL 178.942836 212.434706 \r\nL 179.247505 210.113049 \r\nL 179.856841 212.434706 \r\nL 181.075514 212.434706 \r\nL 181.380183 210.113049 \r\nL 181.684851 212.434706 \r\nL 181.989519 212.434706 \r\nL 182.294188 210.113049 \r\nL 182.598856 211.273878 \r\nL 182.903524 210.113049 \r\nL 183.208193 213.595535 \r\nL 183.512861 211.273878 \r\nL 183.817529 213.595535 \r\nL 184.122197 210.113049 \r\nL 184.426866 212.434706 \r\nL 184.731534 212.434706 \r\nL 185.340871 210.113049 \r\nL 186.559544 210.113049 \r\nL 186.864212 212.434706 \r\nL 187.168881 211.273878 \r\nL 187.473549 212.434706 \r\nL 187.778217 210.113049 \r\nL 188.082885 211.273878 \r\nL 188.387554 213.595535 \r\nL 188.692222 210.113049 \r\nL 188.99689 213.595535 \r\nL 189.606227 213.595535 \r\nL 189.910895 210.113049 \r\nL 190.215564 210.113049 \r\nL 190.520232 208.95222 \r\nL 190.8249 212.434706 \r\nL 191.129568 213.595535 \r\nL 191.434237 212.434706 \r\nL 191.738905 212.434706 \r\nL 192.043573 211.273878 \r\nL 192.348242 212.434706 \r\nL 192.65291 210.113049 \r\nL 192.957578 211.273878 \r\nL 193.566915 211.273878 \r\nL 193.871583 212.434706 \r\nL 194.176252 210.113049 \r\nL 194.48092 208.95222 \r\nL 194.785588 212.434706 \r\nL 195.090256 210.113049 \r\nL 195.394925 213.595535 \r\nL 195.699593 214.756364 \r\nL 196.004261 212.434706 \r\nL 196.30893 211.273878 \r\nL 196.613598 212.434706 \r\nL 196.918266 211.273878 \r\nL 197.222935 213.595535 \r\nL 197.527603 213.595535 \r\nL 197.832271 212.434706 \r\nL 198.136939 212.434706 \r\nL 198.441608 210.113049 \r\nL 198.746276 212.434706 \r\nL 199.050944 211.273878 \r\nL 199.355613 212.434706 \r\nL 199.660281 211.273878 \r\nL 199.964949 211.273878 \r\nL 200.269618 213.595535 \r\nL 200.878954 213.595535 \r\nL 201.183623 211.273878 \r\nL 201.488291 213.595535 \r\nL 201.792959 213.595535 \r\nL 202.097627 211.273878 \r\nL 202.402296 210.113049 \r\nL 203.011632 212.434706 \r\nL 203.316301 210.113049 \r\nL 203.925637 214.756364 \r\nL 204.230306 211.273878 \r\nL 204.534974 212.434706 \r\nL 205.144311 212.434706 \r\nL 205.448979 210.113049 \r\nL 205.753647 210.113049 \r\nL 206.058315 214.756364 \r\nL 206.362984 213.595535 \r\nL 206.97232 213.595535 \r\nL 207.276989 214.756364 \r\nL 207.581657 211.273878 \r\nL 207.886325 212.434706 \r\nL 209.104998 212.434706 \r\nL 209.714335 214.756364 \r\nL 210.019003 211.273878 \r\nL 210.323672 212.434706 \r\nL 210.62834 212.434706 \r\nL 211.237677 214.756364 \r\nL 211.542345 211.273878 \r\nL 211.847013 213.595535 \r\nL 212.151682 213.595535 \r\nL 212.45635 214.756364 \r\nL 213.065686 212.434706 \r\nL 213.370355 212.434706 \r\nL 213.675023 210.113049 \r\nL 213.979691 208.95222 \r\nL 214.28436 214.756364 \r\nL 214.589028 213.595535 \r\nL 214.893696 211.273878 \r\nL 215.198365 212.434706 \r\nL 215.503033 211.273878 \r\nL 215.807701 211.273878 \r\nL 216.112369 212.434706 \r\nL 216.721706 212.434706 \r\nL 217.026374 210.113049 \r\nL 217.331043 212.434706 \r\nL 217.635711 213.595535 \r\nL 218.549716 213.595535 \r\nL 218.854384 212.434706 \r\nL 219.159053 214.756364 \r\nL 219.463721 211.273878 \r\nL 219.768389 213.595535 \r\nL 220.987062 213.595535 \r\nL 221.596399 211.273878 \r\nL 221.901067 213.595535 \r\nL 222.205736 211.273878 \r\nL 222.510404 212.434706 \r\nL 222.815072 214.756364 \r\nL 223.11974 212.434706 \r\nL 223.424409 211.273878 \r\nL 223.729077 213.595535 \r\nL 224.033745 214.756364 \r\nL 224.338414 211.273878 \r\nL 224.643082 212.434706 \r\nL 224.94775 214.756364 \r\nL 225.252419 212.434706 \r\nL 225.861755 212.434706 \r\nL 226.166424 213.595535 \r\nL 226.471092 213.595535 \r\nL 226.77576 214.756364 \r\nL 227.080428 213.595535 \r\nL 227.385097 214.756364 \r\nL 227.689765 211.273878 \r\nL 227.994433 213.595535 \r\nL 228.299102 210.113049 \r\nL 228.60377 213.595535 \r\nL 228.908438 213.595535 \r\nL 229.213107 212.434706 \r\nL 229.517775 213.595535 \r\nL 229.822443 211.273878 \r\nL 230.127111 214.756364 \r\nL 230.43178 214.756364 \r\nL 230.736448 213.595535 \r\nL 231.041116 213.595535 \r\nL 231.345785 211.273878 \r\nL 231.650453 211.273878 \r\nL 231.955121 214.756364 \r\nL 232.25979 214.756364 \r\nL 232.564458 213.595535 \r\nL 232.869126 213.595535 \r\nL 233.173795 214.756364 \r\nL 233.478463 213.595535 \r\nL 234.087799 213.595535 \r\nL 234.392468 214.756364 \r\nL 234.697136 211.273878 \r\nL 235.001804 214.756364 \r\nL 235.306473 214.756364 \r\nL 235.611141 212.434706 \r\nL 235.915809 211.273878 \r\nL 236.220478 212.434706 \r\nL 236.525146 212.434706 \r\nL 236.829814 211.273878 \r\nL 237.439151 211.273878 \r\nL 237.743819 212.434706 \r\nL 238.048487 208.95222 \r\nL 238.353156 211.273878 \r\nL 238.657824 214.756364 \r\nL 238.962492 212.434706 \r\nL 239.267161 211.273878 \r\nL 239.571829 214.756364 \r\nL 239.876497 213.595535 \r\nL 240.181166 213.595535 \r\nL 240.485834 212.434706 \r\nL 240.790502 213.595535 \r\nL 241.09517 212.434706 \r\nL 241.399839 213.595535 \r\nL 242.009175 213.595535 \r\nL 242.313844 211.273878 \r\nL 242.618512 211.273878 \r\nL 242.92318 214.756364 \r\nL 243.227849 211.273878 \r\nL 243.532517 212.434706 \r\nL 244.141854 212.434706 \r\nL 244.446522 211.273878 \r\nL 245.055858 213.595535 \r\nL 245.360527 212.434706 \r\nL 245.665195 207.791392 \r\nL 245.969863 214.756364 \r\nL 246.274532 208.95222 \r\nL 246.5792 212.434706 \r\nL 246.883868 213.595535 \r\nL 247.493205 211.273878 \r\nL 247.797873 213.595535 \r\nL 248.102541 210.113049 \r\nL 248.40721 211.273878 \r\nL 248.711878 214.756364 \r\nL 249.016546 211.273878 \r\nL 249.321215 212.434706 \r\nL 249.625883 211.273878 \r\nL 249.930551 213.595535 \r\nL 250.23522 212.434706 \r\nL 250.844556 214.756364 \r\nL 251.149225 214.756364 \r\nL 251.453893 212.434706 \r\nL 251.758561 214.756364 \r\nL 252.063229 212.434706 \r\nL 252.977234 212.434706 \r\nL 253.586571 214.756364 \r\nL 253.891239 211.273878 \r\nL 254.500576 213.595535 \r\nL 254.805244 212.434706 \r\nL 255.109912 213.595535 \r\nL 255.414581 212.434706 \r\nL 255.719249 214.756364 \r\nL 256.023917 213.595535 \r\nL 256.328586 214.756364 \r\nL 256.937922 212.434706 \r\nL 257.242591 214.756364 \r\nL 257.547259 214.756364 \r\nL 257.851927 212.434706 \r\nL 258.156596 212.434706 \r\nL 258.461264 213.595535 \r\nL 258.765932 212.434706 \r\nL 259.0706 212.434706 \r\nL 259.679937 214.756364 \r\nL 260.289274 212.434706 \r\nL 260.593942 210.113049 \r\nL 260.89861 211.273878 \r\nL 261.203279 211.273878 \r\nL 261.507947 213.595535 \r\nL 261.812615 212.434706 \r\nL 262.117283 213.595535 \r\nL 262.421952 211.273878 \r\nL 262.72662 213.595535 \r\nL 263.031288 214.756364 \r\nL 263.335957 213.595535 \r\nL 263.945293 213.595535 \r\nL 264.249962 214.756364 \r\nL 264.55463 214.756364 \r\nL 264.859298 210.113049 \r\nL 265.163967 214.756364 \r\nL 265.468635 214.756364 \r\nL 265.773303 212.434706 \r\nL 266.687308 208.95222 \r\nL 266.991976 210.113049 \r\nL 267.296645 212.434706 \r\nL 267.601313 211.273878 \r\nL 267.905981 211.273878 \r\nL 268.21065 214.756364 \r\nL 269.124654 214.756364 \r\nL 269.429323 213.595535 \r\nL 269.733991 214.756364 \r\nL 270.038659 214.756364 \r\nL 270.343328 210.113049 \r\nL 270.647996 213.595535 \r\nL 271.257333 211.273878 \r\nL 271.562001 213.595535 \r\nL 271.866669 214.756364 \r\nL 272.171338 213.595535 \r\nL 272.476006 211.273878 \r\nL 272.780674 214.756364 \r\nL 273.085342 213.595535 \r\nL 273.390011 213.595535 \r\nL 273.694679 214.756364 \r\nL 274.304016 212.434706 \r\nL 274.608684 210.113049 \r\nL 274.913352 211.273878 \r\nL 275.218021 213.595535 \r\nL 275.522689 211.273878 \r\nL 275.827357 212.434706 \r\nL 276.132025 210.113049 \r\nL 276.436694 212.434706 \r\nL 276.741362 213.595535 \r\nL 277.04603 211.273878 \r\nL 277.350699 212.434706 \r\nL 277.655367 214.756364 \r\nL 277.960035 211.273878 \r\nL 278.264704 213.595535 \r\nL 278.569372 212.434706 \r\nL 279.178709 214.756364 \r\nL 279.483377 213.595535 \r\nL 279.788045 213.595535 \r\nL 280.092713 212.434706 \r\nL 280.397382 214.756364 \r\nL 281.006718 214.756364 \r\nL 281.311387 213.595535 \r\nL 281.616055 214.756364 \r\nL 281.920723 213.595535 \r\nL 282.225392 214.756364 \r\nL 282.834728 214.756364 \r\nL 283.139396 212.434706 \r\nL 283.444065 213.595535 \r\nL 283.748733 213.595535 \r\nL 284.053401 214.756364 \r\nL 284.35807 212.434706 \r\nL 284.662738 214.756364 \r\nL 284.967406 210.113049 \r\nL 285.272075 214.756364 \r\nL 285.576743 210.113049 \r\nL 285.881411 213.595535 \r\nL 286.18608 212.434706 \r\nL 286.490748 213.595535 \r\nL 286.795416 213.595535 \r\nL 287.100084 214.756364 \r\nL 287.404753 213.595535 \r\nL 287.709421 211.273878 \r\nL 288.014089 214.756364 \r\nL 288.318758 210.113049 \r\nL 288.623426 211.273878 \r\nL 288.928094 211.273878 \r\nL 289.232763 210.113049 \r\nL 289.537431 213.595535 \r\nL 289.842099 212.434706 \r\nL 290.146768 214.756364 \r\nL 290.451436 214.756364 \r\nL 290.756104 213.595535 \r\nL 291.060772 214.756364 \r\nL 291.670109 210.113049 \r\nL 291.974777 214.756364 \r\nL 292.279446 212.434706 \r\nL 292.584114 214.756364 \r\nL 292.888782 213.595535 \r\nL 293.193451 213.595535 \r\nL 293.498119 211.273878 \r\nL 293.802787 211.273878 \r\nL 294.412124 213.595535 \r\nL 294.716792 211.273878 \r\nL 295.02146 212.434706 \r\nL 295.326129 212.434706 \r\nL 295.630797 213.595535 \r\nL 295.935465 213.595535 \r\nL 296.240134 212.434706 \r\nL 297.154139 212.434706 \r\nL 297.458807 211.273878 \r\nL 297.763475 212.434706 \r\nL 298.068143 214.756364 \r\nL 298.372812 213.595535 \r\nL 299.896153 213.595535 \r\nL 300.200822 212.434706 \r\nL 300.50549 212.434706 \r\nL 300.810158 213.595535 \r\nL 301.114826 211.273878 \r\nL 301.419495 213.595535 \r\nL 302.028831 213.595535 \r\nL 302.638168 211.273878 \r\nL 303.247505 211.273878 \r\nL 303.552173 213.595535 \r\nL 303.856841 213.595535 \r\nL 304.16151 210.113049 \r\nL 304.770846 210.113049 \r\nL 305.075514 213.595535 \r\nL 305.380183 213.595535 \r\nL 305.989519 211.273878 \r\nL 306.598856 211.273878 \r\nL 306.903524 212.434706 \r\nL 307.208193 212.434706 \r\nL 307.512861 210.113049 \r\nL 307.817529 210.113049 \r\nL 308.122197 211.273878 \r\nL 308.426866 211.273878 \r\nL 308.731534 214.756364 \r\nL 309.036202 213.595535 \r\nL 309.340871 211.273878 \r\nL 309.645539 213.595535 \r\nL 309.950207 212.434706 \r\nL 310.254876 213.595535 \r\nL 310.559544 212.434706 \r\nL 310.864212 213.595535 \r\nL 311.168881 211.273878 \r\nL 311.473549 211.273878 \r\nL 311.778217 213.595535 \r\nL 312.082885 211.273878 \r\nL 312.387554 213.595535 \r\nL 312.692222 211.273878 \r\nL 312.99689 213.595535 \r\nL 313.301559 212.434706 \r\nL 313.606227 213.595535 \r\nL 313.910895 213.595535 \r\nL 314.520232 211.273878 \r\nL 314.8249 212.434706 \r\nL 315.129568 212.434706 \r\nL 315.434237 213.595535 \r\nL 315.738905 211.273878 \r\nL 316.043573 212.434706 \r\nL 316.348242 211.273878 \r\nL 316.65291 213.595535 \r\nL 316.957578 212.434706 \r\nL 317.262247 210.113049 \r\nL 317.566915 211.273878 \r\nL 317.871583 210.113049 \r\nL 318.176252 210.113049 \r\nL 318.48092 211.273878 \r\nL 318.785588 213.595535 \r\nL 319.394925 211.273878 \r\nL 319.699593 213.595535 \r\nL 320.004261 210.113049 \r\nL 320.30893 212.434706 \r\nL 320.613598 213.595535 \r\nL 320.918266 211.273878 \r\nL 321.222935 212.434706 \r\nL 321.527603 212.434706 \r\nL 321.832271 213.595535 \r\nL 322.136939 212.434706 \r\nL 322.441608 210.113049 \r\nL 322.746276 211.273878 \r\nL 323.355613 211.273878 \r\nL 323.660281 213.595535 \r\nL 323.964949 213.595535 \r\nL 324.269618 211.273878 \r\nL 324.574286 210.113049 \r\nL 324.878954 211.273878 \r\nL 326.097627 211.273878 \r\nL 326.402296 213.595535 \r\nL 326.706964 210.113049 \r\nL 327.011632 212.434706 \r\nL 327.316301 212.434706 \r\nL 327.620969 211.273878 \r\nL 327.925637 212.434706 \r\nL 328.839642 212.434706 \r\nL 329.144311 208.95222 \r\nL 329.448979 211.273878 \r\nL 329.753647 212.434706 \r\nL 330.058315 210.113049 \r\nL 330.362984 211.273878 \r\nL 330.667652 213.595535 \r\nL 330.97232 212.434706 \r\nL 331.581657 212.434706 \r\nL 331.886325 211.273878 \r\nL 332.495662 213.595535 \r\nL 332.80033 212.434706 \r\nL 333.104998 213.595535 \r\nL 333.409667 212.434706 \r\nL 333.714335 210.113049 \r\nL 334.019003 212.434706 \r\nL 334.323672 212.434706 \r\nL 334.62834 211.273878 \r\nL 334.933008 213.595535 \r\nL 335.237677 211.273878 \r\nL 335.847013 213.595535 \r\nL 336.151682 213.595535 \r\nL 336.45635 212.434706 \r\nL 336.761018 213.595535 \r\nL 337.370355 213.595535 \r\nL 337.675023 212.434706 \r\nL 338.28436 212.434706 \r\nL 338.589028 214.756364 \r\nL 338.893696 212.434706 \r\nL 339.198365 213.595535 \r\nL 339.503033 211.273878 \r\nL 339.807701 211.273878 \r\nL 340.112369 212.434706 \r\nL 340.417038 212.434706 \r\nL 340.721706 211.273878 \r\nL 341.026374 213.595535 \r\nL 341.331043 212.434706 \r\nL 341.940379 214.756364 \r\nL 342.245048 212.434706 \r\nL 343.463721 212.434706 \r\nL 343.768389 213.595535 \r\nL 344.377726 211.273878 \r\nL 344.682394 213.595535 \r\nL 344.987062 212.434706 \r\nL 345.901067 212.434706 \r\nL 346.205736 213.595535 \r\nL 346.510404 212.434706 \r\nL 346.815072 213.595535 \r\nL 347.11974 211.273878 \r\nL 347.424409 212.434706 \r\nL 348.338414 212.434706 \r\nL 348.643082 211.273878 \r\nL 349.252419 213.595535 \r\nL 349.557087 211.273878 \r\nL 349.861755 213.595535 \r\nL 350.166424 212.434706 \r\nL 350.471092 213.595535 \r\nL 350.77576 211.273878 \r\nL 351.080428 212.434706 \r\nL 351.385097 211.273878 \r\nL 351.689765 212.434706 \r\nL 351.994433 211.273878 \r\nL 352.299102 211.273878 \r\nL 352.60377 212.434706 \r\nL 352.908438 212.434706 \r\nL 353.213107 208.95222 \r\nL 353.517775 211.273878 \r\nL 353.822443 212.434706 \r\nL 353.822443 212.434706 \r\n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 34.240625 224.64 \r\nL 34.240625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 369.040625 224.64 \r\nL 369.040625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 34.240625 224.64 \r\nL 369.040625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 34.240625 7.2 \r\nL 369.040625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_2\">\r\n    <g id=\"patch_12\">\r\n     <path d=\"M 41.240625 219.64 \r\nL 118.640625 219.64 \r\nQ 120.640625 219.64 120.640625 217.64 \r\nL 120.640625 188.7275 \r\nQ 120.640625 186.7275 118.640625 186.7275 \r\nL 41.240625 186.7275 \r\nQ 39.240625 186.7275 39.240625 188.7275 \r\nL 39.240625 217.64 \r\nQ 39.240625 219.64 41.240625 219.64 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_28\">\r\n     <path d=\"M 43.240625 194.825937 \r\nL 63.240625 194.825937 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_29\"/>\r\n    <g id=\"text_25\">\r\n     <!-- train_acc -->\r\n     <g transform=\"translate(71.240625 198.325937)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"344.042969\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"399.023438\" xlink:href=\"#DejaVuSans-99\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_30\">\r\n     <path d=\"M 43.240625 209.782187 \r\nL 63.240625 209.782187 \r\n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_31\"/>\r\n    <g id=\"text_26\">\r\n     <!-- val_acc -->\r\n     <g transform=\"translate(71.240625 213.282187)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p508ee491aa\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"34.240625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "accax = axes.twinx() # 윈도우 하나에 여러개 그릴 수 있음\n",
    "axes.plot(hist.history['loss'], 'y', label = 'train_loss')\n",
    "axes.plot(hist.history['val_loss'], 'r', label = 'val_loss')\n",
    "accax.plot(hist.history['acc'], 'b', label = 'train_acc')\n",
    "accax.plot(hist.history['val_acc'], 'g', label = 'val_acc')\n",
    "\n",
    "axes.set_xlabel('epoch')\n",
    "axes.set_ylabel('cost')\n",
    "accax.set_ylabel('accuracy')\n",
    "axes.legend(loc = 'upper left')\n",
    "accax.legend(loc = 'lower left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "xtrain=xtrain.reshape(60000,784).astype('float32')/255.0\n",
    "# xval=xval.reshape(10000,784).astype('float32')/255.0\n",
    "xtest=xtest.reshape(10000,784).astype('float32')/255.0\n",
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "# yval = np_utils.to_categorical(yval)\n",
    "ytest = np_utils.to_categorical(ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 구성하기  입력계층, 히든 계층 출력 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units =2, input_dim = 28*28, activation= 'relu')) #래이어 설계, 입력데이터의 차원\n",
    "# 입력 =784, 출력=2인 레이어 추가 \n",
    "\n",
    "model.add(Dense(units =10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 학습과정 설정, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.1895 - acc: 0.5826\nEpoch 2/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.1631 - acc: 0.5903\nEpoch 3/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.1426 - acc: 0.5942\nEpoch 4/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.1259 - acc: 0.5994\nEpoch 5/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.1125 - acc: 0.6023\nEpoch 6/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.1010 - acc: 0.6053\nEpoch 7/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0903 - acc: 0.6072\nEpoch 8/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0822 - acc: 0.6101\nEpoch 9/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0745 - acc: 0.6140\nEpoch 10/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0677 - acc: 0.6168\nEpoch 11/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0612 - acc: 0.6205\nEpoch 12/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0558 - acc: 0.6234\nEpoch 13/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0511 - acc: 0.6237\nEpoch 14/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0466 - acc: 0.6286\nEpoch 15/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0422 - acc: 0.6310\nEpoch 16/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0387 - acc: 0.6335\nEpoch 17/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0353 - acc: 0.6356\nEpoch 18/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0317 - acc: 0.6374\nEpoch 19/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0291 - acc: 0.6410\nEpoch 20/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0260 - acc: 0.6416\nEpoch 21/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0232 - acc: 0.6462\nEpoch 22/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0204 - acc: 0.6465\nEpoch 23/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0183 - acc: 0.6501\nEpoch 24/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0157 - acc: 0.6520\nEpoch 25/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0135 - acc: 0.6530\nEpoch 26/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0109 - acc: 0.6544\nEpoch 27/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 1.0093 - acc: 0.6551\nEpoch 28/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0076 - acc: 0.6572\nEpoch 29/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0057 - acc: 0.6577\nEpoch 30/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0045 - acc: 0.6582\nEpoch 31/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 1.0028 - acc: 0.6595\nEpoch 32/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0010 - acc: 0.6613\nEpoch 33/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 1.0000 - acc: 0.6609\nEpoch 34/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9981 - acc: 0.6618\nEpoch 35/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.9968 - acc: 0.6622\nEpoch 36/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 0.9961 - acc: 0.6633\nEpoch 37/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9949 - acc: 0.6642\nEpoch 38/50\n60000/60000 [==============================] - 1s 24us/sample - loss: 0.9934 - acc: 0.6628\nEpoch 39/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9923 - acc: 0.6645\nEpoch 40/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9917 - acc: 0.6660\nEpoch 41/50\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.9905 - acc: 0.6654\nEpoch 42/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9896 - acc: 0.6652\nEpoch 43/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 0.9888 - acc: 0.6660\nEpoch 44/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9875 - acc: 0.6658\nEpoch 45/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 0.9869 - acc: 0.6665\nEpoch 46/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 0.9862 - acc: 0.6661\nEpoch 47/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 0.9851 - acc: 0.6680\nEpoch 48/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9843 - acc: 0.6669\nEpoch 49/50\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.9836 - acc: 0.6673\nEpoch 50/50\n60000/60000 [==============================] - 1s 21us/sample - loss: 0.9824 - acc: 0.6673\n"
    }
   ],
   "source": [
    "# 3번 모델 학습과정 설정 \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics = ['accuracy']) # loss == cost\n",
    "hist = model.fit(xtrain, ytrain, batch_size=32,  epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.9857413740158081, 0.6708]"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "model.evaluate(xtest, ytest, batch_size= 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 사용하기 (분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "yhat = model.predict(xtest[0:1])\n",
    "yhat # yhat을 모두 더하면, 1이 나옴 왜냐? 확률이기 때문에!\n",
    "# ytest[0:1]\n",
    "yhat[0]\n",
    "np.sum(yhat[0])\n",
    "np.max(yhat[0])\n",
    "np.argmax(yhat[0])"
   ]
  }
 ]
}